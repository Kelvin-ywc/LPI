AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: False
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 3
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('refexp_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('refexp_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: True
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
LPAI:
  INTERACT: True
  INTERACT_LORA_D: 4
  LAYER_ALIGNMENT: False
  PROMPT_DEPTH: 9
  PROMPT_LORA: True
  PROMPT_LORA_D: 4
  TASK_ALIGNMENT: True
  TEXTUAL_PROMPT: True
  VISUAL_PROMPT: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: False
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: False
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: MODEL/glip_a_tiny_o365.pth
OUTPUT_DIR: OUTPUT
PATHS_CATALOG: /root/workspace/grounding/prompt_grounding/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: 4
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 0.0001
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: True
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 32
  LANG_LR: 0.0001
  MAX_EPOCH: 30
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.0
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 10
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 2
  TEST_WITH_INFERENCE: True
  TUNING_HIGHLEVEL_OVERRIDE: language_prompt_v4
  USE_AMP: True
  USE_AUTOSTEP: True
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: True
  EVAL_TASK: grounding
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 1
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
args.opts []
2024-03-19 03:13:36,344 maskrcnn_benchmark INFO: Using 1 GPUs
2024-03-19 03:13:36,344 maskrcnn_benchmark INFO: Namespace(config_file='configs/refcoco/finetune_A_decompose_task_interact.yaml', custom_shot_and_epoch_and_general_copy='0_10_1', distributed=False, evaluate_only_best_on_test=False, ft_tasks='', keep_testing=False, local_rank=0, opts=[], push_both_val_and_test=False, shuffle_seeds=None, skip_optimizer_resume=False, skip_test=True, skip_train=False, use_prepared_data=False)
2024-03-19 03:13:36,344 maskrcnn_benchmark INFO: Loaded configuration file configs/refcoco/finetune_A_decompose_task_interact.yaml
2024-03-19 03:13:36,344 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "MODEL/glip_a_tiny_o365.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: False
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True

    USE_CHECKPOINT: False

TEST:
  DURING_TRAINING: True
  IMS_PER_BATCH: 1
  EVAL_TASK: grounding
# use for grounding model
DATASETS:
  TRAIN: ("refexp_train", )
  TEST: ("refexp_val",)
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

  USE_OVERRIDE_CATEGORY: True
  SHUFFLE_SEED: 3

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.0001
  WEIGHT_DECAY: 0.05
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 32
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.0
  FIND_UNUSED_PARAMETERS: True

  TEST_WITH_INFERENCE: True
  USE_AUTOSTEP: True
#  USE_COSINE: True

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0

  SEED: 10
  STEP_PATIENCE: 2
  AUTO_TERMINATE_PATIENCE: 4
  TUNING_HIGHLEVEL_OVERRIDE: language_prompt_v4

LPAI:
  VISUAL_PROMPT: True
  TEXTUAL_PROMPT: True
  TASK_ALIGNMENT: True
  LAYER_ALIGNMENT: False
  INTERACT: True
  PROMPT_DEPTH: 9

  PROMPT_LORA_D: 4
  INTERACT_LORA_D: 4
  PROMPT_LORA: True

2024-03-19 03:13:36,345 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: False
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 3
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('refexp_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('refexp_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: True
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
LPAI:
  INTERACT: True
  INTERACT_LORA_D: 4
  LAYER_ALIGNMENT: False
  PROMPT_DEPTH: 9
  PROMPT_LORA: True
  PROMPT_LORA_D: 4
  TASK_ALIGNMENT: True
  TEXTUAL_PROMPT: True
  VISUAL_PROMPT: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: False
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: False
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: MODEL/glip_a_tiny_o365.pth
OUTPUT_DIR: OUTPUT
PATHS_CATALOG: /root/workspace/grounding/prompt_grounding/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: 4
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 0.0001
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: True
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 32
  LANG_LR: 0.0001
  MAX_EPOCH: 30
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.0
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 10
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 2
  TEST_WITH_INFERENCE: True
  TUNING_HIGHLEVEL_OVERRIDE: language_prompt_v4
  USE_AMP: True
  USE_AUTOSTEP: True
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: True
  EVAL_TASK: grounding
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 1
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
2024-03-19 03:13:36,345 maskrcnn_benchmark INFO: Saving config into: OUTPUT/config.yml
2024-03-19 03:13:36,400 maskrcnn_benchmark INFO: Loaded fine-tune configuration file configs/refcoco/finetune_A_decompose_task_interact.yaml
2024-03-19 03:13:36,400 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "MODEL/glip_a_tiny_o365.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: False
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True

    USE_CHECKPOINT: False

TEST:
  DURING_TRAINING: True
  IMS_PER_BATCH: 1
  EVAL_TASK: grounding
# use for grounding model
DATASETS:
  TRAIN: ("refexp_train", )
  TEST: ("refexp_val",)
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

  USE_OVERRIDE_CATEGORY: True
  SHUFFLE_SEED: 3

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.0001
  WEIGHT_DECAY: 0.05
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 32
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.0
  FIND_UNUSED_PARAMETERS: True

  TEST_WITH_INFERENCE: True
  USE_AUTOSTEP: True
#  USE_COSINE: True

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0

  SEED: 10
  STEP_PATIENCE: 2
  AUTO_TERMINATE_PATIENCE: 4
  TUNING_HIGHLEVEL_OVERRIDE: language_prompt_v4

LPAI:
  VISUAL_PROMPT: True
  TEXTUAL_PROMPT: True
  TASK_ALIGNMENT: True
  LAYER_ALIGNMENT: False
  INTERACT: True
  PROMPT_DEPTH: 9

  PROMPT_LORA_D: 4
  INTERACT_LORA_D: 4
  PROMPT_LORA: True

Saving config into: OUTPUT/ft_task_1/config.yml
2024-03-19 03:13:36,435 maskrcnn_benchmark INFO: Training configs/refcoco/finetune_A_decompose_task_interact.yaml
VISION BACKBONE USE GRADIENT CHECKPOINTING:  False
LANGUAGE BACKBONE USE GRADIENT CHECKPOINTING:  False
2024-03-19 03:13:44,558 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.proj.bias                                          loaded from backbone.body.layers.0.blocks.0.attn.proj.bias                                  of shape (96,)
2024-03-19 03:13:44,558 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.proj.weight                                        loaded from backbone.body.layers.0.blocks.0.attn.proj.weight                                of shape (96, 96)
2024-03-19 03:13:44,558 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.qkv.bias                                           loaded from backbone.body.layers.0.blocks.0.attn.qkv.bias                                   of shape (288,)
2024-03-19 03:13:44,558 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.qkv.weight                                         loaded from backbone.body.layers.0.blocks.0.attn.qkv.weight                                 of shape (288, 96)
2024-03-19 03:13:44,558 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.relative_position_bias_table                       loaded from backbone.body.layers.0.blocks.0.attn.relative_position_bias_table               of shape (169, 3)
2024-03-19 03:13:44,558 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.relative_position_index                            loaded from backbone.body.layers.0.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,558 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.mlp.fc1.bias                                            loaded from backbone.body.layers.0.blocks.0.mlp.fc1.bias                                    of shape (384,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.mlp.fc1.weight                                          loaded from backbone.body.layers.0.blocks.0.mlp.fc1.weight                                  of shape (384, 96)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.mlp.fc2.bias                                            loaded from backbone.body.layers.0.blocks.0.mlp.fc2.bias                                    of shape (96,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.mlp.fc2.weight                                          loaded from backbone.body.layers.0.blocks.0.mlp.fc2.weight                                  of shape (96, 384)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.norm1.bias                                              loaded from backbone.body.layers.0.blocks.0.norm1.bias                                      of shape (96,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.norm1.weight                                            loaded from backbone.body.layers.0.blocks.0.norm1.weight                                    of shape (96,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.norm2.bias                                              loaded from backbone.body.layers.0.blocks.0.norm2.bias                                      of shape (96,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.norm2.weight                                            loaded from backbone.body.layers.0.blocks.0.norm2.weight                                    of shape (96,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.proj.bias                                          loaded from backbone.body.layers.0.blocks.1.attn.proj.bias                                  of shape (96,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.proj.weight                                        loaded from backbone.body.layers.0.blocks.1.attn.proj.weight                                of shape (96, 96)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.qkv.bias                                           loaded from backbone.body.layers.0.blocks.1.attn.qkv.bias                                   of shape (288,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.qkv.weight                                         loaded from backbone.body.layers.0.blocks.1.attn.qkv.weight                                 of shape (288, 96)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.relative_position_bias_table                       loaded from backbone.body.layers.0.blocks.1.attn.relative_position_bias_table               of shape (169, 3)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.relative_position_index                            loaded from backbone.body.layers.0.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.mlp.fc1.bias                                            loaded from backbone.body.layers.0.blocks.1.mlp.fc1.bias                                    of shape (384,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.mlp.fc1.weight                                          loaded from backbone.body.layers.0.blocks.1.mlp.fc1.weight                                  of shape (384, 96)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.mlp.fc2.bias                                            loaded from backbone.body.layers.0.blocks.1.mlp.fc2.bias                                    of shape (96,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.mlp.fc2.weight                                          loaded from backbone.body.layers.0.blocks.1.mlp.fc2.weight                                  of shape (96, 384)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.norm1.bias                                              loaded from backbone.body.layers.0.blocks.1.norm1.bias                                      of shape (96,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.norm1.weight                                            loaded from backbone.body.layers.0.blocks.1.norm1.weight                                    of shape (96,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.norm2.bias                                              loaded from backbone.body.layers.0.blocks.1.norm2.bias                                      of shape (96,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.norm2.weight                                            loaded from backbone.body.layers.0.blocks.1.norm2.weight                                    of shape (96,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.downsample.norm.bias                                             loaded from backbone.body.layers.0.downsample.norm.bias                                     of shape (384,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.downsample.norm.weight                                           loaded from backbone.body.layers.0.downsample.norm.weight                                   of shape (384,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.downsample.reduction.weight                                      loaded from backbone.body.layers.0.downsample.reduction.weight                              of shape (192, 384)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.proj.bias                                          loaded from backbone.body.layers.1.blocks.0.attn.proj.bias                                  of shape (192,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.proj.weight                                        loaded from backbone.body.layers.1.blocks.0.attn.proj.weight                                of shape (192, 192)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.qkv.bias                                           loaded from backbone.body.layers.1.blocks.0.attn.qkv.bias                                   of shape (576,)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.qkv.weight                                         loaded from backbone.body.layers.1.blocks.0.attn.qkv.weight                                 of shape (576, 192)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.relative_position_bias_table                       loaded from backbone.body.layers.1.blocks.0.attn.relative_position_bias_table               of shape (169, 6)
2024-03-19 03:13:44,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.relative_position_index                            loaded from backbone.body.layers.1.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.mlp.fc1.bias                                            loaded from backbone.body.layers.1.blocks.0.mlp.fc1.bias                                    of shape (768,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.mlp.fc1.weight                                          loaded from backbone.body.layers.1.blocks.0.mlp.fc1.weight                                  of shape (768, 192)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.mlp.fc2.bias                                            loaded from backbone.body.layers.1.blocks.0.mlp.fc2.bias                                    of shape (192,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.mlp.fc2.weight                                          loaded from backbone.body.layers.1.blocks.0.mlp.fc2.weight                                  of shape (192, 768)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.norm1.bias                                              loaded from backbone.body.layers.1.blocks.0.norm1.bias                                      of shape (192,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.norm1.weight                                            loaded from backbone.body.layers.1.blocks.0.norm1.weight                                    of shape (192,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.norm2.bias                                              loaded from backbone.body.layers.1.blocks.0.norm2.bias                                      of shape (192,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.norm2.weight                                            loaded from backbone.body.layers.1.blocks.0.norm2.weight                                    of shape (192,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.proj.bias                                          loaded from backbone.body.layers.1.blocks.1.attn.proj.bias                                  of shape (192,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.proj.weight                                        loaded from backbone.body.layers.1.blocks.1.attn.proj.weight                                of shape (192, 192)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.qkv.bias                                           loaded from backbone.body.layers.1.blocks.1.attn.qkv.bias                                   of shape (576,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.qkv.weight                                         loaded from backbone.body.layers.1.blocks.1.attn.qkv.weight                                 of shape (576, 192)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.relative_position_bias_table                       loaded from backbone.body.layers.1.blocks.1.attn.relative_position_bias_table               of shape (169, 6)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.relative_position_index                            loaded from backbone.body.layers.1.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.mlp.fc1.bias                                            loaded from backbone.body.layers.1.blocks.1.mlp.fc1.bias                                    of shape (768,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.mlp.fc1.weight                                          loaded from backbone.body.layers.1.blocks.1.mlp.fc1.weight                                  of shape (768, 192)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.mlp.fc2.bias                                            loaded from backbone.body.layers.1.blocks.1.mlp.fc2.bias                                    of shape (192,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.mlp.fc2.weight                                          loaded from backbone.body.layers.1.blocks.1.mlp.fc2.weight                                  of shape (192, 768)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.norm1.bias                                              loaded from backbone.body.layers.1.blocks.1.norm1.bias                                      of shape (192,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.norm1.weight                                            loaded from backbone.body.layers.1.blocks.1.norm1.weight                                    of shape (192,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.norm2.bias                                              loaded from backbone.body.layers.1.blocks.1.norm2.bias                                      of shape (192,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.norm2.weight                                            loaded from backbone.body.layers.1.blocks.1.norm2.weight                                    of shape (192,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.downsample.norm.bias                                             loaded from backbone.body.layers.1.downsample.norm.bias                                     of shape (768,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.downsample.norm.weight                                           loaded from backbone.body.layers.1.downsample.norm.weight                                   of shape (768,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.downsample.reduction.weight                                      loaded from backbone.body.layers.1.downsample.reduction.weight                              of shape (384, 768)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.0.attn.proj.bias                                  of shape (384,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.0.attn.proj.weight                                of shape (384, 384)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.0.attn.qkv.bias                                   of shape (1152,)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.0.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.0.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 03:13:44,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,561 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.0.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 03:13:44,561 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.0.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 03:13:44,561 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.0.mlp.fc2.bias                                    of shape (384,)
2024-03-19 03:13:44,561 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.0.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 03:13:44,561 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.norm1.bias                                              loaded from backbone.body.layers.2.blocks.0.norm1.bias                                      of shape (384,)
2024-03-19 03:13:44,561 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.norm1.weight                                            loaded from backbone.body.layers.2.blocks.0.norm1.weight                                    of shape (384,)
2024-03-19 03:13:44,561 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.norm2.bias                                              loaded from backbone.body.layers.2.blocks.0.norm2.bias                                      of shape (384,)
2024-03-19 03:13:44,561 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.norm2.weight                                            loaded from backbone.body.layers.2.blocks.0.norm2.weight                                    of shape (384,)
2024-03-19 03:13:44,561 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.1.attn.proj.bias                                  of shape (384,)
2024-03-19 03:13:44,561 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.1.attn.proj.weight                                of shape (384, 384)
2024-03-19 03:13:44,561 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.1.attn.qkv.bias                                   of shape (1152,)
2024-03-19 03:13:44,561 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.1.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 03:13:44,561 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.1.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 03:13:44,561 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.1.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.1.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.1.mlp.fc2.bias                                    of shape (384,)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.1.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.norm1.bias                                              loaded from backbone.body.layers.2.blocks.1.norm1.bias                                      of shape (384,)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.norm1.weight                                            loaded from backbone.body.layers.2.blocks.1.norm1.weight                                    of shape (384,)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.norm2.bias                                              loaded from backbone.body.layers.2.blocks.1.norm2.bias                                      of shape (384,)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.norm2.weight                                            loaded from backbone.body.layers.2.blocks.1.norm2.weight                                    of shape (384,)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.2.attn.proj.bias                                  of shape (384,)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.2.attn.proj.weight                                of shape (384, 384)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.2.attn.qkv.bias                                   of shape (1152,)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.2.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.2.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.2.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.2.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.2.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.2.mlp.fc2.bias                                    of shape (384,)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.2.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.norm1.bias                                              loaded from backbone.body.layers.2.blocks.2.norm1.bias                                      of shape (384,)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.norm1.weight                                            loaded from backbone.body.layers.2.blocks.2.norm1.weight                                    of shape (384,)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.norm2.bias                                              loaded from backbone.body.layers.2.blocks.2.norm2.bias                                      of shape (384,)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.norm2.weight                                            loaded from backbone.body.layers.2.blocks.2.norm2.weight                                    of shape (384,)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.3.attn.proj.bias                                  of shape (384,)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.3.attn.proj.weight                                of shape (384, 384)
2024-03-19 03:13:44,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.3.attn.qkv.bias                                   of shape (1152,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.3.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.3.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.3.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.3.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.3.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.3.mlp.fc2.bias                                    of shape (384,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.3.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.norm1.bias                                              loaded from backbone.body.layers.2.blocks.3.norm1.bias                                      of shape (384,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.norm1.weight                                            loaded from backbone.body.layers.2.blocks.3.norm1.weight                                    of shape (384,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.norm2.bias                                              loaded from backbone.body.layers.2.blocks.3.norm2.bias                                      of shape (384,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.norm2.weight                                            loaded from backbone.body.layers.2.blocks.3.norm2.weight                                    of shape (384,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.4.attn.proj.bias                                  of shape (384,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.4.attn.proj.weight                                of shape (384, 384)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.4.attn.qkv.bias                                   of shape (1152,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.4.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.4.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.4.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.4.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.4.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.4.mlp.fc2.bias                                    of shape (384,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.4.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.norm1.bias                                              loaded from backbone.body.layers.2.blocks.4.norm1.bias                                      of shape (384,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.norm1.weight                                            loaded from backbone.body.layers.2.blocks.4.norm1.weight                                    of shape (384,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.norm2.bias                                              loaded from backbone.body.layers.2.blocks.4.norm2.bias                                      of shape (384,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.norm2.weight                                            loaded from backbone.body.layers.2.blocks.4.norm2.weight                                    of shape (384,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.5.attn.proj.bias                                  of shape (384,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.5.attn.proj.weight                                of shape (384, 384)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.5.attn.qkv.bias                                   of shape (1152,)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.5.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.5.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 03:13:44,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.5.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.5.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.5.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.5.mlp.fc2.bias                                    of shape (384,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.5.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.norm1.bias                                              loaded from backbone.body.layers.2.blocks.5.norm1.bias                                      of shape (384,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.norm1.weight                                            loaded from backbone.body.layers.2.blocks.5.norm1.weight                                    of shape (384,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.norm2.bias                                              loaded from backbone.body.layers.2.blocks.5.norm2.bias                                      of shape (384,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.norm2.weight                                            loaded from backbone.body.layers.2.blocks.5.norm2.weight                                    of shape (384,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.downsample.norm.bias                                             loaded from backbone.body.layers.2.downsample.norm.bias                                     of shape (1536,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.downsample.norm.weight                                           loaded from backbone.body.layers.2.downsample.norm.weight                                   of shape (1536,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.downsample.reduction.weight                                      loaded from backbone.body.layers.2.downsample.reduction.weight                              of shape (768, 1536)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.proj.bias                                          loaded from backbone.body.layers.3.blocks.0.attn.proj.bias                                  of shape (768,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.proj.weight                                        loaded from backbone.body.layers.3.blocks.0.attn.proj.weight                                of shape (768, 768)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.qkv.bias                                           loaded from backbone.body.layers.3.blocks.0.attn.qkv.bias                                   of shape (2304,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.qkv.weight                                         loaded from backbone.body.layers.3.blocks.0.attn.qkv.weight                                 of shape (2304, 768)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.relative_position_bias_table                       loaded from backbone.body.layers.3.blocks.0.attn.relative_position_bias_table               of shape (169, 24)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.relative_position_index                            loaded from backbone.body.layers.3.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.mlp.fc1.bias                                            loaded from backbone.body.layers.3.blocks.0.mlp.fc1.bias                                    of shape (3072,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.mlp.fc1.weight                                          loaded from backbone.body.layers.3.blocks.0.mlp.fc1.weight                                  of shape (3072, 768)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.mlp.fc2.bias                                            loaded from backbone.body.layers.3.blocks.0.mlp.fc2.bias                                    of shape (768,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.mlp.fc2.weight                                          loaded from backbone.body.layers.3.blocks.0.mlp.fc2.weight                                  of shape (768, 3072)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.norm1.bias                                              loaded from backbone.body.layers.3.blocks.0.norm1.bias                                      of shape (768,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.norm1.weight                                            loaded from backbone.body.layers.3.blocks.0.norm1.weight                                    of shape (768,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.norm2.bias                                              loaded from backbone.body.layers.3.blocks.0.norm2.bias                                      of shape (768,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.norm2.weight                                            loaded from backbone.body.layers.3.blocks.0.norm2.weight                                    of shape (768,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.proj.bias                                          loaded from backbone.body.layers.3.blocks.1.attn.proj.bias                                  of shape (768,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.proj.weight                                        loaded from backbone.body.layers.3.blocks.1.attn.proj.weight                                of shape (768, 768)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.qkv.bias                                           loaded from backbone.body.layers.3.blocks.1.attn.qkv.bias                                   of shape (2304,)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.qkv.weight                                         loaded from backbone.body.layers.3.blocks.1.attn.qkv.weight                                 of shape (2304, 768)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.relative_position_bias_table                       loaded from backbone.body.layers.3.blocks.1.attn.relative_position_bias_table               of shape (169, 24)
2024-03-19 03:13:44,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.relative_position_index                            loaded from backbone.body.layers.3.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.mlp.fc1.bias                                            loaded from backbone.body.layers.3.blocks.1.mlp.fc1.bias                                    of shape (3072,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.mlp.fc1.weight                                          loaded from backbone.body.layers.3.blocks.1.mlp.fc1.weight                                  of shape (3072, 768)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.mlp.fc2.bias                                            loaded from backbone.body.layers.3.blocks.1.mlp.fc2.bias                                    of shape (768,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.mlp.fc2.weight                                          loaded from backbone.body.layers.3.blocks.1.mlp.fc2.weight                                  of shape (768, 3072)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.norm1.bias                                              loaded from backbone.body.layers.3.blocks.1.norm1.bias                                      of shape (768,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.norm1.weight                                            loaded from backbone.body.layers.3.blocks.1.norm1.weight                                    of shape (768,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.norm2.bias                                              loaded from backbone.body.layers.3.blocks.1.norm2.bias                                      of shape (768,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.norm2.weight                                            loaded from backbone.body.layers.3.blocks.1.norm2.weight                                    of shape (768,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm1.bias                                                                loaded from backbone.body.norm1.bias                                                        of shape (192,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm1.weight                                                              loaded from backbone.body.norm1.weight                                                      of shape (192,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm2.bias                                                                loaded from backbone.body.norm2.bias                                                        of shape (384,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm2.weight                                                              loaded from backbone.body.norm2.weight                                                      of shape (384,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm3.bias                                                                loaded from backbone.body.norm3.bias                                                        of shape (768,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm3.weight                                                              loaded from backbone.body.norm3.weight                                                      of shape (768,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.patch_embed.norm.bias                                                     loaded from backbone.body.patch_embed.norm.bias                                             of shape (96,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.patch_embed.norm.weight                                                   loaded from backbone.body.patch_embed.norm.weight                                           of shape (96,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.patch_embed.proj.bias                                                     loaded from backbone.body.patch_embed.proj.bias                                             of shape (96,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.patch_embed.proj.weight                                                   loaded from backbone.body.patch_embed.proj.weight                                           of shape (96, 3, 4, 4)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                                                            loaded from backbone.fpn.fpn_inner2.bias                                                    of shape (256,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                                                          loaded from backbone.fpn.fpn_inner2.weight                                                  of shape (256, 192, 1, 1)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                                                            loaded from backbone.fpn.fpn_inner3.bias                                                    of shape (256,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                                                          loaded from backbone.fpn.fpn_inner3.weight                                                  of shape (256, 384, 1, 1)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                                                            loaded from backbone.fpn.fpn_inner4.bias                                                    of shape (256,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                                                          loaded from backbone.fpn.fpn_inner4.weight                                                  of shape (256, 768, 1, 1)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                                                            loaded from backbone.fpn.fpn_layer2.bias                                                    of shape (256,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                                                          loaded from backbone.fpn.fpn_layer2.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                                                            loaded from backbone.fpn.fpn_layer3.bias                                                    of shape (256,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                                                          loaded from backbone.fpn.fpn_layer3.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                                                            loaded from backbone.fpn.fpn_layer4.bias                                                    of shape (256,)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                                                          loaded from backbone.fpn.fpn_layer4.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 03:13:44,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.top_blocks.p6.bias                                                         loaded from backbone.fpn.top_blocks.p6.bias                                                 of shape (256,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.top_blocks.p6.weight                                                       loaded from backbone.fpn.top_blocks.p6.weight                                               of shape (256, 256, 3, 3)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.top_blocks.p7.bias                                                         loaded from backbone.fpn.top_blocks.p7.bias                                                 of shape (256,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.top_blocks.p7.weight                                                       loaded from backbone.fpn.top_blocks.p7.weight                                               of shape (256, 256, 3, 3)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.proj.bias                                  loaded from backbone.body.layers.0.blocks.0.attn.proj.bias                                  of shape (96,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.proj.weight                                loaded from backbone.body.layers.0.blocks.0.attn.proj.weight                                of shape (96, 96)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.qkv.bias                                   loaded from backbone.body.layers.0.blocks.0.attn.qkv.bias                                   of shape (288,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.qkv.weight                                 loaded from backbone.body.layers.0.blocks.0.attn.qkv.weight                                 of shape (288, 96)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.relative_position_bias_table               loaded from backbone.body.layers.0.blocks.0.attn.relative_position_bias_table               of shape (169, 3)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.relative_position_index                    loaded from backbone.body.layers.0.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.mlp.fc1.bias                                    loaded from backbone.body.layers.0.blocks.0.mlp.fc1.bias                                    of shape (384,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.mlp.fc1.weight                                  loaded from backbone.body.layers.0.blocks.0.mlp.fc1.weight                                  of shape (384, 96)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.mlp.fc2.bias                                    loaded from backbone.body.layers.0.blocks.0.mlp.fc2.bias                                    of shape (96,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.mlp.fc2.weight                                  loaded from backbone.body.layers.0.blocks.0.mlp.fc2.weight                                  of shape (96, 384)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.norm1.bias                                      loaded from backbone.body.layers.0.blocks.0.norm1.bias                                      of shape (96,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.norm1.weight                                    loaded from backbone.body.layers.0.blocks.0.norm1.weight                                    of shape (96,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.norm2.bias                                      loaded from backbone.body.layers.0.blocks.0.norm2.bias                                      of shape (96,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.norm2.weight                                    loaded from backbone.body.layers.0.blocks.0.norm2.weight                                    of shape (96,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.proj.bias                                  loaded from backbone.body.layers.0.blocks.1.attn.proj.bias                                  of shape (96,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.proj.weight                                loaded from backbone.body.layers.0.blocks.1.attn.proj.weight                                of shape (96, 96)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.qkv.bias                                   loaded from backbone.body.layers.0.blocks.1.attn.qkv.bias                                   of shape (288,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.qkv.weight                                 loaded from backbone.body.layers.0.blocks.1.attn.qkv.weight                                 of shape (288, 96)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.relative_position_bias_table               loaded from backbone.body.layers.0.blocks.1.attn.relative_position_bias_table               of shape (169, 3)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.relative_position_index                    loaded from backbone.body.layers.0.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.mlp.fc1.bias                                    loaded from backbone.body.layers.0.blocks.1.mlp.fc1.bias                                    of shape (384,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.mlp.fc1.weight                                  loaded from backbone.body.layers.0.blocks.1.mlp.fc1.weight                                  of shape (384, 96)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.mlp.fc2.bias                                    loaded from backbone.body.layers.0.blocks.1.mlp.fc2.bias                                    of shape (96,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.mlp.fc2.weight                                  loaded from backbone.body.layers.0.blocks.1.mlp.fc2.weight                                  of shape (96, 384)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.norm1.bias                                      loaded from backbone.body.layers.0.blocks.1.norm1.bias                                      of shape (96,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.norm1.weight                                    loaded from backbone.body.layers.0.blocks.1.norm1.weight                                    of shape (96,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.norm2.bias                                      loaded from backbone.body.layers.0.blocks.1.norm2.bias                                      of shape (96,)
2024-03-19 03:13:44,566 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.norm2.weight                                    loaded from backbone.body.layers.0.blocks.1.norm2.weight                                    of shape (96,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.downsample.norm.bias                                     loaded from backbone.body.layers.0.downsample.norm.bias                                     of shape (384,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.downsample.norm.weight                                   loaded from backbone.body.layers.0.downsample.norm.weight                                   of shape (384,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.downsample.reduction.weight                              loaded from backbone.body.layers.0.downsample.reduction.weight                              of shape (192, 384)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.proj.bias                                  loaded from backbone.body.layers.1.blocks.0.attn.proj.bias                                  of shape (192,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.proj.weight                                loaded from backbone.body.layers.1.blocks.0.attn.proj.weight                                of shape (192, 192)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.qkv.bias                                   loaded from backbone.body.layers.1.blocks.0.attn.qkv.bias                                   of shape (576,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.qkv.weight                                 loaded from backbone.body.layers.1.blocks.0.attn.qkv.weight                                 of shape (576, 192)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.relative_position_bias_table               loaded from backbone.body.layers.1.blocks.0.attn.relative_position_bias_table               of shape (169, 6)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.relative_position_index                    loaded from backbone.body.layers.1.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.mlp.fc1.bias                                    loaded from backbone.body.layers.1.blocks.0.mlp.fc1.bias                                    of shape (768,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.mlp.fc1.weight                                  loaded from backbone.body.layers.1.blocks.0.mlp.fc1.weight                                  of shape (768, 192)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.mlp.fc2.bias                                    loaded from backbone.body.layers.1.blocks.0.mlp.fc2.bias                                    of shape (192,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.mlp.fc2.weight                                  loaded from backbone.body.layers.1.blocks.0.mlp.fc2.weight                                  of shape (192, 768)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.norm1.bias                                      loaded from backbone.body.layers.1.blocks.0.norm1.bias                                      of shape (192,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.norm1.weight                                    loaded from backbone.body.layers.1.blocks.0.norm1.weight                                    of shape (192,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.norm2.bias                                      loaded from backbone.body.layers.1.blocks.0.norm2.bias                                      of shape (192,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.norm2.weight                                    loaded from backbone.body.layers.1.blocks.0.norm2.weight                                    of shape (192,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.proj.bias                                  loaded from backbone.body.layers.1.blocks.1.attn.proj.bias                                  of shape (192,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.proj.weight                                loaded from backbone.body.layers.1.blocks.1.attn.proj.weight                                of shape (192, 192)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.qkv.bias                                   loaded from backbone.body.layers.1.blocks.1.attn.qkv.bias                                   of shape (576,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.qkv.weight                                 loaded from backbone.body.layers.1.blocks.1.attn.qkv.weight                                 of shape (576, 192)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.relative_position_bias_table               loaded from backbone.body.layers.1.blocks.1.attn.relative_position_bias_table               of shape (169, 6)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.relative_position_index                    loaded from backbone.body.layers.1.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.mlp.fc1.bias                                    loaded from backbone.body.layers.1.blocks.1.mlp.fc1.bias                                    of shape (768,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.mlp.fc1.weight                                  loaded from backbone.body.layers.1.blocks.1.mlp.fc1.weight                                  of shape (768, 192)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.mlp.fc2.bias                                    loaded from backbone.body.layers.1.blocks.1.mlp.fc2.bias                                    of shape (192,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.mlp.fc2.weight                                  loaded from backbone.body.layers.1.blocks.1.mlp.fc2.weight                                  of shape (192, 768)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.norm1.bias                                      loaded from backbone.body.layers.1.blocks.1.norm1.bias                                      of shape (192,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.norm1.weight                                    loaded from backbone.body.layers.1.blocks.1.norm1.weight                                    of shape (192,)
2024-03-19 03:13:44,567 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.norm2.bias                                      loaded from backbone.body.layers.1.blocks.1.norm2.bias                                      of shape (192,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.norm2.weight                                    loaded from backbone.body.layers.1.blocks.1.norm2.weight                                    of shape (192,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.downsample.norm.bias                                     loaded from backbone.body.layers.1.downsample.norm.bias                                     of shape (768,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.downsample.norm.weight                                   loaded from backbone.body.layers.1.downsample.norm.weight                                   of shape (768,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.downsample.reduction.weight                              loaded from backbone.body.layers.1.downsample.reduction.weight                              of shape (384, 768)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.0.attn.proj.bias                                  of shape (384,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.0.attn.proj.weight                                of shape (384, 384)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.0.attn.qkv.bias                                   of shape (1152,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.0.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.0.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.0.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.0.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.0.mlp.fc2.bias                                    of shape (384,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.0.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.norm1.bias                                      loaded from backbone.body.layers.2.blocks.0.norm1.bias                                      of shape (384,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.norm1.weight                                    loaded from backbone.body.layers.2.blocks.0.norm1.weight                                    of shape (384,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.norm2.bias                                      loaded from backbone.body.layers.2.blocks.0.norm2.bias                                      of shape (384,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.norm2.weight                                    loaded from backbone.body.layers.2.blocks.0.norm2.weight                                    of shape (384,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.1.attn.proj.bias                                  of shape (384,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.1.attn.proj.weight                                of shape (384, 384)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.1.attn.qkv.bias                                   of shape (1152,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.1.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.1.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.1.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.1.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.1.mlp.fc2.bias                                    of shape (384,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.1.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.norm1.bias                                      loaded from backbone.body.layers.2.blocks.1.norm1.bias                                      of shape (384,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.norm1.weight                                    loaded from backbone.body.layers.2.blocks.1.norm1.weight                                    of shape (384,)
2024-03-19 03:13:44,568 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.norm2.bias                                      loaded from backbone.body.layers.2.blocks.1.norm2.bias                                      of shape (384,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.norm2.weight                                    loaded from backbone.body.layers.2.blocks.1.norm2.weight                                    of shape (384,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.2.attn.proj.bias                                  of shape (384,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.2.attn.proj.weight                                of shape (384, 384)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.2.attn.qkv.bias                                   of shape (1152,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.2.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.2.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.2.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.2.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.2.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.2.mlp.fc2.bias                                    of shape (384,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.2.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.norm1.bias                                      loaded from backbone.body.layers.2.blocks.2.norm1.bias                                      of shape (384,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.norm1.weight                                    loaded from backbone.body.layers.2.blocks.2.norm1.weight                                    of shape (384,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.norm2.bias                                      loaded from backbone.body.layers.2.blocks.2.norm2.bias                                      of shape (384,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.norm2.weight                                    loaded from backbone.body.layers.2.blocks.2.norm2.weight                                    of shape (384,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.3.attn.proj.bias                                  of shape (384,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.3.attn.proj.weight                                of shape (384, 384)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.3.attn.qkv.bias                                   of shape (1152,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.3.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.3.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.3.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.3.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.3.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.3.mlp.fc2.bias                                    of shape (384,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.3.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.norm1.bias                                      loaded from backbone.body.layers.2.blocks.3.norm1.bias                                      of shape (384,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.norm1.weight                                    loaded from backbone.body.layers.2.blocks.3.norm1.weight                                    of shape (384,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.norm2.bias                                      loaded from backbone.body.layers.2.blocks.3.norm2.bias                                      of shape (384,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.norm2.weight                                    loaded from backbone.body.layers.2.blocks.3.norm2.weight                                    of shape (384,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.4.attn.proj.bias                                  of shape (384,)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.4.attn.proj.weight                                of shape (384, 384)
2024-03-19 03:13:44,569 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.4.attn.qkv.bias                                   of shape (1152,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.4.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.4.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.4.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.4.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.4.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.4.mlp.fc2.bias                                    of shape (384,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.4.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.norm1.bias                                      loaded from backbone.body.layers.2.blocks.4.norm1.bias                                      of shape (384,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.norm1.weight                                    loaded from backbone.body.layers.2.blocks.4.norm1.weight                                    of shape (384,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.norm2.bias                                      loaded from backbone.body.layers.2.blocks.4.norm2.bias                                      of shape (384,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.norm2.weight                                    loaded from backbone.body.layers.2.blocks.4.norm2.weight                                    of shape (384,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.5.attn.proj.bias                                  of shape (384,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.5.attn.proj.weight                                of shape (384, 384)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.5.attn.qkv.bias                                   of shape (1152,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.5.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.5.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.5.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.5.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.5.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.5.mlp.fc2.bias                                    of shape (384,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.5.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.norm1.bias                                      loaded from backbone.body.layers.2.blocks.5.norm1.bias                                      of shape (384,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.norm1.weight                                    loaded from backbone.body.layers.2.blocks.5.norm1.weight                                    of shape (384,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.norm2.bias                                      loaded from backbone.body.layers.2.blocks.5.norm2.bias                                      of shape (384,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.norm2.weight                                    loaded from backbone.body.layers.2.blocks.5.norm2.weight                                    of shape (384,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.downsample.norm.bias                                     loaded from backbone.body.layers.2.downsample.norm.bias                                     of shape (1536,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.downsample.norm.weight                                   loaded from backbone.body.layers.2.downsample.norm.weight                                   of shape (1536,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.downsample.reduction.weight                              loaded from backbone.body.layers.2.downsample.reduction.weight                              of shape (768, 1536)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.proj.bias                                  loaded from backbone.body.layers.3.blocks.0.attn.proj.bias                                  of shape (768,)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.proj.weight                                loaded from backbone.body.layers.3.blocks.0.attn.proj.weight                                of shape (768, 768)
2024-03-19 03:13:44,570 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.qkv.bias                                   loaded from backbone.body.layers.3.blocks.0.attn.qkv.bias                                   of shape (2304,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.qkv.weight                                 loaded from backbone.body.layers.3.blocks.0.attn.qkv.weight                                 of shape (2304, 768)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.relative_position_bias_table               loaded from backbone.body.layers.3.blocks.0.attn.relative_position_bias_table               of shape (169, 24)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.relative_position_index                    loaded from backbone.body.layers.3.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.mlp.fc1.bias                                    loaded from backbone.body.layers.3.blocks.0.mlp.fc1.bias                                    of shape (3072,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.mlp.fc1.weight                                  loaded from backbone.body.layers.3.blocks.0.mlp.fc1.weight                                  of shape (3072, 768)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.mlp.fc2.bias                                    loaded from backbone.body.layers.3.blocks.0.mlp.fc2.bias                                    of shape (768,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.mlp.fc2.weight                                  loaded from backbone.body.layers.3.blocks.0.mlp.fc2.weight                                  of shape (768, 3072)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.norm1.bias                                      loaded from backbone.body.layers.3.blocks.0.norm1.bias                                      of shape (768,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.norm1.weight                                    loaded from backbone.body.layers.3.blocks.0.norm1.weight                                    of shape (768,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.norm2.bias                                      loaded from backbone.body.layers.3.blocks.0.norm2.bias                                      of shape (768,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.norm2.weight                                    loaded from backbone.body.layers.3.blocks.0.norm2.weight                                    of shape (768,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.proj.bias                                  loaded from backbone.body.layers.3.blocks.1.attn.proj.bias                                  of shape (768,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.proj.weight                                loaded from backbone.body.layers.3.blocks.1.attn.proj.weight                                of shape (768, 768)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.qkv.bias                                   loaded from backbone.body.layers.3.blocks.1.attn.qkv.bias                                   of shape (2304,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.qkv.weight                                 loaded from backbone.body.layers.3.blocks.1.attn.qkv.weight                                 of shape (2304, 768)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.relative_position_bias_table               loaded from backbone.body.layers.3.blocks.1.attn.relative_position_bias_table               of shape (169, 24)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.relative_position_index                    loaded from backbone.body.layers.3.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.mlp.fc1.bias                                    loaded from backbone.body.layers.3.blocks.1.mlp.fc1.bias                                    of shape (3072,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.mlp.fc1.weight                                  loaded from backbone.body.layers.3.blocks.1.mlp.fc1.weight                                  of shape (3072, 768)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.mlp.fc2.bias                                    loaded from backbone.body.layers.3.blocks.1.mlp.fc2.bias                                    of shape (768,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.mlp.fc2.weight                                  loaded from backbone.body.layers.3.blocks.1.mlp.fc2.weight                                  of shape (768, 3072)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.norm1.bias                                      loaded from backbone.body.layers.3.blocks.1.norm1.bias                                      of shape (768,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.norm1.weight                                    loaded from backbone.body.layers.3.blocks.1.norm1.weight                                    of shape (768,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.norm2.bias                                      loaded from backbone.body.layers.3.blocks.1.norm2.bias                                      of shape (768,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.norm2.weight                                    loaded from backbone.body.layers.3.blocks.1.norm2.weight                                    of shape (768,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm1.bias                                                        loaded from backbone.body.norm1.bias                                                        of shape (192,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm1.weight                                                      loaded from backbone.body.norm1.weight                                                      of shape (192,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm2.bias                                                        loaded from backbone.body.norm2.bias                                                        of shape (384,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm2.weight                                                      loaded from backbone.body.norm2.weight                                                      of shape (384,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm3.bias                                                        loaded from backbone.body.norm3.bias                                                        of shape (768,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm3.weight                                                      loaded from backbone.body.norm3.weight                                                      of shape (768,)
2024-03-19 03:13:44,571 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.patch_embed.norm.bias                                             loaded from backbone.body.patch_embed.norm.bias                                             of shape (96,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.patch_embed.norm.weight                                           loaded from backbone.body.patch_embed.norm.weight                                           of shape (96,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.patch_embed.proj.bias                                             loaded from backbone.body.patch_embed.proj.bias                                             of shape (96,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.patch_embed.proj.weight                                           loaded from backbone.body.patch_embed.proj.weight                                           of shape (96, 3, 4, 4)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner2.bias                                                    loaded from backbone.fpn.fpn_inner2.bias                                                    of shape (256,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner2.weight                                                  loaded from backbone.fpn.fpn_inner2.weight                                                  of shape (256, 192, 1, 1)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner3.bias                                                    loaded from backbone.fpn.fpn_inner3.bias                                                    of shape (256,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner3.weight                                                  loaded from backbone.fpn.fpn_inner3.weight                                                  of shape (256, 384, 1, 1)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner4.bias                                                    loaded from backbone.fpn.fpn_inner4.bias                                                    of shape (256,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner4.weight                                                  loaded from backbone.fpn.fpn_inner4.weight                                                  of shape (256, 768, 1, 1)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer2.bias                                                    loaded from backbone.fpn.fpn_layer2.bias                                                    of shape (256,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer2.weight                                                  loaded from backbone.fpn.fpn_layer2.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer3.bias                                                    loaded from backbone.fpn.fpn_layer3.bias                                                    of shape (256,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer3.weight                                                  loaded from backbone.fpn.fpn_layer3.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer4.bias                                                    loaded from backbone.fpn.fpn_layer4.bias                                                    of shape (256,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer4.weight                                                  loaded from backbone.fpn.fpn_layer4.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.top_blocks.p6.bias                                                 loaded from backbone.fpn.top_blocks.p6.bias                                                 of shape (256,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.top_blocks.p6.weight                                               loaded from backbone.fpn.top_blocks.p6.weight                                               of shape (256, 256, 3, 3)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.top_blocks.p7.bias                                                 loaded from backbone.fpn.top_blocks.p7.bias                                                 of shape (256,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.top_blocks.p7.weight                                               loaded from backbone.fpn.top_blocks.p7.weight                                               of shape (256, 256, 3, 3)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.embeddings.LayerNorm.bias                          loaded from language_backbone.body.model.embeddings.LayerNorm.bias                          of shape (768,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.embeddings.LayerNorm.weight                        loaded from language_backbone.body.model.embeddings.LayerNorm.weight                        of shape (768,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.embeddings.position_embeddings.weight              loaded from language_backbone.body.model.embeddings.position_embeddings.weight              of shape (512, 768)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.embeddings.token_type_embeddings.weight            loaded from language_backbone.body.model.embeddings.token_type_embeddings.weight            of shape (2, 768)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.embeddings.word_embeddings.weight                  loaded from language_backbone.body.model.embeddings.word_embeddings.weight                  of shape (30522, 768)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.0.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.0.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,572 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.0.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.0.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.0.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.0.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.0.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.0.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.0.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.0.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.0.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.0.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.0.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.0.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.1.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.1.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.1.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.1.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.1.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.1.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.1.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.1.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.1.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.1.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.1.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.1.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.1.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.1.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.bias   loaded from language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.bias   of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.weight loaded from language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.weight of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.output.dense.bias       loaded from language_backbone.body.model.encoder.layer.10.attention.output.dense.bias       of shape (768,)
2024-03-19 03:13:44,573 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.output.dense.weight     loaded from language_backbone.body.model.encoder.layer.10.attention.output.dense.weight     of shape (768, 768)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.key.bias           loaded from language_backbone.body.model.encoder.layer.10.attention.self.key.bias           of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.key.weight         loaded from language_backbone.body.model.encoder.layer.10.attention.self.key.weight         of shape (768, 768)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.query.bias         loaded from language_backbone.body.model.encoder.layer.10.attention.self.query.bias         of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.query.weight       loaded from language_backbone.body.model.encoder.layer.10.attention.self.query.weight       of shape (768, 768)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.value.bias         loaded from language_backbone.body.model.encoder.layer.10.attention.self.value.bias         of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.value.weight       loaded from language_backbone.body.model.encoder.layer.10.attention.self.value.weight       of shape (768, 768)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.intermediate.dense.bias           loaded from language_backbone.body.model.encoder.layer.10.intermediate.dense.bias           of shape (3072,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.intermediate.dense.weight         loaded from language_backbone.body.model.encoder.layer.10.intermediate.dense.weight         of shape (3072, 768)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.output.LayerNorm.bias             loaded from language_backbone.body.model.encoder.layer.10.output.LayerNorm.bias             of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.output.LayerNorm.weight           loaded from language_backbone.body.model.encoder.layer.10.output.LayerNorm.weight           of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.output.dense.bias                 loaded from language_backbone.body.model.encoder.layer.10.output.dense.bias                 of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.output.dense.weight               loaded from language_backbone.body.model.encoder.layer.10.output.dense.weight               of shape (768, 3072)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.bias   loaded from language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.bias   of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.weight loaded from language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.weight of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.output.dense.bias       loaded from language_backbone.body.model.encoder.layer.11.attention.output.dense.bias       of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.output.dense.weight     loaded from language_backbone.body.model.encoder.layer.11.attention.output.dense.weight     of shape (768, 768)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.key.bias           loaded from language_backbone.body.model.encoder.layer.11.attention.self.key.bias           of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.key.weight         loaded from language_backbone.body.model.encoder.layer.11.attention.self.key.weight         of shape (768, 768)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.query.bias         loaded from language_backbone.body.model.encoder.layer.11.attention.self.query.bias         of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.query.weight       loaded from language_backbone.body.model.encoder.layer.11.attention.self.query.weight       of shape (768, 768)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.value.bias         loaded from language_backbone.body.model.encoder.layer.11.attention.self.value.bias         of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.value.weight       loaded from language_backbone.body.model.encoder.layer.11.attention.self.value.weight       of shape (768, 768)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.intermediate.dense.bias           loaded from language_backbone.body.model.encoder.layer.11.intermediate.dense.bias           of shape (3072,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.intermediate.dense.weight         loaded from language_backbone.body.model.encoder.layer.11.intermediate.dense.weight         of shape (3072, 768)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.output.LayerNorm.bias             loaded from language_backbone.body.model.encoder.layer.11.output.LayerNorm.bias             of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.output.LayerNorm.weight           loaded from language_backbone.body.model.encoder.layer.11.output.LayerNorm.weight           of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.output.dense.bias                 loaded from language_backbone.body.model.encoder.layer.11.output.dense.bias                 of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.output.dense.weight               loaded from language_backbone.body.model.encoder.layer.11.output.dense.weight               of shape (768, 3072)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,574 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.2.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.2.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.2.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.2.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.2.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.2.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.2.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.2.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.2.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.2.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.2.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.2.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.2.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.2.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.3.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.3.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.3.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.3.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.3.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.3.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.3.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.3.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.3.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.3.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.3.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.3.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.3.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.3.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,575 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.4.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.4.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.4.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.4.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.4.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.4.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.4.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.4.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.4.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.4.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.4.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.4.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.4.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.4.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.5.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.5.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.5.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.5.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.5.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.5.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.5.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.5.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.5.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.5.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.5.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.5.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.5.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.5.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,576 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.6.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.6.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.6.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.6.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.6.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.6.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.6.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.6.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.6.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.6.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.6.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.6.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.6.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.6.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.7.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.7.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.7.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.7.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.7.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.7.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.7.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.7.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.7.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.7.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.7.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.7.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.7.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,577 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.7.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.8.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.8.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.8.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.8.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.8.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.8.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.8.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.8.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.8.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.8.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.8.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.8.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.8.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.8.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.9.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.9.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.9.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.9.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.9.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.9.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.9.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.9.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.9.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.9.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.9.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.9.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.9.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,578 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.9.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.embeddings.LayerNorm.bias                                  loaded from language_backbone.body.model.embeddings.LayerNorm.bias                          of shape (768,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.embeddings.LayerNorm.weight                                loaded from language_backbone.body.model.embeddings.LayerNorm.weight                        of shape (768,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.embeddings.position_embeddings.weight                      loaded from language_backbone.body.model.embeddings.position_embeddings.weight              of shape (512, 768)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.embeddings.token_type_embeddings.weight                    loaded from language_backbone.body.model.embeddings.token_type_embeddings.weight            of shape (2, 768)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.embeddings.word_embeddings.weight                          loaded from language_backbone.body.model.embeddings.word_embeddings.weight                  of shape (30522, 768)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.0.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.0.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.0.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.0.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.0.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.0.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.0.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.0.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.0.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.0.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.0.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.0.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.0.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.0.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.1.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.1.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.1.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,579 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.1.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.1.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.1.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.1.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.1.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.1.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.1.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.1.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.1.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.1.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.1.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.bias           loaded from language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.bias   of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.weight         loaded from language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.weight of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.output.dense.bias               loaded from language_backbone.body.model.encoder.layer.10.attention.output.dense.bias       of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.output.dense.weight             loaded from language_backbone.body.model.encoder.layer.10.attention.output.dense.weight     of shape (768, 768)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.key.bias                   loaded from language_backbone.body.model.encoder.layer.10.attention.self.key.bias           of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.key.weight                 loaded from language_backbone.body.model.encoder.layer.10.attention.self.key.weight         of shape (768, 768)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.query.bias                 loaded from language_backbone.body.model.encoder.layer.10.attention.self.query.bias         of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.query.weight               loaded from language_backbone.body.model.encoder.layer.10.attention.self.query.weight       of shape (768, 768)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.value.bias                 loaded from language_backbone.body.model.encoder.layer.10.attention.self.value.bias         of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.value.weight               loaded from language_backbone.body.model.encoder.layer.10.attention.self.value.weight       of shape (768, 768)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.intermediate.dense.bias                   loaded from language_backbone.body.model.encoder.layer.10.intermediate.dense.bias           of shape (3072,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.intermediate.dense.weight                 loaded from language_backbone.body.model.encoder.layer.10.intermediate.dense.weight         of shape (3072, 768)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.output.LayerNorm.bias                     loaded from language_backbone.body.model.encoder.layer.10.output.LayerNorm.bias             of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.output.LayerNorm.weight                   loaded from language_backbone.body.model.encoder.layer.10.output.LayerNorm.weight           of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.output.dense.bias                         loaded from language_backbone.body.model.encoder.layer.10.output.dense.bias                 of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.output.dense.weight                       loaded from language_backbone.body.model.encoder.layer.10.output.dense.weight               of shape (768, 3072)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.bias           loaded from language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.bias   of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.weight         loaded from language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.weight of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.output.dense.bias               loaded from language_backbone.body.model.encoder.layer.11.attention.output.dense.bias       of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.output.dense.weight             loaded from language_backbone.body.model.encoder.layer.11.attention.output.dense.weight     of shape (768, 768)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.key.bias                   loaded from language_backbone.body.model.encoder.layer.11.attention.self.key.bias           of shape (768,)
2024-03-19 03:13:44,580 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.key.weight                 loaded from language_backbone.body.model.encoder.layer.11.attention.self.key.weight         of shape (768, 768)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.query.bias                 loaded from language_backbone.body.model.encoder.layer.11.attention.self.query.bias         of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.query.weight               loaded from language_backbone.body.model.encoder.layer.11.attention.self.query.weight       of shape (768, 768)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.value.bias                 loaded from language_backbone.body.model.encoder.layer.11.attention.self.value.bias         of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.value.weight               loaded from language_backbone.body.model.encoder.layer.11.attention.self.value.weight       of shape (768, 768)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.intermediate.dense.bias                   loaded from language_backbone.body.model.encoder.layer.11.intermediate.dense.bias           of shape (3072,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.intermediate.dense.weight                 loaded from language_backbone.body.model.encoder.layer.11.intermediate.dense.weight         of shape (3072, 768)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.output.LayerNorm.bias                     loaded from language_backbone.body.model.encoder.layer.11.output.LayerNorm.bias             of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.output.LayerNorm.weight                   loaded from language_backbone.body.model.encoder.layer.11.output.LayerNorm.weight           of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.output.dense.bias                         loaded from language_backbone.body.model.encoder.layer.11.output.dense.bias                 of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.output.dense.weight                       loaded from language_backbone.body.model.encoder.layer.11.output.dense.weight               of shape (768, 3072)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.2.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.2.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.2.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.2.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.2.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.2.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.2.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.2.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.2.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.2.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.2.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.2.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.2.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.2.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.3.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.3.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,581 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.3.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.3.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.3.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.3.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.3.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.3.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.3.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.3.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.3.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.3.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.3.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.3.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.4.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.4.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.4.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.4.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.4.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.4.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.4.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.4.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.4.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.4.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.4.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.4.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.4.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.4.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.5.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.5.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,582 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.5.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.5.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.5.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.5.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.5.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.5.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.5.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.5.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.5.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.5.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.5.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.5.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.6.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.6.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.6.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.6.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.6.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.6.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.6.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.6.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.6.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.6.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.6.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.6.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.6.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.6.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.7.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.7.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,583 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.7.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.7.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.7.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.7.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.7.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.7.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.7.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.7.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.7.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.7.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.7.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.7.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.8.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.8.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.8.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.8.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.8.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.8.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.8.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.8.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.8.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.8.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.8.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.8.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.8.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.8.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.9.attention.output.dense.bias        of shape (768,)
2024-03-19 03:13:44,584 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.9.attention.output.dense.weight      of shape (768, 768)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.9.attention.self.key.bias            of shape (768,)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.9.attention.self.key.weight          of shape (768, 768)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.9.attention.self.query.bias          of shape (768,)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.9.attention.self.query.weight        of shape (768, 768)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.9.attention.self.value.bias          of shape (768,)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.9.attention.self.value.weight        of shape (768, 768)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.9.intermediate.dense.bias            of shape (3072,)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.9.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.9.output.LayerNorm.bias              of shape (768,)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.9.output.LayerNorm.weight            of shape (768,)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.9.output.dense.bias                  of shape (768,)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.9.output.dense.weight                of shape (768, 3072)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0                                                     loaded from rpn.anchor_generator.cell_anchors.0                                             of shape (1, 4)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1                                                     loaded from rpn.anchor_generator.cell_anchors.1                                             of shape (1, 4)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2                                                     loaded from rpn.anchor_generator.cell_anchors.2                                             of shape (1, 4)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3                                                     loaded from rpn.anchor_generator.cell_anchors.3                                             of shape (1, 4)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4                                                     loaded from rpn.anchor_generator.cell_anchors.4                                             of shape (1, 4)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                                                                 loaded from rpn.head.bbox_pred.bias                                                         of shape (4,)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                                                               loaded from rpn.head.bbox_pred.weight                                                       of shape (4, 256, 1, 1)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bias0                                                                          loaded from rpn.head.bias0                                                                  of shape (1,)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bias_lang                                                                      loaded from rpn.head.bias_lang                                                              of shape (768,)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.centerness.bias                                                                loaded from rpn.head.centerness.bias                                                        of shape (1,)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.centerness.weight                                                              loaded from rpn.head.centerness.weight                                                      of shape (1, 256, 1, 1)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                                                                loaded from rpn.head.cls_logits.bias                                                        of shape (80,)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                                                              loaded from rpn.head.cls_logits.weight                                                      of shape (80, 256, 1, 1)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dot_product_projection_text.bias                                               loaded from rpn.head.dot_product_projection_text.bias                                       of shape (256,)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dot_product_projection_text.weight                                             loaded from rpn.head.dot_product_projection_text.weight                                     of shape (256, 768)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.0.AttnConv.1.bias                                         of shape (1,)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.0.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.0.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,585 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.0.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.0.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.0.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.0.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.0.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.0.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.0.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.0.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.0.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.0.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.0.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.offset.bias                                                     loaded from rpn.head.dyhead_tower.0.offset.bias                                             of shape (27,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.offset.weight                                                   loaded from rpn.head.dyhead_tower.0.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.0.relu.fc.0.bias                                          of shape (64,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.0.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.0.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.0.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.1.AttnConv.1.bias                                         of shape (1,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.1.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.1.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.1.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.1.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.1.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.1.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.1.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.1.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.1.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.1.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.1.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.1.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.1.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,586 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.offset.bias                                                     loaded from rpn.head.dyhead_tower.1.offset.bias                                             of shape (27,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.offset.weight                                                   loaded from rpn.head.dyhead_tower.1.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.1.relu.fc.0.bias                                          of shape (64,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.1.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.1.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.1.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.2.AttnConv.1.bias                                         of shape (1,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.2.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.2.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.2.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.2.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.2.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.2.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.2.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.2.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.2.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.2.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.2.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.2.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.2.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.offset.bias                                                     loaded from rpn.head.dyhead_tower.2.offset.bias                                             of shape (27,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.offset.weight                                                   loaded from rpn.head.dyhead_tower.2.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.2.relu.fc.0.bias                                          of shape (64,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.2.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.2.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.2.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.3.AttnConv.1.bias                                         of shape (1,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.3.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.3.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.3.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.3.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.3.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,587 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.3.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.3.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.3.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.3.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.3.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.3.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.3.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.3.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.offset.bias                                                     loaded from rpn.head.dyhead_tower.3.offset.bias                                             of shape (27,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.offset.weight                                                   loaded from rpn.head.dyhead_tower.3.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.3.relu.fc.0.bias                                          of shape (64,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.3.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.3.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.3.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.4.AttnConv.1.bias                                         of shape (1,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.4.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.4.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.4.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.4.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.4.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.4.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.4.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.4.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.4.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.4.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.4.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.4.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.4.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.offset.bias                                                     loaded from rpn.head.dyhead_tower.4.offset.bias                                             of shape (27,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.offset.weight                                                   loaded from rpn.head.dyhead_tower.4.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.4.relu.fc.0.bias                                          of shape (64,)
2024-03-19 03:13:44,588 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.4.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.4.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.4.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.5.AttnConv.1.bias                                         of shape (1,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.5.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.5.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.5.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.5.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.5.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.5.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.5.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.5.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.5.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.5.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.5.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.5.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.5.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.offset.bias                                                     loaded from rpn.head.dyhead_tower.5.offset.bias                                             of shape (27,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.offset.weight                                                   loaded from rpn.head.dyhead_tower.5.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.5.relu.fc.0.bias                                          of shape (64,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.5.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.5.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.5.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.log_scale                                                                      loaded from rpn.head.log_scale                                                              of shape (1,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.scales.0.scale                                                                 loaded from rpn.head.scales.0.scale                                                         of shape (1,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.scales.1.scale                                                                 loaded from rpn.head.scales.1.scale                                                         of shape (1,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.scales.2.scale                                                                 loaded from rpn.head.scales.2.scale                                                         of shape (1,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.scales.3.scale                                                                 loaded from rpn.head.scales.3.scale                                                         of shape (1,)
2024-03-19 03:13:44,589 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.scales.4.scale                                                                 loaded from rpn.head.scales.4.scale                                                         of shape (1,)
2024-03-19 03:13:44,593 maskrcnn_benchmark.utils.model_serialization WARNING: Some layers unloaded with pre-trained weight: 
encoder.embeddings.LayerNorm.{bias, weight}
encoder.embeddings.position_embeddings.weight
encoder.embeddings.token_type_embeddings.weight
encoder.embeddings.word_embeddings.weight
encoder.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.0.attention.output.dense.{bias, weight}
encoder.encoder.layer.0.attention.self.key.{bias, weight}
encoder.encoder.layer.0.attention.self.query.{bias, weight}
encoder.encoder.layer.0.attention.self.value.{bias, weight}
encoder.encoder.layer.0.intermediate.dense.{bias, weight}
encoder.encoder.layer.0.output.LayerNorm.{bias, weight}
encoder.encoder.layer.0.output.dense.{bias, weight}
encoder.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.1.attention.output.dense.{bias, weight}
encoder.encoder.layer.1.attention.self.key.{bias, weight}
encoder.encoder.layer.1.attention.self.query.{bias, weight}
encoder.encoder.layer.1.attention.self.value.{bias, weight}
encoder.encoder.layer.1.intermediate.dense.{bias, weight}
encoder.encoder.layer.1.output.LayerNorm.{bias, weight}
encoder.encoder.layer.1.output.dense.{bias, weight}
encoder.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.10.attention.output.dense.{bias, weight}
encoder.encoder.layer.10.attention.self.key.{bias, weight}
encoder.encoder.layer.10.attention.self.query.{bias, weight}
encoder.encoder.layer.10.attention.self.value.{bias, weight}
encoder.encoder.layer.10.intermediate.dense.{bias, weight}
encoder.encoder.layer.10.output.LayerNorm.{bias, weight}
encoder.encoder.layer.10.output.dense.{bias, weight}
encoder.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.11.attention.output.dense.{bias, weight}
encoder.encoder.layer.11.attention.self.key.{bias, weight}
encoder.encoder.layer.11.attention.self.query.{bias, weight}
encoder.encoder.layer.11.attention.self.value.{bias, weight}
encoder.encoder.layer.11.intermediate.dense.{bias, weight}
encoder.encoder.layer.11.output.LayerNorm.{bias, weight}
encoder.encoder.layer.11.output.dense.{bias, weight}
encoder.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.2.attention.output.dense.{bias, weight}
encoder.encoder.layer.2.attention.self.key.{bias, weight}
encoder.encoder.layer.2.attention.self.query.{bias, weight}
encoder.encoder.layer.2.attention.self.value.{bias, weight}
encoder.encoder.layer.2.intermediate.dense.{bias, weight}
encoder.encoder.layer.2.output.LayerNorm.{bias, weight}
encoder.encoder.layer.2.output.dense.{bias, weight}
encoder.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.3.attention.output.dense.{bias, weight}
encoder.encoder.layer.3.attention.self.key.{bias, weight}
encoder.encoder.layer.3.attention.self.query.{bias, weight}
encoder.encoder.layer.3.attention.self.value.{bias, weight}
encoder.encoder.layer.3.intermediate.dense.{bias, weight}
encoder.encoder.layer.3.output.LayerNorm.{bias, weight}
encoder.encoder.layer.3.output.dense.{bias, weight}
encoder.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.4.attention.output.dense.{bias, weight}
encoder.encoder.layer.4.attention.self.key.{bias, weight}
encoder.encoder.layer.4.attention.self.query.{bias, weight}
encoder.encoder.layer.4.attention.self.value.{bias, weight}
encoder.encoder.layer.4.intermediate.dense.{bias, weight}
encoder.encoder.layer.4.output.LayerNorm.{bias, weight}
encoder.encoder.layer.4.output.dense.{bias, weight}
encoder.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.5.attention.output.dense.{bias, weight}
encoder.encoder.layer.5.attention.self.key.{bias, weight}
encoder.encoder.layer.5.attention.self.query.{bias, weight}
encoder.encoder.layer.5.attention.self.value.{bias, weight}
encoder.encoder.layer.5.intermediate.dense.{bias, weight}
encoder.encoder.layer.5.output.LayerNorm.{bias, weight}
encoder.encoder.layer.5.output.dense.{bias, weight}
encoder.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.6.attention.output.dense.{bias, weight}
encoder.encoder.layer.6.attention.self.key.{bias, weight}
encoder.encoder.layer.6.attention.self.query.{bias, weight}
encoder.encoder.layer.6.attention.self.value.{bias, weight}
encoder.encoder.layer.6.intermediate.dense.{bias, weight}
encoder.encoder.layer.6.output.LayerNorm.{bias, weight}
encoder.encoder.layer.6.output.dense.{bias, weight}
encoder.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.7.attention.output.dense.{bias, weight}
encoder.encoder.layer.7.attention.self.key.{bias, weight}
encoder.encoder.layer.7.attention.self.query.{bias, weight}
encoder.encoder.layer.7.attention.self.value.{bias, weight}
encoder.encoder.layer.7.intermediate.dense.{bias, weight}
encoder.encoder.layer.7.output.LayerNorm.{bias, weight}
encoder.encoder.layer.7.output.dense.{bias, weight}
encoder.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.8.attention.output.dense.{bias, weight}
encoder.encoder.layer.8.attention.self.key.{bias, weight}
encoder.encoder.layer.8.attention.self.query.{bias, weight}
encoder.encoder.layer.8.attention.self.value.{bias, weight}
encoder.encoder.layer.8.intermediate.dense.{bias, weight}
encoder.encoder.layer.8.output.LayerNorm.{bias, weight}
encoder.encoder.layer.8.output.dense.{bias, weight}
encoder.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.9.attention.output.dense.{bias, weight}
encoder.encoder.layer.9.attention.self.key.{bias, weight}
encoder.encoder.layer.9.attention.self.query.{bias, weight}
encoder.encoder.layer.9.attention.self.value.{bias, weight}
encoder.encoder.layer.9.intermediate.dense.{bias, weight}
encoder.encoder.layer.9.output.LayerNorm.{bias, weight}
encoder.encoder.layer.9.output.dense.{bias, weight}
encoder.fpn.fpn_inner2.{bias, weight}
encoder.fpn.fpn_inner3.{bias, weight}
encoder.fpn.fpn_inner4.{bias, weight}
encoder.fpn.fpn_layer2.{bias, weight}
encoder.fpn.fpn_layer3.{bias, weight}
encoder.fpn.fpn_layer4.{bias, weight}
encoder.fpn.top_blocks.p6.{bias, weight}
encoder.fpn.top_blocks.p7.{bias, weight}
encoder.language_backbone.body.embeddings.LayerNorm.{bias, weight}
encoder.language_backbone.body.embeddings.position_embeddings.weight
encoder.language_backbone.body.embeddings.token_type_embeddings.weight
encoder.language_backbone.body.embeddings.word_embeddings.weight
encoder.language_backbone.body.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.output.dense.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.embeddings.LayerNorm.{bias, weight}
encoder.language_encoder.embeddings.position_embeddings.weight
encoder.language_encoder.embeddings.token_type_embeddings.weight
encoder.language_encoder.embeddings.word_embeddings.weight
encoder.language_encoder.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.0.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.0.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.0.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.0.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.0.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.0.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.0.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.1.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.1.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.1.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.1.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.1.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.1.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.1.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.10.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.10.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.10.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.10.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.10.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.10.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.10.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.11.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.11.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.11.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.11.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.11.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.11.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.11.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.2.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.2.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.2.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.2.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.2.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.2.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.2.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.3.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.3.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.3.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.3.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.3.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.3.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.3.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.4.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.4.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.4.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.4.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.4.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.4.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.4.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.5.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.5.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.5.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.5.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.5.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.5.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.5.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.6.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.6.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.6.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.6.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.6.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.6.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.6.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.7.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.7.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.7.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.7.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.7.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.7.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.7.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.8.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.8.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.8.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.8.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.8.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.8.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.8.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.9.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.9.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.9.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.9.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.9.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.9.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.9.output.dense.{bias, weight}
encoder.language_encoder.model.embeddings.LayerNorm.{bias, weight}
encoder.language_encoder.model.embeddings.position_embeddings.weight
encoder.language_encoder.model.embeddings.token_type_embeddings.weight
encoder.language_encoder.model.embeddings.word_embeddings.weight
encoder.language_encoder.model.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.output.dense.{bias, weight}
encoder.layers.0.blocks.0.attn.proj.{bias, weight}
encoder.layers.0.blocks.0.attn.qkv.{bias, weight}
encoder.layers.0.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.0.blocks.0.mlp.fc1.{bias, weight}
encoder.layers.0.blocks.0.mlp.fc2.{bias, weight}
encoder.layers.0.blocks.0.norm1.{bias, weight}
encoder.layers.0.blocks.0.norm2.{bias, weight}
encoder.layers.0.blocks.1.attn.proj.{bias, weight}
encoder.layers.0.blocks.1.attn.qkv.{bias, weight}
encoder.layers.0.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.0.blocks.1.mlp.fc1.{bias, weight}
encoder.layers.0.blocks.1.mlp.fc2.{bias, weight}
encoder.layers.0.blocks.1.norm1.{bias, weight}
encoder.layers.0.blocks.1.norm2.{bias, weight}
encoder.layers.0.downsample.norm.{bias, weight}
encoder.layers.0.downsample.reduction.weight
encoder.layers.1.blocks.0.attn.proj.{bias, weight}
encoder.layers.1.blocks.0.attn.qkv.{bias, weight}
encoder.layers.1.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.1.blocks.0.mlp.fc1.{bias, weight}
encoder.layers.1.blocks.0.mlp.fc2.{bias, weight}
encoder.layers.1.blocks.0.norm1.{bias, weight}
encoder.layers.1.blocks.0.norm2.{bias, weight}
encoder.layers.1.blocks.1.attn.proj.{bias, weight}
encoder.layers.1.blocks.1.attn.qkv.{bias, weight}
encoder.layers.1.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.1.blocks.1.mlp.fc1.{bias, weight}
encoder.layers.1.blocks.1.mlp.fc2.{bias, weight}
encoder.layers.1.blocks.1.norm1.{bias, weight}
encoder.layers.1.blocks.1.norm2.{bias, weight}
encoder.layers.1.downsample.norm.{bias, weight}
encoder.layers.1.downsample.reduction.weight
encoder.layers.2.blocks.0.attn.proj.{bias, weight}
encoder.layers.2.blocks.0.attn.qkv.{bias, weight}
encoder.layers.2.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.0.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.0.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.0.norm1.{bias, weight}
encoder.layers.2.blocks.0.norm2.{bias, weight}
encoder.layers.2.blocks.1.attn.proj.{bias, weight}
encoder.layers.2.blocks.1.attn.qkv.{bias, weight}
encoder.layers.2.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.1.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.1.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.1.norm1.{bias, weight}
encoder.layers.2.blocks.1.norm2.{bias, weight}
encoder.layers.2.blocks.2.attn.proj.{bias, weight}
encoder.layers.2.blocks.2.attn.qkv.{bias, weight}
encoder.layers.2.blocks.2.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.2.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.2.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.2.norm1.{bias, weight}
encoder.layers.2.blocks.2.norm2.{bias, weight}
encoder.layers.2.blocks.3.attn.proj.{bias, weight}
encoder.layers.2.blocks.3.attn.qkv.{bias, weight}
encoder.layers.2.blocks.3.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.3.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.3.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.3.norm1.{bias, weight}
encoder.layers.2.blocks.3.norm2.{bias, weight}
encoder.layers.2.blocks.4.attn.proj.{bias, weight}
encoder.layers.2.blocks.4.attn.qkv.{bias, weight}
encoder.layers.2.blocks.4.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.4.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.4.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.4.norm1.{bias, weight}
encoder.layers.2.blocks.4.norm2.{bias, weight}
encoder.layers.2.blocks.5.attn.proj.{bias, weight}
encoder.layers.2.blocks.5.attn.qkv.{bias, weight}
encoder.layers.2.blocks.5.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.5.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.5.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.5.norm1.{bias, weight}
encoder.layers.2.blocks.5.norm2.{bias, weight}
encoder.layers.2.downsample.norm.{bias, weight}
encoder.layers.2.downsample.reduction.weight
encoder.layers.3.blocks.0.attn.proj.{bias, weight}
encoder.layers.3.blocks.0.attn.qkv.{bias, weight}
encoder.layers.3.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.3.blocks.0.mlp.fc1.{bias, weight}
encoder.layers.3.blocks.0.mlp.fc2.{bias, weight}
encoder.layers.3.blocks.0.norm1.{bias, weight}
encoder.layers.3.blocks.0.norm2.{bias, weight}
encoder.layers.3.blocks.1.attn.proj.{bias, weight}
encoder.layers.3.blocks.1.attn.qkv.{bias, weight}
encoder.layers.3.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.3.blocks.1.mlp.fc1.{bias, weight}
encoder.layers.3.blocks.1.mlp.fc2.{bias, weight}
encoder.layers.3.blocks.1.norm1.{bias, weight}
encoder.layers.3.blocks.1.norm2.{bias, weight}
encoder.model.embeddings.LayerNorm.{bias, weight}
encoder.model.embeddings.position_embeddings.weight
encoder.model.embeddings.token_type_embeddings.weight
encoder.model.embeddings.word_embeddings.weight
encoder.model.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.0.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.0.attention.self.key.{bias, weight}
encoder.model.encoder.layer.0.attention.self.query.{bias, weight}
encoder.model.encoder.layer.0.attention.self.value.{bias, weight}
encoder.model.encoder.layer.0.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.0.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.0.output.dense.{bias, weight}
encoder.model.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.1.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.1.attention.self.key.{bias, weight}
encoder.model.encoder.layer.1.attention.self.query.{bias, weight}
encoder.model.encoder.layer.1.attention.self.value.{bias, weight}
encoder.model.encoder.layer.1.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.1.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.1.output.dense.{bias, weight}
encoder.model.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.10.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.10.attention.self.key.{bias, weight}
encoder.model.encoder.layer.10.attention.self.query.{bias, weight}
encoder.model.encoder.layer.10.attention.self.value.{bias, weight}
encoder.model.encoder.layer.10.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.10.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.10.output.dense.{bias, weight}
encoder.model.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.11.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.11.attention.self.key.{bias, weight}
encoder.model.encoder.layer.11.attention.self.query.{bias, weight}
encoder.model.encoder.layer.11.attention.self.value.{bias, weight}
encoder.model.encoder.layer.11.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.11.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.11.output.dense.{bias, weight}
encoder.model.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.2.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.2.attention.self.key.{bias, weight}
encoder.model.encoder.layer.2.attention.self.query.{bias, weight}
encoder.model.encoder.layer.2.attention.self.value.{bias, weight}
encoder.model.encoder.layer.2.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.2.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.2.output.dense.{bias, weight}
encoder.model.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.3.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.3.attention.self.key.{bias, weight}
encoder.model.encoder.layer.3.attention.self.query.{bias, weight}
encoder.model.encoder.layer.3.attention.self.value.{bias, weight}
encoder.model.encoder.layer.3.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.3.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.3.output.dense.{bias, weight}
encoder.model.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.4.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.4.attention.self.key.{bias, weight}
encoder.model.encoder.layer.4.attention.self.query.{bias, weight}
encoder.model.encoder.layer.4.attention.self.value.{bias, weight}
encoder.model.encoder.layer.4.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.4.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.4.output.dense.{bias, weight}
encoder.model.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.5.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.5.attention.self.key.{bias, weight}
encoder.model.encoder.layer.5.attention.self.query.{bias, weight}
encoder.model.encoder.layer.5.attention.self.value.{bias, weight}
encoder.model.encoder.layer.5.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.5.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.5.output.dense.{bias, weight}
encoder.model.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.6.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.6.attention.self.key.{bias, weight}
encoder.model.encoder.layer.6.attention.self.query.{bias, weight}
encoder.model.encoder.layer.6.attention.self.value.{bias, weight}
encoder.model.encoder.layer.6.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.6.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.6.output.dense.{bias, weight}
encoder.model.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.7.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.7.attention.self.key.{bias, weight}
encoder.model.encoder.layer.7.attention.self.query.{bias, weight}
encoder.model.encoder.layer.7.attention.self.value.{bias, weight}
encoder.model.encoder.layer.7.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.7.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.7.output.dense.{bias, weight}
encoder.model.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.8.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.8.attention.self.key.{bias, weight}
encoder.model.encoder.layer.8.attention.self.query.{bias, weight}
encoder.model.encoder.layer.8.attention.self.value.{bias, weight}
encoder.model.encoder.layer.8.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.8.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.8.output.dense.{bias, weight}
encoder.model.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.9.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.9.attention.self.key.{bias, weight}
encoder.model.encoder.layer.9.attention.self.query.{bias, weight}
encoder.model.encoder.layer.9.attention.self.value.{bias, weight}
encoder.model.encoder.layer.9.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.9.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.9.output.dense.{bias, weight}
encoder.norm1.{bias, weight}
encoder.norm2.{bias, weight}
encoder.norm3.{bias, weight}
encoder.patch_embed.norm.{bias, weight}
encoder.patch_embed.proj.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.attn.proj.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.0.blocks.0.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.norm1.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.norm2.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.attn.proj.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.0.blocks.1.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.norm1.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.norm2.{bias, weight}
encoder.visual_encoder.layers.0.downsample.norm.{bias, weight}
encoder.visual_encoder.layers.0.downsample.reduction.weight
encoder.visual_encoder.layers.1.blocks.0.attn.proj.{bias, weight}
encoder.visual_encoder.layers.1.blocks.0.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.1.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.1.blocks.0.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.1.blocks.0.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.1.blocks.0.norm1.{bias, weight}
encoder.visual_encoder.layers.1.blocks.0.norm2.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.attn.proj.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.1.blocks.1.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.norm1.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.norm2.{bias, weight}
encoder.visual_encoder.layers.1.downsample.norm.{bias, weight}
encoder.visual_encoder.layers.1.downsample.reduction.weight
encoder.visual_encoder.layers.2.blocks.0.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.0.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.0.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.0.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.0.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.0.norm2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.1.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.norm2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.2.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.norm2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.3.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.norm2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.4.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.norm2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.5.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.norm2.{bias, weight}
encoder.visual_encoder.layers.2.downsample.norm.{bias, weight}
encoder.visual_encoder.layers.2.downsample.reduction.weight
encoder.visual_encoder.layers.3.blocks.0.attn.proj.{bias, weight}
encoder.visual_encoder.layers.3.blocks.0.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.3.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.3.blocks.0.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.3.blocks.0.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.3.blocks.0.norm1.{bias, weight}
encoder.visual_encoder.layers.3.blocks.0.norm2.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.attn.proj.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.3.blocks.1.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.norm1.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.norm2.{bias, weight}
encoder.visual_encoder.norm1.{bias, weight}
encoder.visual_encoder.norm2.{bias, weight}
encoder.visual_encoder.norm3.{bias, weight}
encoder.visual_encoder.patch_embed.norm.{bias, weight}
encoder.visual_encoder.patch_embed.proj.{bias, weight}
language_backbone.body.embeddings.LayerNorm.{bias, weight}
language_backbone.body.embeddings.position_embeddings.weight
language_backbone.body.embeddings.token_type_embeddings.weight
language_backbone.body.embeddings.word_embeddings.weight
language_backbone.body.encoder.interactModuleList.0.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.0.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.1.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.1.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.10.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.10.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.11.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.11.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.2.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.2.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.3.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.3.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.4.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.4.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.5.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.5.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.6.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.6.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.7.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.7.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.8.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.8.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.9.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.9.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.0.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.0.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.0.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.0.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.0.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.0.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.0.output.dense.{bias, weight}
language_backbone.body.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.1.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.1.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.1.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.1.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.1.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.1.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.1.output.dense.{bias, weight}
language_backbone.body.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.10.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.10.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.10.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.10.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.10.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.10.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.10.output.dense.{bias, weight}
language_backbone.body.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.11.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.11.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.11.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.11.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.11.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.11.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.11.output.dense.{bias, weight}
language_backbone.body.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.2.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.2.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.2.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.2.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.2.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.2.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.2.output.dense.{bias, weight}
language_backbone.body.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.3.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.3.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.3.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.3.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.3.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.3.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.3.output.dense.{bias, weight}
language_backbone.body.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.4.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.4.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.4.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.4.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.4.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.4.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.4.output.dense.{bias, weight}
language_backbone.body.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.5.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.5.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.5.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.5.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.5.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.5.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.5.output.dense.{bias, weight}
language_backbone.body.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.6.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.6.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.6.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.6.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.6.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.6.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.6.output.dense.{bias, weight}
language_backbone.body.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.7.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.7.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.7.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.7.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.7.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.7.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.7.output.dense.{bias, weight}
language_backbone.body.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.8.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.8.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.8.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.8.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.8.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.8.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.8.output.dense.{bias, weight}
language_backbone.body.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.9.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.9.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.9.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.9.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.9.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.9.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.9.output.dense.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.0.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.0.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.1.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.1.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.10.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.10.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.11.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.11.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.2.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.2.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.3.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.3.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.4.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.4.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.5.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.5.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.6.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.6.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.7.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.7.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.8.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.8.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.9.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.9.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
rpn.tunable_linear.weight
textual_prompt.0.{dim_1, dim_2, dim_3}
textual_prompt.1.{dim_1, dim_2, dim_3}
textual_prompt.10.{dim_1, dim_2, dim_3}
textual_prompt.11.{dim_1, dim_2, dim_3}
textual_prompt.2.{dim_1, dim_2, dim_3}
textual_prompt.3.{dim_1, dim_2, dim_3}
textual_prompt.4.{dim_1, dim_2, dim_3}
textual_prompt.5.{dim_1, dim_2, dim_3}
textual_prompt.6.{dim_1, dim_2, dim_3}
textual_prompt.7.{dim_1, dim_2, dim_3}
textual_prompt.8.{dim_1, dim_2, dim_3}
textual_prompt.9.{dim_1, dim_2, dim_3}
visual_prompt.0.{dim_1, dim_2, dim_3}
visual_prompt.1.{dim_1, dim_2, dim_3}
visual_prompt.10.{dim_1, dim_2, dim_3}
visual_prompt.11.{dim_1, dim_2, dim_3}
visual_prompt.2.{dim_1, dim_2, dim_3}
visual_prompt.3.{dim_1, dim_2, dim_3}
visual_prompt.4.{dim_1, dim_2, dim_3}
visual_prompt.5.{dim_1, dim_2, dim_3}
visual_prompt.6.{dim_1, dim_2, dim_3}
visual_prompt.7.{dim_1, dim_2, dim_3}
visual_prompt.8.{dim_1, dim_2, dim_3}
visual_prompt.9.{dim_1, dim_2, dim_3}
Backbone Freeze: True
FPN Freeze: True
RPN Freeze: True
Linear Probe: True
Language Freeze: True
Linear Layer (True Prmopt Tuning): True
High Level Override: language_prompt_v4
2024-03-19 03:13:46,414 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 03:13:46,415 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 03:13:46,415 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 03:13:46,415 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 03:13:46,415 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 03:13:46,415 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 03:13:46,415 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 03:13:46,415 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 03:13:46,415 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 03:13:46,415 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 03:13:46,416 maskrcnn_benchmark INFO: visual_prompt.0.dim_1 : Not Frozen, param number, 36
2024-03-19 03:13:46,416 maskrcnn_benchmark INFO: visual_prompt.0.dim_2 : Not Frozen, param number, 64
2024-03-19 03:13:46,416 maskrcnn_benchmark INFO: visual_prompt.0.dim_3 : Not Frozen, param number, 384
2024-03-19 03:13:46,416 maskrcnn_benchmark INFO: textual_prompt.0.dim_1 : Not Frozen, param number, 36
2024-03-19 03:13:46,416 maskrcnn_benchmark INFO: textual_prompt.0.dim_2 : Not Frozen, param number, 64
2024-03-19 03:13:46,416 maskrcnn_benchmark INFO: textual_prompt.0.dim_3 : Not Frozen, param number, 3072
2024-03-19 03:13:46,418 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 03:13:46,419 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.60s)
creating index...
index created!
2024-03-19 03:13:49,084 maskrcnn_benchmark INFO: Training on task 0: appliance, total training sample size: 804
refexp_train has the 804 data points RefExpDataset
Number of iterations are 251
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 03:13:49,284 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
2024-03-19 03:13:49,285 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  25
eta: 0:05:58  iter: 20  loss: 2.2120 (2.1770)  loss_reg: 0.2690 (0.2729)  loss_centerness: 0.4840 (0.4829)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4270 (1.4212)  time: 1.3340 (1.5534)  data: 0.0127 (0.2430)  lr: 0.010000  wd: 0.000500  max mem: 12747
eta: 0:05:13  iter: 40  loss: 1.9604 (2.0823)  loss_reg: 0.2606 (0.2745)  loss_centerness: 0.4828 (0.4840)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1981 (1.3238)  time: 1.2837 (1.4877)  data: 0.0113 (0.1845)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:04:38  iter: 60  loss: 1.8014 (1.9957)  loss_reg: 0.2839 (0.2784)  loss_centerness: 0.4847 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0337 (1.2331)  time: 1.2904 (1.4599)  data: 0.0112 (0.1638)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:04:07  iter: 80  loss: 1.8231 (1.9517)  loss_reg: 0.2758 (0.2812)  loss_centerness: 0.4843 (0.4847)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9999 (1.1858)  time: 1.2961 (1.4488)  data: 0.0114 (0.1540)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:03:39  iter: 100  loss: 1.7090 (1.9069)  loss_reg: 0.2714 (0.2801)  loss_centerness: 0.4805 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9714 (1.1426)  time: 1.3486 (1.4558)  data: 0.0133 (0.1497)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:03:10  iter: 120  loss: 1.7206 (1.8837)  loss_reg: 0.2821 (0.2802)  loss_centerness: 0.4838 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9656 (1.1193)  time: 1.3456 (1.4568)  data: 0.0129 (0.1474)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:02:41  iter: 140  loss: 1.7216 (1.8618)  loss_reg: 0.2690 (0.2798)  loss_centerness: 0.4834 (0.4840)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9713 (1.0980)  time: 1.2991 (1.4513)  data: 0.0115 (0.1446)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:02:12  iter: 160  loss: 1.7234 (1.8458)  loss_reg: 0.2868 (0.2808)  loss_centerness: 0.4854 (0.4843)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9409 (1.0807)  time: 1.3060 (1.4525)  data: 0.0124 (0.1428)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:01:43  iter: 180  loss: 1.6935 (1.8306)  loss_reg: 0.2724 (0.2801)  loss_centerness: 0.4825 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9437 (1.0662)  time: 1.2970 (1.4566)  data: 0.0114 (0.1487)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:01:14  iter: 200  loss: 1.6488 (1.8145)  loss_reg: 0.2643 (0.2795)  loss_centerness: 0.4820 (0.4840)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9055 (1.0510)  time: 1.3589 (1.4584)  data: 0.0130 (0.1473)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:00:45  iter: 220  loss: 1.7047 (1.8066)  loss_reg: 0.2733 (0.2796)  loss_centerness: 0.4824 (0.4841)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9261 (1.0429)  time: 1.3385 (1.4564)  data: 0.0125 (0.1457)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:00:16  iter: 240  loss: 1.6211 (1.7947)  loss_reg: 0.2778 (0.2798)  loss_centerness: 0.4849 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8722 (1.0308)  time: 1.2970 (1.4550)  data: 0.0130 (0.1459)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:00:00  iter: 251  loss: 1.6483 (1.7916)  loss_reg: 0.2861 (0.2807)  loss_centerness: 0.4856 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8922 (1.0267)  time: 1.2991 (1.4539)  data: 0.0124 (0.1453)  lr: 0.009045  wd: 0.000500  max mem: 12748
Evaluating
2024-03-19 03:20:39,536 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 03:20:47,560 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 03:20:47,564 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 03:20:47,597 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.5205479452054794, 0.6575342465753424] 

2024-03-19 03:20:47,597 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 03:20:47,597 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 03:20:47,597 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.5205479452054794, 0.6575342465753424], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 03:20:48,106 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 03:20:49,260 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 03:20:50,606 maskrcnn_benchmark.trainer INFO: Total training time: 0:07:01.308635 (1.6785 s / it)
2024-03-19 03:20:50,633 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 03:20:50,634 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 03:20:50,634 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 03:20:50,634 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 03:20:50,634 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 03:20:50,634 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 03:20:50,634 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 03:20:50,634 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 03:20:50,634 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 03:20:50,634 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 03:20:50,635 maskrcnn_benchmark INFO: visual_prompt.1.dim_1 : Not Frozen, param number, 36
2024-03-19 03:20:50,635 maskrcnn_benchmark INFO: visual_prompt.1.dim_2 : Not Frozen, param number, 64
2024-03-19 03:20:50,635 maskrcnn_benchmark INFO: visual_prompt.1.dim_3 : Not Frozen, param number, 384
2024-03-19 03:20:50,635 maskrcnn_benchmark INFO: textual_prompt.1.dim_1 : Not Frozen, param number, 36
2024-03-19 03:20:50,636 maskrcnn_benchmark INFO: textual_prompt.1.dim_2 : Not Frozen, param number, 64
2024-03-19 03:20:50,636 maskrcnn_benchmark INFO: textual_prompt.1.dim_3 : Not Frozen, param number, 3072
2024-03-19 03:20:50,638 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 03:20:50,639 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.80s)
creating index...
index created!
2024-03-19 03:20:53,253 maskrcnn_benchmark INFO: Training on task 1: sports, total training sample size: 853
refexp_train has the 853 data points RefExpDataset
Number of iterations are 266
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 03:20:53,443 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 03:20:53,622 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
2024-03-19 03:20:53,763 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  26
eta: 0:06:00  iter: 20  loss: 2.3182 (1.8321)  loss_reg: 0.3160 (0.2829)  loss_centerness: 0.4912 (0.4847)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3809 (1.0546)  time: 1.3612 (1.4652)  data: 0.0200 (0.1553)  task_loss: 0.1343 (0.1343)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:05:30  iter: 40  loss: 2.1459 (1.8531)  loss_reg: 0.3112 (0.2847)  loss_centerness: 0.4866 (0.4849)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1997 (1.0651)  time: 1.3697 (1.4638)  data: 0.0133 (0.1536)  task_loss: 0.1338 (0.1340)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:05:01  iter: 60  loss: 2.0573 (1.8651)  loss_reg: 0.3023 (0.2866)  loss_centerness: 0.4853 (0.4851)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0853 (1.0675)  time: 1.3779 (1.4616)  data: 0.0156 (0.1520)  task_loss: 0.1332 (0.1337)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:04:32  iter: 80  loss: 1.9756 (1.8735)  loss_reg: 0.2969 (0.2882)  loss_centerness: 0.4872 (0.4853)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0383 (1.0677)  time: 1.3658 (1.4627)  data: 0.0157 (0.1524)  task_loss: 0.1325 (0.1334)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:04:02  iter: 100  loss: 1.9503 (1.8787)  loss_reg: 0.2943 (0.2893)  loss_centerness: 0.4900 (0.4856)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0120 (1.0659)  time: 1.3623 (1.4605)  data: 0.0131 (0.1510)  task_loss: 0.1319 (0.1331)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:03:33  iter: 120  loss: 2.0112 (1.8853)  loss_reg: 0.3098 (0.2908)  loss_centerness: 0.4883 (0.4858)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0515 (1.0658)  time: 1.4059 (1.4599)  data: 0.0178 (0.1499)  task_loss: 0.1313 (0.1328)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:03:03  iter: 140  loss: 1.9224 (1.8871)  loss_reg: 0.2848 (0.2912)  loss_centerness: 0.4874 (0.4859)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9938 (1.0626)  time: 1.3708 (1.4598)  data: 0.0197 (0.1487)  task_loss: 0.1306 (0.1325)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:02:34  iter: 160  loss: 1.8996 (1.8878)  loss_reg: 0.2895 (0.2915)  loss_centerness: 0.4856 (0.4860)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9474 (1.0587)  time: 1.3924 (1.4599)  data: 0.0171 (0.1480)  task_loss: 0.1300 (0.1322)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:02:05  iter: 180  loss: 1.9089 (1.8910)  loss_reg: 0.3081 (0.2926)  loss_centerness: 0.4886 (0.4862)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9958 (1.0570)  time: 1.3674 (1.4589)  data: 0.0198 (0.1472)  task_loss: 0.1293 (0.1319)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:01:36  iter: 200  loss: 1.9269 (1.8924)  loss_reg: 0.3068 (0.2933)  loss_centerness: 0.4906 (0.4864)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9858 (1.0543)  time: 1.3693 (1.4580)  data: 0.0159 (0.1464)  task_loss: 0.1286 (0.1315)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:01:07  iter: 220  loss: 1.8923 (1.8937)  loss_reg: 0.3142 (0.2942)  loss_centerness: 0.4889 (0.4865)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9837 (1.0518)  time: 1.3640 (1.4583)  data: 0.0183 (0.1468)  task_loss: 0.1279 (0.1312)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:37  iter: 240  loss: 1.8901 (1.8952)  loss_reg: 0.3103 (0.2947)  loss_centerness: 0.4878 (0.4866)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9811 (1.0499)  time: 1.3815 (1.4581)  data: 0.0175 (0.1462)  task_loss: 0.1272 (0.1309)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:08  iter: 260  loss: 1.8407 (1.8944)  loss_reg: 0.2838 (0.2950)  loss_centerness: 0.4853 (0.4867)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9528 (1.0463)  time: 1.3698 (1.4572)  data: 0.0159 (0.1456)  task_loss: 0.1266 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:00  iter: 266  loss: 1.9232 (1.8949)  loss_reg: 0.3035 (0.2952)  loss_centerness: 0.4898 (0.4868)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0316 (1.0459)  time: 1.3918 (1.4576)  data: 0.0159 (0.1455)  task_loss: 0.1264 (0.1304)  lr: 0.000955  wd: 0.000500  max mem: 12749
Evaluating
2024-03-19 03:28:12,929 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 03:28:21,366 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 03:28:21,369 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 03:28:21,404 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.5205479452054794, 0.6575342465753424] 

2024-03-19 03:28:21,404 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 03:28:21,404 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 03:28:21,404 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.5205479452054794, 0.6575342465753424], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 03:28:21,420 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 03:28:26,076 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 03:28:26,079 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 03:28:26,092 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2222222222222222, 0.8518518518518519, 1.0] 

2024-03-19 03:28:26,092 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 03:28:26,092 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 03:28:26,092 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2222222222222222, 0.8518518518518519, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 03:28:26,142 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 03:28:27,298 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 03:28:28,488 maskrcnn_benchmark.trainer INFO: Total training time: 0:07:34.711621 (1.7094 s / it)
2024-03-19 03:28:28,510 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 03:28:28,510 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 03:28:28,510 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 03:28:28,510 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 03:28:28,510 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 03:28:28,510 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 03:28:28,510 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 03:28:28,510 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 03:28:28,510 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 03:28:28,510 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 03:28:28,511 maskrcnn_benchmark INFO: visual_prompt.2.dim_1 : Not Frozen, param number, 36
2024-03-19 03:28:28,511 maskrcnn_benchmark INFO: visual_prompt.2.dim_2 : Not Frozen, param number, 64
2024-03-19 03:28:28,511 maskrcnn_benchmark INFO: visual_prompt.2.dim_3 : Not Frozen, param number, 384
2024-03-19 03:28:28,512 maskrcnn_benchmark INFO: textual_prompt.2.dim_1 : Not Frozen, param number, 36
2024-03-19 03:28:28,512 maskrcnn_benchmark INFO: textual_prompt.2.dim_2 : Not Frozen, param number, 64
2024-03-19 03:28:28,512 maskrcnn_benchmark INFO: textual_prompt.2.dim_3 : Not Frozen, param number, 3072
2024-03-19 03:28:28,517 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 03:28:28,518 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.75s)
creating index...
index created!
2024-03-19 03:28:31,683 maskrcnn_benchmark INFO: Training on task 2: outdoor, total training sample size: 1063
refexp_train has the 1063 data points RefExpDataset
Number of iterations are 332
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 03:28:31,884 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 03:28:32,065 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 03:28:32,247 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
2024-03-19 03:28:32,405 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  33
eta: 0:07:35  iter: 20  loss: 2.0716 (1.9020)  loss_reg: 0.2784 (0.2949)  loss_centerness: 0.4810 (0.4866)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1571 (1.0511)  time: 1.4629 (1.4614)  data: 0.1282 (0.1486)  task_loss: 0.1283 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:07:06  iter: 40  loss: 1.8176 (1.9007)  loss_reg: 0.2670 (0.2942)  loss_centerness: 0.4815 (0.4864)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9660 (1.0486)  time: 1.4355 (1.4609)  data: 0.1277 (0.1480)  task_loss: 0.1283 (0.1302)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:06:37  iter: 60  loss: 1.8507 (1.8995)  loss_reg: 0.2770 (0.2939)  loss_centerness: 0.4811 (0.4863)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9217 (1.0458)  time: 1.4404 (1.4613)  data: 0.1286 (0.1483)  task_loss: 0.1283 (0.1301)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:06:08  iter: 80  loss: 1.8413 (1.8980)  loss_reg: 0.2804 (0.2935)  loss_centerness: 0.4834 (0.4862)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9362 (1.0429)  time: 1.4644 (1.4612)  data: 0.1295 (0.1478)  task_loss: 0.1282 (0.1299)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:05:38  iter: 100  loss: 1.8213 (1.8958)  loss_reg: 0.2850 (0.2932)  loss_centerness: 0.4811 (0.4861)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9314 (1.0395)  time: 1.4052 (1.4607)  data: 0.1220 (0.1473)  task_loss: 0.1282 (0.1299)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:05:09  iter: 120  loss: 1.7991 (1.8926)  loss_reg: 0.2776 (0.2928)  loss_centerness: 0.4823 (0.4860)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9111 (1.0351)  time: 1.4589 (1.4605)  data: 0.1353 (0.1469)  task_loss: 0.1282 (0.1298)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:04:40  iter: 140  loss: 1.7385 (1.8885)  loss_reg: 0.2652 (0.2923)  loss_centerness: 0.4824 (0.4859)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8562 (1.0302)  time: 1.4090 (1.4599)  data: 0.1197 (0.1470)  task_loss: 0.1281 (0.1297)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:04:11  iter: 160  loss: 1.8238 (1.8855)  loss_reg: 0.2756 (0.2921)  loss_centerness: 0.4844 (0.4858)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9082 (1.0260)  time: 1.4420 (1.4593)  data: 0.1273 (0.1465)  task_loss: 0.1281 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:03:41  iter: 180  loss: 1.7753 (1.8821)  loss_reg: 0.2830 (0.2918)  loss_centerness: 0.4818 (0.4857)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8603 (1.0217)  time: 1.4036 (1.4587)  data: 0.1273 (0.1460)  task_loss: 0.1280 (0.1295)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:03:12  iter: 200  loss: 1.7483 (1.8788)  loss_reg: 0.2757 (0.2915)  loss_centerness: 0.4814 (0.4856)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8572 (1.0175)  time: 1.4001 (1.4580)  data: 0.1159 (0.1462)  task_loss: 0.1280 (0.1295)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:02:43  iter: 220  loss: 1.6929 (1.8743)  loss_reg: 0.2764 (0.2912)  loss_centerness: 0.4819 (0.4856)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8106 (1.0122)  time: 1.4086 (1.4572)  data: 0.1181 (0.1457)  task_loss: 0.1279 (0.1294)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:02:13  iter: 240  loss: 1.7091 (1.8701)  loss_reg: 0.2724 (0.2908)  loss_centerness: 0.4816 (0.4855)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8210 (1.0073)  time: 1.4072 (1.4564)  data: 0.1205 (0.1452)  task_loss: 0.1279 (0.1293)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:01:44  iter: 260  loss: 1.7347 (1.8669)  loss_reg: 0.2716 (0.2904)  loss_centerness: 0.4818 (0.4854)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8561 (1.0036)  time: 1.3985 (1.4552)  data: 0.1160 (0.1447)  task_loss: 0.1278 (0.1293)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:01:15  iter: 280  loss: 1.7036 (1.8632)  loss_reg: 0.2821 (0.2904)  loss_centerness: 0.4831 (0.4853)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8049 (0.9989)  time: 1.4703 (1.4565)  data: 0.1289 (0.1457)  task_loss: 0.1278 (0.1292)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:46  iter: 300  loss: 1.7150 (1.8604)  loss_reg: 0.2727 (0.2901)  loss_centerness: 0.4818 (0.4853)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8335 (0.9955)  time: 1.4398 (1.4561)  data: 0.1245 (0.1454)  task_loss: 0.1278 (0.1292)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:17  iter: 320  loss: 1.7082 (1.8568)  loss_reg: 0.2694 (0.2899)  loss_centerness: 0.4823 (0.4852)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7906 (0.9912)  time: 1.3978 (1.4553)  data: 0.1215 (0.1450)  task_loss: 0.1277 (0.1291)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:00  iter: 332  loss: 1.7003 (1.8544)  loss_reg: 0.2645 (0.2897)  loss_centerness: 0.4806 (0.4852)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7976 (0.9886)  time: 1.3951 (1.4547)  data: 0.1195 (0.1447)  task_loss: 0.1277 (0.1291)  lr: 0.006545  wd: 0.000500  max mem: 12749
Evaluating
2024-03-19 03:37:32,823 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 03:37:41,439 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 03:37:41,443 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 03:37:41,473 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.5205479452054794, 0.6575342465753424] 

2024-03-19 03:37:41,473 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 03:37:41,473 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 03:37:41,474 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.5205479452054794, 0.6575342465753424], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 03:37:41,487 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 03:37:46,560 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 03:37:46,563 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 03:37:46,576 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2222222222222222, 0.8518518518518519, 1.0] 

2024-03-19 03:37:46,576 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 03:37:46,576 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 03:37:46,576 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2222222222222222, 0.8518518518518519, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 03:37:46,591 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 03:37:52,354 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 03:37:52,358 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 03:37:52,374 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3409090909090909, 0.5454545454545454, 0.7954545454545454] 

2024-03-19 03:37:52,374 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 03:37:52,374 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 03:37:52,374 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8181818181818182
evaluate on task refcoco, val, 2, res: {'refcoco': [0.3409090909090909, 0.5454545454545454, 0.7954545454545454], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 03:37:52,427 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 03:37:53,608 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 03:37:54,926 maskrcnn_benchmark.trainer INFO: Total training time: 0:09:22.507045 (1.6943 s / it)
2024-03-19 03:37:54,951 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 03:37:54,951 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 03:37:54,951 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 03:37:54,951 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 03:37:54,951 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 03:37:54,951 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 03:37:54,951 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 03:37:54,951 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 03:37:54,951 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 03:37:54,951 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 03:37:54,952 maskrcnn_benchmark INFO: visual_prompt.3.dim_1 : Not Frozen, param number, 36
2024-03-19 03:37:54,952 maskrcnn_benchmark INFO: visual_prompt.3.dim_2 : Not Frozen, param number, 64
2024-03-19 03:37:54,953 maskrcnn_benchmark INFO: visual_prompt.3.dim_3 : Not Frozen, param number, 384
2024-03-19 03:37:54,953 maskrcnn_benchmark INFO: textual_prompt.3.dim_1 : Not Frozen, param number, 36
2024-03-19 03:37:54,953 maskrcnn_benchmark INFO: textual_prompt.3.dim_2 : Not Frozen, param number, 64
2024-03-19 03:37:54,953 maskrcnn_benchmark INFO: textual_prompt.3.dim_3 : Not Frozen, param number, 3072
2024-03-19 03:37:54,955 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 03:37:54,955 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.92s)
creating index...
index created!
2024-03-19 03:37:57,776 maskrcnn_benchmark INFO: Training on task 3: electronic, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 03:37:57,989 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 03:37:58,170 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.06s)
creating index...
index created!
2024-03-19 03:37:59,352 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 03:37:59,538 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
2024-03-19 03:37:59,722 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:41  iter: 20  loss: 2.0951 (1.8597)  loss_reg: 0.1882 (0.2877)  loss_centerness: 0.4741 (0.4849)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2866 (0.9953)  time: 1.3739 (1.4572)  data: 0.0151 (0.1466)  task_loss: 0.1310 (0.1292)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:14:12  iter: 40  loss: 1.8858 (1.8600)  loss_reg: 0.1964 (0.2858)  loss_centerness: 0.4749 (0.4847)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0733 (0.9967)  time: 1.3634 (1.4565)  data: 0.0136 (0.1462)  task_loss: 0.1310 (0.1292)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:13:42  iter: 60  loss: 1.7242 (1.8574)  loss_reg: 0.1878 (0.2838)  loss_centerness: 0.4718 (0.4844)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9268 (0.9956)  time: 1.3509 (1.4557)  data: 0.0132 (0.1457)  task_loss: 0.1309 (0.1293)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:13:12  iter: 80  loss: 1.6034 (1.8524)  loss_reg: 0.1990 (0.2820)  loss_centerness: 0.4732 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8049 (0.9919)  time: 1.3472 (1.4550)  data: 0.0149 (0.1453)  task_loss: 0.1308 (0.1293)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:12:43  iter: 100  loss: 1.6492 (1.8480)  loss_reg: 0.1931 (0.2802)  loss_centerness: 0.4707 (0.4840)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8302 (0.9887)  time: 1.3451 (1.4540)  data: 0.0151 (0.1449)  task_loss: 0.1308 (0.1294)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:12:14  iter: 120  loss: 1.6128 (1.8437)  loss_reg: 0.2034 (0.2788)  loss_centerness: 0.4738 (0.4838)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8306 (0.9853)  time: 1.3833 (1.4541)  data: 0.0211 (0.1445)  task_loss: 0.1307 (0.1294)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:11:45  iter: 140  loss: 1.5289 (1.8388)  loss_reg: 0.1873 (0.2773)  loss_centerness: 0.4720 (0.4836)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7530 (0.9813)  time: 1.3909 (1.4544)  data: 0.0154 (0.1442)  task_loss: 0.1306 (0.1294)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:11:16  iter: 160  loss: 1.5487 (1.8337)  loss_reg: 0.2024 (0.2759)  loss_centerness: 0.4735 (0.4834)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7417 (0.9771)  time: 1.3692 (1.4539)  data: 0.0133 (0.1439)  task_loss: 0.1306 (0.1295)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:10:46  iter: 180  loss: 1.5515 (1.8289)  loss_reg: 0.1923 (0.2745)  loss_centerness: 0.4720 (0.4832)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7708 (0.9733)  time: 1.3628 (1.4537)  data: 0.0178 (0.1437)  task_loss: 0.1305 (0.1295)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:10:18  iter: 200  loss: 1.6121 (1.8245)  loss_reg: 0.1883 (0.2731)  loss_centerness: 0.4742 (0.4831)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7841 (0.9698)  time: 1.3792 (1.4544)  data: 0.0166 (0.1435)  task_loss: 0.1304 (0.1295)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:09:48  iter: 220  loss: 1.5067 (1.8194)  loss_reg: 0.2020 (0.2718)  loss_centerness: 0.4742 (0.4829)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7001 (0.9656)  time: 1.3356 (1.4536)  data: 0.0131 (0.1432)  task_loss: 0.1304 (0.1295)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:09:19  iter: 240  loss: 1.5372 (1.8145)  loss_reg: 0.1985 (0.2704)  loss_centerness: 0.4731 (0.4827)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7519 (0.9617)  time: 1.3781 (1.4532)  data: 0.0136 (0.1430)  task_loss: 0.1303 (0.1295)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:08:50  iter: 260  loss: 1.5237 (1.8097)  loss_reg: 0.1876 (0.2692)  loss_centerness: 0.4726 (0.4826)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7301 (0.9577)  time: 1.3586 (1.4532)  data: 0.0131 (0.1427)  task_loss: 0.1302 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:08:21  iter: 280  loss: 1.5088 (1.8051)  loss_reg: 0.2041 (0.2680)  loss_centerness: 0.4753 (0.4824)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7301 (0.9540)  time: 1.3587 (1.4534)  data: 0.0154 (0.1430)  task_loss: 0.1302 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:07:52  iter: 300  loss: 1.5174 (1.8005)  loss_reg: 0.1751 (0.2669)  loss_centerness: 0.4725 (0.4823)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6941 (0.9501)  time: 1.3121 (1.4526)  data: 0.0137 (0.1427)  task_loss: 0.1301 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:07:23  iter: 320  loss: 1.5542 (1.7963)  loss_reg: 0.1855 (0.2657)  loss_centerness: 0.4717 (0.4821)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7379 (0.9467)  time: 1.3625 (1.4528)  data: 0.0171 (0.1426)  task_loss: 0.1300 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:06:54  iter: 340  loss: 1.5224 (1.7925)  loss_reg: 0.1993 (0.2648)  loss_centerness: 0.4746 (0.4820)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7071 (0.9434)  time: 1.3908 (1.4532)  data: 0.0134 (0.1424)  task_loss: 0.1300 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:06:25  iter: 360  loss: 1.4668 (1.7877)  loss_reg: 0.1769 (0.2636)  loss_centerness: 0.4739 (0.4818)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6906 (0.9396)  time: 1.3490 (1.4529)  data: 0.0178 (0.1421)  task_loss: 0.1299 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:05:55  iter: 380  loss: 1.5471 (1.7838)  loss_reg: 0.1869 (0.2624)  loss_centerness: 0.4733 (0.4817)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7452 (0.9366)  time: 1.3692 (1.4525)  data: 0.0153 (0.1419)  task_loss: 0.1298 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:05:26  iter: 400  loss: 1.4969 (1.7799)  loss_reg: 0.1898 (0.2614)  loss_centerness: 0.4711 (0.4815)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7089 (0.9334)  time: 1.3883 (1.4526)  data: 0.0170 (0.1418)  task_loss: 0.1298 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:04:57  iter: 420  loss: 1.4765 (1.7763)  loss_reg: 0.2164 (0.2607)  loss_centerness: 0.4753 (0.4815)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6949 (0.9301)  time: 1.3538 (1.4526)  data: 0.0181 (0.1416)  task_loss: 0.1297 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:04:28  iter: 440  loss: 1.4507 (1.7722)  loss_reg: 0.1869 (0.2597)  loss_centerness: 0.4722 (0.4813)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6810 (0.9269)  time: 1.3745 (1.4522)  data: 0.0143 (0.1414)  task_loss: 0.1296 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:03:59  iter: 460  loss: 1.5498 (1.7687)  loss_reg: 0.1895 (0.2587)  loss_centerness: 0.4722 (0.4812)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7390 (0.9241)  time: 1.3879 (1.4524)  data: 0.0135 (0.1413)  task_loss: 0.1296 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:03:30  iter: 480  loss: 1.5064 (1.7653)  loss_reg: 0.1968 (0.2580)  loss_centerness: 0.4748 (0.4811)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7094 (0.9211)  time: 1.3686 (1.4522)  data: 0.0158 (0.1412)  task_loss: 0.1295 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:03:01  iter: 500  loss: 1.5323 (1.7618)  loss_reg: 0.1940 (0.2572)  loss_centerness: 0.4738 (0.4810)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7080 (0.9182)  time: 1.3655 (1.4526)  data: 0.0136 (0.1410)  task_loss: 0.1294 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:02:32  iter: 520  loss: 1.4958 (1.7587)  loss_reg: 0.2022 (0.2565)  loss_centerness: 0.4736 (0.4809)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6965 (0.9154)  time: 1.3782 (1.4525)  data: 0.0162 (0.1409)  task_loss: 0.1293 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:02:03  iter: 540  loss: 1.4890 (1.7550)  loss_reg: 0.1888 (0.2556)  loss_centerness: 0.4724 (0.4808)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6940 (0.9124)  time: 1.3637 (1.4525)  data: 0.0169 (0.1408)  task_loss: 0.1293 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:01:34  iter: 560  loss: 1.5687 (1.7527)  loss_reg: 0.2145 (0.2551)  loss_centerness: 0.4754 (0.4807)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7705 (0.9104)  time: 1.3996 (1.4526)  data: 0.0156 (0.1407)  task_loss: 0.1292 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:01:05  iter: 580  loss: 1.4545 (1.7489)  loss_reg: 0.1872 (0.2542)  loss_centerness: 0.4738 (0.4806)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6881 (0.9072)  time: 1.3629 (1.4530)  data: 0.0162 (0.1409)  task_loss: 0.1291 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:36  iter: 600  loss: 1.5376 (1.7460)  loss_reg: 0.2037 (0.2535)  loss_centerness: 0.4736 (0.4805)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7198 (0.9049)  time: 1.3608 (1.4534)  data: 0.0153 (0.1413)  task_loss: 0.1291 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:07  iter: 620  loss: 1.5104 (1.7427)  loss_reg: 0.1938 (0.2528)  loss_centerness: 0.4723 (0.4804)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6828 (0.9020)  time: 1.3643 (1.4534)  data: 0.0188 (0.1412)  task_loss: 0.1290 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:00  iter: 625  loss: 1.5392 (1.7423)  loss_reg: 0.2034 (0.2527)  loss_centerness: 0.4745 (0.4804)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7142 (0.9018)  time: 1.3643 (1.4532)  data: 0.0128 (0.1411)  task_loss: 0.1290 (0.1296)  lr: 0.000000  wd: 0.000500  max mem: 12749
Evaluating
2024-03-19 03:54:54,646 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 03:55:03,126 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 03:55:03,129 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 03:55:03,160 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.5205479452054794, 0.6575342465753424] 

2024-03-19 03:55:03,161 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 03:55:03,161 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 03:55:03,161 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9178082191780822
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.5205479452054794, 0.6575342465753424], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 03:55:03,175 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 03:55:07,652 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 03:55:07,656 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 03:55:07,669 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2962962962962963, 0.8888888888888888, 1.0] 

2024-03-19 03:55:07,669 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 03:55:07,669 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 03:55:07,669 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2962962962962963, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 03:55:07,686 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 03:55:14,152 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 03:55:14,155 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 03:55:14,172 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.36363636363636365, 0.5454545454545454, 0.75] 

2024-03-19 03:55:14,172 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 03:55:14,172 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 03:55:14,172 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6818181818181818
evaluate on task refcoco, val, 2, res: {'refcoco': [0.36363636363636365, 0.5454545454545454, 0.75], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 03:55:14,191 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 03:55:38,316 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 03:55:38,320 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 03:55:38,427 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.30196078431372547, 0.8156862745098039, 0.9215686274509803] 

2024-03-19 03:55:38,428 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 03:55:38,428 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 03:55:38,428 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9019607843137255
evaluate on task refcoco, val, 3, res: {'refcoco': [0.30196078431372547, 0.8156862745098039, 0.9215686274509803], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 03:55:38,478 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 03:55:39,712 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 03:55:41,018 maskrcnn_benchmark.trainer INFO: Total training time: 0:17:41.281847 (1.6981 s / it)
2024-03-19 03:55:41,043 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 03:55:41,043 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 03:55:41,043 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 03:55:41,043 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 03:55:41,043 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 03:55:41,043 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 03:55:41,043 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 03:55:41,043 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 03:55:41,043 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 03:55:41,043 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 03:55:41,044 maskrcnn_benchmark INFO: visual_prompt.4.dim_1 : Not Frozen, param number, 36
2024-03-19 03:55:41,044 maskrcnn_benchmark INFO: visual_prompt.4.dim_2 : Not Frozen, param number, 64
2024-03-19 03:55:41,045 maskrcnn_benchmark INFO: visual_prompt.4.dim_3 : Not Frozen, param number, 384
2024-03-19 03:55:41,045 maskrcnn_benchmark INFO: textual_prompt.4.dim_1 : Not Frozen, param number, 36
2024-03-19 03:55:41,045 maskrcnn_benchmark INFO: textual_prompt.4.dim_2 : Not Frozen, param number, 64
2024-03-19 03:55:41,045 maskrcnn_benchmark INFO: textual_prompt.4.dim_3 : Not Frozen, param number, 3072
2024-03-19 03:55:41,047 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 03:55:41,047 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=2.07s)
creating index...
index created!
2024-03-19 03:55:43,986 maskrcnn_benchmark INFO: Training on task 4: accessory, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 03:55:44,190 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 03:55:44,373 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 03:55:44,558 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.01s)
creating index...
index created!
2024-03-19 03:55:45,689 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 03:55:45,884 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
2024-03-19 03:55:46,086 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:39  iter: 20  loss: 2.2824 (1.7502)  loss_reg: 0.2489 (0.2525)  loss_centerness: 0.4784 (0.4804)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4007 (0.9095)  time: 1.4657 (1.4544)  data: 0.1338 (0.1422)  task_loss: 0.1320 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:14:10  iter: 40  loss: 2.0502 (1.7543)  loss_reg: 0.2468 (0.2524)  loss_centerness: 0.4790 (0.4804)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1772 (0.9135)  time: 1.4358 (1.4543)  data: 0.1300 (0.1420)  task_loss: 0.1319 (0.1296)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:13:41  iter: 60  loss: 1.9483 (1.7569)  loss_reg: 0.2200 (0.2520)  loss_centerness: 0.4778 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1212 (0.9160)  time: 1.3989 (1.4539)  data: 0.1221 (0.1418)  task_loss: 0.1319 (0.1297)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:12  iter: 80  loss: 1.8854 (1.7589)  loss_reg: 0.2351 (0.2519)  loss_centerness: 0.4770 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0385 (0.9179)  time: 1.4057 (1.4536)  data: 0.1248 (0.1416)  task_loss: 0.1319 (0.1297)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:42  iter: 100  loss: 1.9186 (1.7613)  loss_reg: 0.2363 (0.2518)  loss_centerness: 0.4760 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0774 (0.9201)  time: 1.4191 (1.4533)  data: 0.1309 (0.1415)  task_loss: 0.1318 (0.1297)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:14  iter: 120  loss: 1.8291 (1.7627)  loss_reg: 0.2205 (0.2514)  loss_centerness: 0.4800 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0111 (0.9216)  time: 1.4229 (1.4535)  data: 0.1244 (0.1413)  task_loss: 0.1318 (0.1298)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:44  iter: 140  loss: 1.8428 (1.7635)  loss_reg: 0.2163 (0.2512)  loss_centerness: 0.4770 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9796 (0.9224)  time: 1.3969 (1.4531)  data: 0.1161 (0.1411)  task_loss: 0.1318 (0.1298)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:15  iter: 160  loss: 1.8697 (1.7649)  loss_reg: 0.2257 (0.2510)  loss_centerness: 0.4773 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0163 (0.9237)  time: 1.4192 (1.4528)  data: 0.1343 (0.1410)  task_loss: 0.1317 (0.1298)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:46  iter: 180  loss: 1.8903 (1.7667)  loss_reg: 0.2334 (0.2509)  loss_centerness: 0.4790 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0424 (0.9254)  time: 1.4083 (1.4526)  data: 0.1252 (0.1408)  task_loss: 0.1317 (0.1299)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:17  iter: 200  loss: 1.7947 (1.7675)  loss_reg: 0.2114 (0.2505)  loss_centerness: 0.4770 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9709 (0.9264)  time: 1.4640 (1.4529)  data: 0.1299 (0.1411)  task_loss: 0.1317 (0.1299)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:48  iter: 220  loss: 1.8557 (1.7685)  loss_reg: 0.2482 (0.2505)  loss_centerness: 0.4799 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9855 (0.9271)  time: 1.4082 (1.4527)  data: 0.1163 (0.1409)  task_loss: 0.1317 (0.1299)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:19  iter: 240  loss: 1.8370 (1.7699)  loss_reg: 0.2328 (0.2504)  loss_centerness: 0.4794 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9839 (0.9284)  time: 1.4028 (1.4524)  data: 0.1201 (0.1407)  task_loss: 0.1316 (0.1299)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:50  iter: 260  loss: 1.8170 (1.7708)  loss_reg: 0.2359 (0.2503)  loss_centerness: 0.4789 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0059 (0.9292)  time: 1.4227 (1.4523)  data: 0.1280 (0.1406)  task_loss: 0.1316 (0.1300)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:21  iter: 280  loss: 1.8701 (1.7719)  loss_reg: 0.2369 (0.2501)  loss_centerness: 0.4784 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0102 (0.9302)  time: 1.4105 (1.4523)  data: 0.1252 (0.1408)  task_loss: 0.1316 (0.1300)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:51  iter: 300  loss: 1.7824 (1.7722)  loss_reg: 0.2177 (0.2499)  loss_centerness: 0.4784 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9439 (0.9305)  time: 1.4242 (1.4522)  data: 0.1292 (0.1407)  task_loss: 0.1316 (0.1300)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:22  iter: 320  loss: 1.8464 (1.7731)  loss_reg: 0.2435 (0.2499)  loss_centerness: 0.4769 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9885 (0.9312)  time: 1.4164 (1.4521)  data: 0.1292 (0.1406)  task_loss: 0.1315 (0.1300)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:53  iter: 340  loss: 1.8456 (1.7736)  loss_reg: 0.2287 (0.2497)  loss_centerness: 0.4780 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9779 (0.9317)  time: 1.4694 (1.4522)  data: 0.1293 (0.1405)  task_loss: 0.1315 (0.1300)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:24  iter: 360  loss: 1.8134 (1.7742)  loss_reg: 0.2340 (0.2496)  loss_centerness: 0.4781 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9577 (0.9322)  time: 1.4772 (1.4528)  data: 0.1395 (0.1408)  task_loss: 0.1315 (0.1301)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:55  iter: 380  loss: 1.7791 (1.7744)  loss_reg: 0.2183 (0.2494)  loss_centerness: 0.4758 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9402 (0.9324)  time: 1.4292 (1.4527)  data: 0.1299 (0.1407)  task_loss: 0.1314 (0.1301)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:26  iter: 400  loss: 1.8232 (1.7748)  loss_reg: 0.2431 (0.2493)  loss_centerness: 0.4775 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9549 (0.9327)  time: 1.4122 (1.4523)  data: 0.1243 (0.1405)  task_loss: 0.1314 (0.1301)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:57  iter: 420  loss: 1.8055 (1.7751)  loss_reg: 0.2367 (0.2492)  loss_centerness: 0.4802 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9334 (0.9329)  time: 1.4108 (1.4520)  data: 0.1230 (0.1404)  task_loss: 0.1314 (0.1301)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:28  iter: 440  loss: 1.7894 (1.7756)  loss_reg: 0.2291 (0.2491)  loss_centerness: 0.4796 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9432 (0.9333)  time: 1.4177 (1.4521)  data: 0.1244 (0.1403)  task_loss: 0.1313 (0.1301)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:59  iter: 460  loss: 1.7837 (1.7759)  loss_reg: 0.2243 (0.2489)  loss_centerness: 0.4771 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9362 (0.9336)  time: 1.4350 (1.4523)  data: 0.1305 (0.1402)  task_loss: 0.1313 (0.1301)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:30  iter: 480  loss: 1.7819 (1.7759)  loss_reg: 0.2330 (0.2488)  loss_centerness: 0.4810 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9439 (0.9335)  time: 1.4213 (1.4522)  data: 0.1290 (0.1401)  task_loss: 0.1313 (0.1301)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:01  iter: 500  loss: 1.7606 (1.7761)  loss_reg: 0.2277 (0.2487)  loss_centerness: 0.4767 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9496 (0.9337)  time: 1.4212 (1.4520)  data: 0.1280 (0.1400)  task_loss: 0.1313 (0.1302)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:32  iter: 520  loss: 1.8072 (1.7763)  loss_reg: 0.2226 (0.2485)  loss_centerness: 0.4786 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9203 (0.9340)  time: 1.4736 (1.4523)  data: 0.1314 (0.1399)  task_loss: 0.1312 (0.1302)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:03  iter: 540  loss: 1.7901 (1.7767)  loss_reg: 0.2450 (0.2485)  loss_centerness: 0.4791 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9444 (0.9342)  time: 1.4440 (1.4522)  data: 0.1261 (0.1398)  task_loss: 0.1312 (0.1302)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:34  iter: 560  loss: 1.7952 (1.7769)  loss_reg: 0.2240 (0.2483)  loss_centerness: 0.4776 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9347 (0.9344)  time: 1.4620 (1.4522)  data: 0.1285 (0.1398)  task_loss: 0.1312 (0.1302)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:05  iter: 580  loss: 1.7999 (1.7770)  loss_reg: 0.2297 (0.2482)  loss_centerness: 0.4781 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9373 (0.9344)  time: 1.4132 (1.4521)  data: 0.1296 (0.1397)  task_loss: 0.1312 (0.1302)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:36  iter: 600  loss: 1.7517 (1.7769)  loss_reg: 0.2462 (0.2481)  loss_centerness: 0.4787 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8909 (0.9343)  time: 1.4085 (1.4519)  data: 0.1191 (0.1395)  task_loss: 0.1311 (0.1302)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:07  iter: 620  loss: 1.7671 (1.7770)  loss_reg: 0.2397 (0.2480)  loss_centerness: 0.4762 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9135 (0.9344)  time: 1.4187 (1.4525)  data: 0.1286 (0.1401)  task_loss: 0.1311 (0.1302)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:00  iter: 625  loss: 1.7552 (1.7770)  loss_reg: 0.2358 (0.2480)  loss_centerness: 0.4776 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9169 (0.9344)  time: 1.3978 (1.4525)  data: 0.1157 (0.1400)  task_loss: 0.1311 (0.1302)  lr: 0.000000  wd: 0.000500  max mem: 12750
Evaluating
2024-03-19 04:12:40,041 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 04:12:49,324 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:12:49,331 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 04:12:49,373 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1506849315068493, 0.5205479452054794, 0.6575342465753424] 

2024-03-19 04:12:49,374 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:12:49,374 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:12:49,374 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9178082191780822
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1506849315068493, 0.5205479452054794, 0.6575342465753424], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:12:49,392 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 04:12:54,466 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:12:54,470 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 04:12:54,483 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2962962962962963, 0.8888888888888888, 1.0] 

2024-03-19 04:12:54,483 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:12:54,483 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:12:54,483 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2962962962962963, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:12:54,497 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 04:13:00,385 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:13:00,389 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 04:13:00,405 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3181818181818182, 0.5227272727272727, 0.7272727272727273] 

2024-03-19 04:13:00,406 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:13:00,406 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:13:00,406 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.3181818181818182, 0.5227272727272727, 0.7272727272727273], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:13:00,420 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 04:13:24,512 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:13:24,516 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 04:13:24,620 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2980392156862745, 0.8196078431372549, 0.9215686274509803] 

2024-03-19 04:13:24,621 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:13:24,621 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:13:24,621 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8784313725490196
evaluate on task refcoco, val, 3, res: {'refcoco': [0.2980392156862745, 0.8196078431372549, 0.9215686274509803], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:13:24,637 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 04:13:45,189 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:13:45,193 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 04:13:45,281 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2714285714285714, 0.7857142857142857, 0.9] 

2024-03-19 04:13:45,281 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:13:45,281 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:13:45,282 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9095238095238095
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2714285714285714, 0.7857142857142857, 0.9], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:13:45,335 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 04:13:46,723 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 04:13:47,921 maskrcnn_benchmark.trainer INFO: Total training time: 0:18:01.819925 (1.7309 s / it)
2024-03-19 04:13:47,947 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 04:13:47,947 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 04:13:47,947 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 04:13:47,948 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 04:13:47,948 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 04:13:47,948 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 04:13:47,948 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 04:13:47,948 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 04:13:47,948 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 04:13:47,948 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 04:13:47,949 maskrcnn_benchmark INFO: visual_prompt.5.dim_1 : Not Frozen, param number, 36
2024-03-19 04:13:47,949 maskrcnn_benchmark INFO: visual_prompt.5.dim_2 : Not Frozen, param number, 64
2024-03-19 04:13:47,949 maskrcnn_benchmark INFO: visual_prompt.5.dim_3 : Not Frozen, param number, 384
2024-03-19 04:13:47,949 maskrcnn_benchmark INFO: textual_prompt.5.dim_1 : Not Frozen, param number, 36
2024-03-19 04:13:47,949 maskrcnn_benchmark INFO: textual_prompt.5.dim_2 : Not Frozen, param number, 64
2024-03-19 04:13:47,949 maskrcnn_benchmark INFO: textual_prompt.5.dim_3 : Not Frozen, param number, 3072
2024-03-19 04:13:47,951 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 04:13:47,952 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=2.08s)
creating index...
index created!
2024-03-19 04:13:50,899 maskrcnn_benchmark INFO: Training on task 5: indoor, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 04:13:51,096 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.96s)
creating index...
index created!
2024-03-19 04:13:52,182 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 04:13:52,369 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 04:13:52,553 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 04:13:52,734 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 04:13:52,924 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
2024-03-19 04:13:53,145 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:39  iter: 20  loss: 2.1303 (1.7806)  loss_reg: 0.2291 (0.2479)  loss_centerness: 0.4783 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3079 (0.9379)  time: 1.4079 (1.4531)  data: 0.1198 (0.1408)  task_loss: 0.1333 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:14:10  iter: 40  loss: 2.0097 (1.7826)  loss_reg: 0.2357 (0.2478)  loss_centerness: 0.4778 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1450 (0.9398)  time: 1.4699 (1.4530)  data: 0.1343 (0.1407)  task_loss: 0.1333 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:41  iter: 60  loss: 1.8101 (1.7833)  loss_reg: 0.2207 (0.2476)  loss_centerness: 0.4783 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9911 (0.9405)  time: 1.4735 (1.4534)  data: 0.1293 (0.1410)  task_loss: 0.1333 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:12  iter: 80  loss: 1.8704 (1.7843)  loss_reg: 0.2402 (0.2476)  loss_centerness: 0.4804 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0349 (0.9414)  time: 1.4295 (1.4533)  data: 0.1206 (0.1409)  task_loss: 0.1333 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:42  iter: 100  loss: 1.7900 (1.7847)  loss_reg: 0.2140 (0.2474)  loss_centerness: 0.4758 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9811 (0.9418)  time: 1.4246 (1.4533)  data: 0.1324 (0.1408)  task_loss: 0.1333 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:13  iter: 120  loss: 1.8164 (1.7852)  loss_reg: 0.2278 (0.2473)  loss_centerness: 0.4775 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9661 (0.9423)  time: 1.4305 (1.4533)  data: 0.1290 (0.1407)  task_loss: 0.1333 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:44  iter: 140  loss: 1.8291 (1.7857)  loss_reg: 0.2404 (0.2472)  loss_centerness: 0.4798 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9820 (0.9427)  time: 1.4143 (1.4535)  data: 0.1288 (0.1406)  task_loss: 0.1333 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:15  iter: 160  loss: 1.8262 (1.7862)  loss_reg: 0.2302 (0.2472)  loss_centerness: 0.4769 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9776 (0.9431)  time: 1.4588 (1.4535)  data: 0.1334 (0.1405)  task_loss: 0.1333 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:46  iter: 180  loss: 1.8301 (1.7865)  loss_reg: 0.2325 (0.2470)  loss_centerness: 0.4777 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9827 (0.9434)  time: 1.4412 (1.4534)  data: 0.1276 (0.1405)  task_loss: 0.1333 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:17  iter: 200  loss: 1.7513 (1.7866)  loss_reg: 0.2294 (0.2469)  loss_centerness: 0.4782 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9310 (0.9435)  time: 1.4289 (1.4535)  data: 0.1297 (0.1404)  task_loss: 0.1332 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:48  iter: 220  loss: 1.7534 (1.7868)  loss_reg: 0.2177 (0.2468)  loss_centerness: 0.4760 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9151 (0.9437)  time: 1.4604 (1.4539)  data: 0.1258 (0.1404)  task_loss: 0.1332 (0.1306)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:19  iter: 240  loss: 1.8004 (1.7871)  loss_reg: 0.2384 (0.2466)  loss_centerness: 0.4775 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9586 (0.9440)  time: 1.4021 (1.4537)  data: 0.1198 (0.1403)  task_loss: 0.1332 (0.1306)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:50  iter: 260  loss: 1.7717 (1.7871)  loss_reg: 0.2488 (0.2467)  loss_centerness: 0.4792 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9260 (0.9439)  time: 1.3977 (1.4533)  data: 0.1164 (0.1402)  task_loss: 0.1332 (0.1306)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:21  iter: 280  loss: 1.8363 (1.7874)  loss_reg: 0.2372 (0.2466)  loss_centerness: 0.4788 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9838 (0.9442)  time: 1.4060 (1.4532)  data: 0.1255 (0.1401)  task_loss: 0.1332 (0.1306)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:52  iter: 300  loss: 1.7753 (1.7873)  loss_reg: 0.1931 (0.2463)  loss_centerness: 0.4751 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9405 (0.9443)  time: 1.4772 (1.4535)  data: 0.1300 (0.1403)  task_loss: 0.1332 (0.1307)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:23  iter: 320  loss: 1.8258 (1.7875)  loss_reg: 0.2410 (0.2462)  loss_centerness: 0.4786 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9558 (0.9443)  time: 1.4194 (1.4537)  data: 0.1264 (0.1405)  task_loss: 0.1332 (0.1307)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:54  iter: 340  loss: 1.7482 (1.7874)  loss_reg: 0.2048 (0.2461)  loss_centerness: 0.4754 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9083 (0.9444)  time: 1.4074 (1.4535)  data: 0.1209 (0.1404)  task_loss: 0.1332 (0.1307)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:25  iter: 360  loss: 1.7872 (1.7879)  loss_reg: 0.2415 (0.2461)  loss_centerness: 0.4799 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9402 (0.9447)  time: 1.4085 (1.4534)  data: 0.1228 (0.1403)  task_loss: 0.1332 (0.1307)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:56  iter: 380  loss: 1.7384 (1.7876)  loss_reg: 0.2263 (0.2459)  loss_centerness: 0.4778 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9032 (0.9444)  time: 1.4693 (1.4536)  data: 0.1315 (0.1403)  task_loss: 0.1331 (0.1307)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:27  iter: 400  loss: 1.7651 (1.7874)  loss_reg: 0.2273 (0.2458)  loss_centerness: 0.4790 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9267 (0.9442)  time: 1.4251 (1.4536)  data: 0.1258 (0.1402)  task_loss: 0.1331 (0.1308)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:57  iter: 420  loss: 1.8132 (1.7877)  loss_reg: 0.2441 (0.2458)  loss_centerness: 0.4772 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9444 (0.9444)  time: 1.4173 (1.4536)  data: 0.1292 (0.1402)  task_loss: 0.1331 (0.1308)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:28  iter: 440  loss: 1.7888 (1.7877)  loss_reg: 0.2315 (0.2457)  loss_centerness: 0.4790 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9300 (0.9444)  time: 1.4233 (1.4535)  data: 0.1308 (0.1401)  task_loss: 0.1331 (0.1308)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:59  iter: 460  loss: 1.7597 (1.7877)  loss_reg: 0.2218 (0.2456)  loss_centerness: 0.4762 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9203 (0.9443)  time: 1.4659 (1.4534)  data: 0.1310 (0.1400)  task_loss: 0.1331 (0.1308)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:30  iter: 480  loss: 1.7831 (1.7878)  loss_reg: 0.2255 (0.2456)  loss_centerness: 0.4768 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9542 (0.9444)  time: 1.4703 (1.4538)  data: 0.1303 (0.1402)  task_loss: 0.1331 (0.1308)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:01  iter: 500  loss: 1.7036 (1.7875)  loss_reg: 0.2175 (0.2455)  loss_centerness: 0.4788 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8447 (0.9441)  time: 1.4083 (1.4536)  data: 0.1183 (0.1401)  task_loss: 0.1331 (0.1309)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:32  iter: 520  loss: 1.7970 (1.7875)  loss_reg: 0.2430 (0.2455)  loss_centerness: 0.4803 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9291 (0.9440)  time: 1.4627 (1.4536)  data: 0.1282 (0.1401)  task_loss: 0.1331 (0.1309)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:03  iter: 540  loss: 1.7526 (1.7874)  loss_reg: 0.2238 (0.2453)  loss_centerness: 0.4756 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9310 (0.9440)  time: 1.4068 (1.4534)  data: 0.1205 (0.1400)  task_loss: 0.1330 (0.1309)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:34  iter: 560  loss: 1.7303 (1.7870)  loss_reg: 0.2288 (0.2452)  loss_centerness: 0.4774 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8681 (0.9435)  time: 1.4360 (1.4535)  data: 0.1347 (0.1401)  task_loss: 0.1330 (0.1309)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:05  iter: 580  loss: 1.8188 (1.7872)  loss_reg: 0.2273 (0.2452)  loss_centerness: 0.4767 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9348 (0.9437)  time: 1.4645 (1.4536)  data: 0.1299 (0.1401)  task_loss: 0.1330 (0.1309)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:36  iter: 600  loss: 1.7335 (1.7872)  loss_reg: 0.2394 (0.2451)  loss_centerness: 0.4791 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9036 (0.9436)  time: 1.4144 (1.4533)  data: 0.1208 (0.1400)  task_loss: 0.1330 (0.1310)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:07  iter: 620  loss: 1.7407 (1.7869)  loss_reg: 0.2268 (0.2450)  loss_centerness: 0.4765 (0.4796)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8999 (0.9434)  time: 1.4506 (1.4533)  data: 0.1313 (0.1400)  task_loss: 0.1330 (0.1310)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:00  iter: 625  loss: 1.7154 (1.7868)  loss_reg: 0.2269 (0.2450)  loss_centerness: 0.4775 (0.4796)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8756 (0.9433)  time: 1.4210 (1.4533)  data: 0.1313 (0.1399)  task_loss: 0.1330 (0.1310)  lr: 0.000000  wd: 0.000500  max mem: 12750
Evaluating
2024-03-19 04:30:55,700 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 04:31:04,310 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:31:04,314 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 04:31:04,350 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.4794520547945205, 0.6575342465753424] 

2024-03-19 04:31:04,351 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:31:04,351 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:31:04,351 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9178082191780822
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.4794520547945205, 0.6575342465753424], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:31:04,367 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 04:31:09,104 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:31:09,108 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 04:31:09,121 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2962962962962963, 0.8888888888888888, 1.0] 

2024-03-19 04:31:09,121 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:31:09,121 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:31:09,121 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2962962962962963, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:31:09,139 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 04:31:15,658 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:31:15,662 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 04:31:15,679 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3181818181818182, 0.5227272727272727, 0.7272727272727273] 

2024-03-19 04:31:15,680 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:31:15,680 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:31:15,680 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.3181818181818182, 0.5227272727272727, 0.7272727272727273], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:31:15,698 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 04:31:40,515 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:31:40,518 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 04:31:40,610 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3176470588235294, 0.8235294117647058, 0.9215686274509803] 

2024-03-19 04:31:40,610 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:31:40,610 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:31:40,610 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8784313725490196
evaluate on task refcoco, val, 3, res: {'refcoco': [0.3176470588235294, 0.8235294117647058, 0.9215686274509803], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:31:40,627 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 04:32:02,264 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:32:02,268 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 04:32:02,356 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2761904761904762, 0.8047619047619048, 0.9] 

2024-03-19 04:32:02,356 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:32:02,357 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:32:02,357 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9095238095238095
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2761904761904762, 0.8047619047619048, 0.9], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:32:02,375 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 04:32:31,612 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:32:31,616 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 04:32:31,725 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.23529411764705882, 0.7483660130718954, 0.8921568627450981] 

2024-03-19 04:32:31,725 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:32:31,725 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:32:31,725 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9248366013071896
evaluate on task refcoco, val, 5, res: {'refcoco': [0.23529411764705882, 0.7483660130718954, 0.8921568627450981], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:32:31,769 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 04:32:32,815 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 04:32:34,022 maskrcnn_benchmark.trainer INFO: Total training time: 0:18:40.863186 (1.7934 s / it)
2024-03-19 04:32:34,052 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 04:32:34,052 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 04:32:34,052 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 04:32:34,052 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 04:32:34,052 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 04:32:34,052 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 04:32:34,052 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 04:32:34,052 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 04:32:34,052 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 04:32:34,052 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 04:32:34,053 maskrcnn_benchmark INFO: visual_prompt.6.dim_1 : Not Frozen, param number, 36
2024-03-19 04:32:34,053 maskrcnn_benchmark INFO: visual_prompt.6.dim_2 : Not Frozen, param number, 64
2024-03-19 04:32:34,053 maskrcnn_benchmark INFO: visual_prompt.6.dim_3 : Not Frozen, param number, 384
2024-03-19 04:32:34,053 maskrcnn_benchmark INFO: textual_prompt.6.dim_1 : Not Frozen, param number, 36
2024-03-19 04:32:34,053 maskrcnn_benchmark INFO: textual_prompt.6.dim_2 : Not Frozen, param number, 64
2024-03-19 04:32:34,053 maskrcnn_benchmark INFO: textual_prompt.6.dim_3 : Not Frozen, param number, 3072
2024-03-19 04:32:34,056 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 04:32:34,056 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=2.16s)
creating index...
index created!
2024-03-19 04:32:37,067 maskrcnn_benchmark INFO: Training on task 6: kitchen, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 04:32:37,273 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 04:32:37,457 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 04:32:37,638 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 04:32:37,821 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 04:32:38,002 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.24s)
creating index...
index created!
2024-03-19 04:32:39,365 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 04:32:39,551 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
2024-03-19 04:32:39,810 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:39  iter: 20  loss: 1.8343 (1.7873)  loss_reg: 0.1746 (0.2445)  loss_centerness: 0.4691 (0.4796)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0477 (0.9442)  time: 1.3770 (1.4541)  data: 0.0172 (0.1406)  task_loss: 0.1341 (0.1310)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:14:10  iter: 40  loss: 1.7573 (1.7870)  loss_reg: 0.1708 (0.2440)  loss_centerness: 0.4677 (0.4795)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9719 (0.9445)  time: 1.3742 (1.4540)  data: 0.0164 (0.1405)  task_loss: 0.1341 (0.1310)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:41  iter: 60  loss: 1.6428 (1.7865)  loss_reg: 0.1834 (0.2435)  loss_centerness: 0.4701 (0.4794)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8584 (0.9443)  time: 1.3632 (1.4537)  data: 0.0193 (0.1404)  task_loss: 0.1341 (0.1310)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:12  iter: 80  loss: 1.6009 (1.7854)  loss_reg: 0.1736 (0.2430)  loss_centerness: 0.4685 (0.4793)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7994 (0.9437)  time: 1.3917 (1.4538)  data: 0.0135 (0.1403)  task_loss: 0.1341 (0.1311)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:43  iter: 100  loss: 1.6238 (1.7842)  loss_reg: 0.1718 (0.2425)  loss_centerness: 0.4698 (0.4793)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8273 (0.9429)  time: 1.3510 (1.4536)  data: 0.0148 (0.1402)  task_loss: 0.1341 (0.1311)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:13  iter: 120  loss: 1.6087 (1.7830)  loss_reg: 0.1769 (0.2421)  loss_centerness: 0.4701 (0.4792)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8379 (0.9421)  time: 1.3911 (1.4535)  data: 0.0160 (0.1402)  task_loss: 0.1341 (0.1311)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:45  iter: 140  loss: 1.6106 (1.7816)  loss_reg: 0.1734 (0.2416)  loss_centerness: 0.4701 (0.4791)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8218 (0.9411)  time: 1.3760 (1.4538)  data: 0.0142 (0.1402)  task_loss: 0.1341 (0.1311)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:15  iter: 160  loss: 1.5981 (1.7803)  loss_reg: 0.1692 (0.2411)  loss_centerness: 0.4699 (0.4791)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8222 (0.9403)  time: 1.3716 (1.4538)  data: 0.0177 (0.1401)  task_loss: 0.1341 (0.1312)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:46  iter: 180  loss: 1.5707 (1.7790)  loss_reg: 0.1721 (0.2407)  loss_centerness: 0.4685 (0.4790)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8046 (0.9394)  time: 1.3731 (1.4538)  data: 0.0228 (0.1401)  task_loss: 0.1340 (0.1312)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:17  iter: 200  loss: 1.5905 (1.7778)  loss_reg: 0.1822 (0.2403)  loss_centerness: 0.4675 (0.4789)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8140 (0.9386)  time: 1.3892 (1.4539)  data: 0.0171 (0.1400)  task_loss: 0.1340 (0.1312)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:48  iter: 220  loss: 1.5943 (1.7766)  loss_reg: 0.1678 (0.2399)  loss_centerness: 0.4708 (0.4789)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8157 (0.9378)  time: 1.3984 (1.4540)  data: 0.0162 (0.1399)  task_loss: 0.1340 (0.1312)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:19  iter: 240  loss: 1.5335 (1.7751)  loss_reg: 0.1684 (0.2395)  loss_centerness: 0.4698 (0.4788)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7721 (0.9367)  time: 1.3685 (1.4541)  data: 0.0182 (0.1399)  task_loss: 0.1340 (0.1312)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:50  iter: 260  loss: 1.5369 (1.7736)  loss_reg: 0.1658 (0.2390)  loss_centerness: 0.4679 (0.4787)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7464 (0.9356)  time: 1.3697 (1.4541)  data: 0.0159 (0.1399)  task_loss: 0.1340 (0.1313)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:21  iter: 280  loss: 1.5369 (1.7722)  loss_reg: 0.1792 (0.2387)  loss_centerness: 0.4699 (0.4787)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7680 (0.9345)  time: 1.3580 (1.4540)  data: 0.0133 (0.1398)  task_loss: 0.1340 (0.1313)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:52  iter: 300  loss: 1.5173 (1.7706)  loss_reg: 0.1622 (0.2382)  loss_centerness: 0.4701 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7515 (0.9334)  time: 1.4209 (1.4542)  data: 0.0141 (0.1397)  task_loss: 0.1340 (0.1313)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:23  iter: 320  loss: 1.5945 (1.7695)  loss_reg: 0.1827 (0.2378)  loss_centerness: 0.4689 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8243 (0.9326)  time: 1.3589 (1.4541)  data: 0.0155 (0.1396)  task_loss: 0.1340 (0.1313)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:54  iter: 340  loss: 1.5260 (1.7682)  loss_reg: 0.1835 (0.2374)  loss_centerness: 0.4702 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7573 (0.9316)  time: 1.3852 (1.4541)  data: 0.0135 (0.1396)  task_loss: 0.1340 (0.1313)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:25  iter: 360  loss: 1.5635 (1.7669)  loss_reg: 0.1767 (0.2371)  loss_centerness: 0.4692 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7645 (0.9306)  time: 1.3609 (1.4540)  data: 0.0159 (0.1395)  task_loss: 0.1340 (0.1314)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:56  iter: 380  loss: 1.5203 (1.7655)  loss_reg: 0.1714 (0.2367)  loss_centerness: 0.4706 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7493 (0.9296)  time: 1.3677 (1.4539)  data: 0.0146 (0.1395)  task_loss: 0.1340 (0.1314)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:27  iter: 400  loss: 1.5854 (1.7643)  loss_reg: 0.1796 (0.2363)  loss_centerness: 0.4717 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7972 (0.9288)  time: 1.3757 (1.4541)  data: 0.0180 (0.1396)  task_loss: 0.1340 (0.1314)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:58  iter: 420  loss: 1.5096 (1.7628)  loss_reg: 0.1645 (0.2359)  loss_centerness: 0.4667 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7394 (0.9276)  time: 1.3932 (1.4541)  data: 0.0166 (0.1396)  task_loss: 0.1339 (0.1314)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:29  iter: 440  loss: 1.5483 (1.7615)  loss_reg: 0.1844 (0.2356)  loss_centerness: 0.4689 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7695 (0.9266)  time: 1.3809 (1.4541)  data: 0.0192 (0.1395)  task_loss: 0.1339 (0.1314)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:59  iter: 460  loss: 1.5210 (1.7600)  loss_reg: 0.1668 (0.2352)  loss_centerness: 0.4689 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7568 (0.9255)  time: 1.4282 (1.4541)  data: 0.0157 (0.1395)  task_loss: 0.1339 (0.1315)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:30  iter: 480  loss: 1.5555 (1.7587)  loss_reg: 0.1670 (0.2348)  loss_centerness: 0.4683 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7509 (0.9245)  time: 1.4021 (1.4542)  data: 0.0151 (0.1394)  task_loss: 0.1339 (0.1315)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:01  iter: 500  loss: 1.5447 (1.7574)  loss_reg: 0.1748 (0.2345)  loss_centerness: 0.4705 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7633 (0.9236)  time: 1.3684 (1.4541)  data: 0.0150 (0.1393)  task_loss: 0.1339 (0.1315)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:32  iter: 520  loss: 1.5194 (1.7560)  loss_reg: 0.1573 (0.2341)  loss_centerness: 0.4678 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7696 (0.9226)  time: 1.3736 (1.4541)  data: 0.0132 (0.1393)  task_loss: 0.1339 (0.1315)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:03  iter: 540  loss: 1.5242 (1.7548)  loss_reg: 0.1785 (0.2338)  loss_centerness: 0.4685 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7620 (0.9217)  time: 1.3973 (1.4541)  data: 0.0135 (0.1392)  task_loss: 0.1339 (0.1315)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:34  iter: 560  loss: 1.5570 (1.7536)  loss_reg: 0.1656 (0.2335)  loss_centerness: 0.4704 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7938 (0.9208)  time: 1.4062 (1.4542)  data: 0.0147 (0.1392)  task_loss: 0.1339 (0.1315)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:05  iter: 580  loss: 1.5249 (1.7523)  loss_reg: 0.1778 (0.2332)  loss_centerness: 0.4700 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7303 (0.9197)  time: 1.4003 (1.4542)  data: 0.0149 (0.1391)  task_loss: 0.1339 (0.1315)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:36  iter: 600  loss: 1.5100 (1.7510)  loss_reg: 0.1704 (0.2328)  loss_centerness: 0.4697 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7346 (0.9188)  time: 1.3656 (1.4542)  data: 0.0136 (0.1391)  task_loss: 0.1339 (0.1316)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:07  iter: 620  loss: 1.5387 (1.7499)  loss_reg: 0.1721 (0.2325)  loss_centerness: 0.4683 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7549 (0.9180)  time: 1.3512 (1.4541)  data: 0.0168 (0.1390)  task_loss: 0.1339 (0.1316)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:00  iter: 625  loss: 1.5319 (1.7496)  loss_reg: 0.1587 (0.2324)  loss_centerness: 0.4675 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7549 (0.9177)  time: 1.3512 (1.4541)  data: 0.0145 (0.1390)  task_loss: 0.1339 (0.1316)  lr: 0.000000  wd: 0.000500  max mem: 12750
Evaluating
2024-03-19 04:49:38,838 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 04:49:47,130 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:49:47,133 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 04:49:47,165 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.4931506849315068, 0.6438356164383562] 

2024-03-19 04:49:47,165 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:49:47,165 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:49:47,165 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9178082191780822
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.4931506849315068, 0.6438356164383562], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:49:47,179 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 04:49:51,445 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:49:51,449 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 04:49:51,462 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2222222222222222, 0.8888888888888888, 1.0] 

2024-03-19 04:49:51,462 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:49:51,462 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:49:51,462 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2222222222222222, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:49:51,478 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 04:49:58,009 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:49:58,013 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 04:49:58,029 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2727272727272727, 0.5227272727272727, 0.7272727272727273] 

2024-03-19 04:49:58,030 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:49:58,030 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:49:58,030 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.2727272727272727, 0.5227272727272727, 0.7272727272727273], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:49:58,044 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 04:50:22,162 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:50:22,166 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 04:50:22,279 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3176470588235294, 0.8274509803921568, 0.9215686274509803] 

2024-03-19 04:50:22,279 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:50:22,279 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:50:22,279 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8784313725490196
evaluate on task refcoco, val, 3, res: {'refcoco': [0.3176470588235294, 0.8274509803921568, 0.9215686274509803], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:50:22,296 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 04:50:42,871 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:50:42,874 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 04:50:42,948 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2761904761904762, 0.8, 0.8857142857142857] 

2024-03-19 04:50:42,948 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:50:42,948 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:50:42,949 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9095238095238095
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2761904761904762, 0.8, 0.8857142857142857], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:50:42,963 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 04:51:11,905 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:51:11,908 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 04:51:12,039 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.23202614379084968, 0.7483660130718954, 0.8823529411764706] 

2024-03-19 04:51:12,039 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:51:12,039 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:51:12,039 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8954248366013072
evaluate on task refcoco, val, 5, res: {'refcoco': [0.23202614379084968, 0.7483660130718954, 0.8823529411764706], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:51:12,056 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 04:51:55,805 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 04:51:55,809 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 04:51:55,948 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.339662447257384, 0.919831223628692, 0.9704641350210971] 

2024-03-19 04:51:55,948 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 04:51:55,949 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 04:51:55,949 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9430379746835443
evaluate on task refcoco, val, 6, res: {'refcoco': [0.339662447257384, 0.919831223628692, 0.9704641350210971], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 04:51:55,992 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 04:51:57,724 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 04:51:59,030 maskrcnn_benchmark.trainer INFO: Total training time: 0:19:19.202463 (1.8547 s / it)
2024-03-19 04:51:59,059 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 04:51:59,060 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 04:51:59,060 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 04:51:59,060 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 04:51:59,060 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 04:51:59,060 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 04:51:59,060 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 04:51:59,060 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 04:51:59,060 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 04:51:59,060 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 04:51:59,061 maskrcnn_benchmark INFO: visual_prompt.7.dim_1 : Not Frozen, param number, 36
2024-03-19 04:51:59,061 maskrcnn_benchmark INFO: visual_prompt.7.dim_2 : Not Frozen, param number, 64
2024-03-19 04:51:59,061 maskrcnn_benchmark INFO: visual_prompt.7.dim_3 : Not Frozen, param number, 384
2024-03-19 04:51:59,061 maskrcnn_benchmark INFO: textual_prompt.7.dim_1 : Not Frozen, param number, 36
2024-03-19 04:51:59,061 maskrcnn_benchmark INFO: textual_prompt.7.dim_2 : Not Frozen, param number, 64
2024-03-19 04:51:59,062 maskrcnn_benchmark INFO: textual_prompt.7.dim_3 : Not Frozen, param number, 3072
2024-03-19 04:51:59,064 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 04:51:59,065 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.50s)
creating index...
index created!
2024-03-19 04:52:01,459 maskrcnn_benchmark INFO: Training on task 7: furniture, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.14s)
creating index...
index created!
2024-03-19 04:52:02,749 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 04:52:02,932 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 04:52:03,112 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 04:52:03,293 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 04:52:03,475 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 04:52:03,672 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 04:52:03,857 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 04:52:05,290 maskrcnn_benchmark INFO: Testing on task 7: furniture, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
2024-03-19 04:52:05,556 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:39  iter: 20  loss: 2.1177 (1.7518)  loss_reg: 0.2769 (0.2327)  loss_centerness: 0.4822 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2145 (0.9196)  time: 1.4124 (1.4545)  data: 0.1301 (0.1395)  task_loss: 0.1349 (0.1316)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:14:10  iter: 40  loss: 2.0243 (1.7534)  loss_reg: 0.2708 (0.2329)  loss_centerness: 0.4843 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0784 (0.9208)  time: 1.4172 (1.4543)  data: 0.1286 (0.1394)  task_loss: 0.1349 (0.1316)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:41  iter: 60  loss: 1.9164 (1.7543)  loss_reg: 0.2614 (0.2332)  loss_centerness: 0.4806 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9938 (0.9213)  time: 1.4711 (1.4543)  data: 0.1309 (0.1394)  task_loss: 0.1349 (0.1316)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:12  iter: 80  loss: 1.8491 (1.7550)  loss_reg: 0.2855 (0.2334)  loss_centerness: 0.4822 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9199 (0.9216)  time: 1.4108 (1.4541)  data: 0.1266 (0.1393)  task_loss: 0.1348 (0.1317)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:43  iter: 100  loss: 1.7828 (1.7552)  loss_reg: 0.2616 (0.2336)  loss_centerness: 0.4818 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9055 (0.9216)  time: 1.4686 (1.4541)  data: 0.1287 (0.1393)  task_loss: 0.1348 (0.1317)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:14  iter: 120  loss: 1.8020 (1.7557)  loss_reg: 0.2817 (0.2339)  loss_centerness: 0.4830 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8958 (0.9217)  time: 1.4101 (1.4540)  data: 0.1271 (0.1392)  task_loss: 0.1348 (0.1317)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:45  iter: 140  loss: 1.7552 (1.7560)  loss_reg: 0.2619 (0.2341)  loss_centerness: 0.4801 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8967 (0.9217)  time: 1.4621 (1.4540)  data: 0.1300 (0.1392)  task_loss: 0.1348 (0.1317)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:16  iter: 160  loss: 1.7700 (1.7561)  loss_reg: 0.2654 (0.2343)  loss_centerness: 0.4838 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8783 (0.9215)  time: 1.4470 (1.4540)  data: 0.1323 (0.1392)  task_loss: 0.1348 (0.1317)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:47  iter: 180  loss: 1.7665 (1.7562)  loss_reg: 0.2927 (0.2346)  loss_centerness: 0.4821 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8813 (0.9212)  time: 1.4198 (1.4541)  data: 0.1266 (0.1391)  task_loss: 0.1348 (0.1318)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:17  iter: 200  loss: 1.7319 (1.7562)  loss_reg: 0.2680 (0.2348)  loss_centerness: 0.4806 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8344 (0.9209)  time: 1.4170 (1.4539)  data: 0.1259 (0.1391)  task_loss: 0.1348 (0.1318)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:48  iter: 220  loss: 1.7140 (1.7561)  loss_reg: 0.2552 (0.2349)  loss_centerness: 0.4795 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8723 (0.9206)  time: 1.4198 (1.4538)  data: 0.1262 (0.1390)  task_loss: 0.1348 (0.1318)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:19  iter: 240  loss: 1.7603 (1.7562)  loss_reg: 0.2873 (0.2352)  loss_centerness: 0.4823 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8693 (0.9203)  time: 1.4151 (1.4537)  data: 0.1268 (0.1389)  task_loss: 0.1348 (0.1318)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:50  iter: 260  loss: 1.7302 (1.7562)  loss_reg: 0.2752 (0.2355)  loss_centerness: 0.4832 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8380 (0.9200)  time: 1.4740 (1.4537)  data: 0.1364 (0.1389)  task_loss: 0.1348 (0.1318)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:21  iter: 280  loss: 1.7686 (1.7566)  loss_reg: 0.2738 (0.2358)  loss_centerness: 0.4839 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8900 (0.9199)  time: 1.4762 (1.4540)  data: 0.1387 (0.1391)  task_loss: 0.1348 (0.1318)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:52  iter: 300  loss: 1.6609 (1.7562)  loss_reg: 0.2638 (0.2360)  loss_centerness: 0.4835 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7430 (0.9192)  time: 1.4096 (1.4538)  data: 0.1239 (0.1390)  task_loss: 0.1348 (0.1319)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:23  iter: 320  loss: 1.7096 (1.7560)  loss_reg: 0.2712 (0.2361)  loss_centerness: 0.4842 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8201 (0.9188)  time: 1.4316 (1.4538)  data: 0.1278 (0.1390)  task_loss: 0.1348 (0.1319)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:54  iter: 340  loss: 1.7103 (1.7558)  loss_reg: 0.2617 (0.2363)  loss_centerness: 0.4813 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8174 (0.9183)  time: 1.4194 (1.4537)  data: 0.1297 (0.1389)  task_loss: 0.1348 (0.1319)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:25  iter: 360  loss: 1.7572 (1.7559)  loss_reg: 0.2902 (0.2366)  loss_centerness: 0.4826 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8504 (0.9180)  time: 1.4175 (1.4536)  data: 0.1293 (0.1389)  task_loss: 0.1347 (0.1319)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:56  iter: 380  loss: 1.7458 (1.7557)  loss_reg: 0.2552 (0.2368)  loss_centerness: 0.4809 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8359 (0.9175)  time: 1.4505 (1.4538)  data: 0.1332 (0.1389)  task_loss: 0.1347 (0.1319)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:27  iter: 400  loss: 1.7767 (1.7558)  loss_reg: 0.2883 (0.2371)  loss_centerness: 0.4854 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8616 (0.9172)  time: 1.4243 (1.4537)  data: 0.1311 (0.1388)  task_loss: 0.1347 (0.1319)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:57  iter: 420  loss: 1.6836 (1.7554)  loss_reg: 0.2706 (0.2373)  loss_centerness: 0.4798 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8033 (0.9166)  time: 1.4152 (1.4536)  data: 0.1271 (0.1388)  task_loss: 0.1347 (0.1320)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:28  iter: 440  loss: 1.6958 (1.7550)  loss_reg: 0.2499 (0.2374)  loss_centerness: 0.4794 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8010 (0.9160)  time: 1.4725 (1.4536)  data: 0.1380 (0.1388)  task_loss: 0.1347 (0.1320)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:59  iter: 460  loss: 1.6952 (1.7549)  loss_reg: 0.2731 (0.2376)  loss_centerness: 0.4812 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8132 (0.9156)  time: 1.4304 (1.4536)  data: 0.1325 (0.1387)  task_loss: 0.1347 (0.1320)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:30  iter: 480  loss: 1.7101 (1.7547)  loss_reg: 0.2666 (0.2379)  loss_centerness: 0.4835 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8179 (0.9151)  time: 1.4312 (1.4538)  data: 0.1316 (0.1389)  task_loss: 0.1347 (0.1320)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:01  iter: 500  loss: 1.7160 (1.7546)  loss_reg: 0.2771 (0.2381)  loss_centerness: 0.4833 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8462 (0.9146)  time: 1.4188 (1.4537)  data: 0.1275 (0.1388)  task_loss: 0.1347 (0.1320)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:32  iter: 520  loss: 1.6730 (1.7542)  loss_reg: 0.2697 (0.2382)  loss_centerness: 0.4820 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8059 (0.9141)  time: 1.4608 (1.4537)  data: 0.1343 (0.1388)  task_loss: 0.1347 (0.1320)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:03  iter: 540  loss: 1.6930 (1.7540)  loss_reg: 0.2665 (0.2384)  loss_centerness: 0.4799 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8006 (0.9136)  time: 1.4751 (1.4538)  data: 0.1358 (0.1388)  task_loss: 0.1347 (0.1321)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:34  iter: 560  loss: 1.7256 (1.7538)  loss_reg: 0.2747 (0.2386)  loss_centerness: 0.4830 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8053 (0.9131)  time: 1.4173 (1.4539)  data: 0.1273 (0.1388)  task_loss: 0.1347 (0.1321)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:05  iter: 580  loss: 1.7107 (1.7537)  loss_reg: 0.2830 (0.2389)  loss_centerness: 0.4823 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8208 (0.9127)  time: 1.4166 (1.4538)  data: 0.1294 (0.1387)  task_loss: 0.1347 (0.1321)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:36  iter: 600  loss: 1.6701 (1.7533)  loss_reg: 0.2571 (0.2389)  loss_centerness: 0.4813 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8038 (0.9122)  time: 1.4594 (1.4538)  data: 0.1329 (0.1387)  task_loss: 0.1347 (0.1321)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:07  iter: 620  loss: 1.6980 (1.7531)  loss_reg: 0.2774 (0.2392)  loss_centerness: 0.4839 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7972 (0.9117)  time: 1.4271 (1.4537)  data: 0.1314 (0.1387)  task_loss: 0.1347 (0.1321)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:00  iter: 625  loss: 1.7163 (1.7532)  loss_reg: 0.2782 (0.2392)  loss_centerness: 0.4839 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8053 (0.9117)  time: 1.4271 (1.4537)  data: 0.1318 (0.1387)  task_loss: 0.1347 (0.1321)  lr: 0.000000  wd: 0.000500  max mem: 12750
Evaluating
2024-03-19 05:09:17,597 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 05:09:26,881 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:09:26,886 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:09:26,922 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.4931506849315068, 0.6712328767123288] 

2024-03-19 05:09:26,922 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:09:26,923 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:09:26,923 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8493150684931506
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.4931506849315068, 0.6712328767123288], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:09:26,941 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 05:09:32,534 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:09:32,538 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 05:09:32,551 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2962962962962963, 0.8888888888888888, 1.0] 

2024-03-19 05:09:32,551 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:09:32,551 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:09:32,552 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2962962962962963, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:09:32,567 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 05:09:40,103 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:09:40,107 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:09:40,124 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2727272727272727, 0.5227272727272727, 0.7272727272727273] 

2024-03-19 05:09:40,125 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:09:40,125 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:09:40,125 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.2727272727272727, 0.5227272727272727, 0.7272727272727273], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:09:40,141 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 05:10:06,311 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:10:06,315 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:10:06,408 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.30196078431372547, 0.807843137254902, 0.9098039215686274] 

2024-03-19 05:10:06,409 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:10:06,409 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:10:06,409 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8549019607843137
evaluate on task refcoco, val, 3, res: {'refcoco': [0.30196078431372547, 0.807843137254902, 0.9098039215686274], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:10:06,424 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 05:10:29,020 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:10:29,024 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 05:10:29,099 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2761904761904762, 0.8047619047619048, 0.8857142857142857] 

2024-03-19 05:10:29,099 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:10:29,099 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:10:29,099 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8809523809523809
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2761904761904762, 0.8047619047619048, 0.8857142857142857], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:10:29,114 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 05:10:59,679 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:10:59,684 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:10:59,815 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.22875816993464052, 0.7450980392156863, 0.8823529411764706] 

2024-03-19 05:10:59,815 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:10:59,815 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:10:59,815 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8954248366013072
evaluate on task refcoco, val, 5, res: {'refcoco': [0.22875816993464052, 0.7450980392156863, 0.8823529411764706], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:10:59,834 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 05:11:46,517 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:11:46,525 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:11:46,691 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3291139240506329, 0.9177215189873418, 0.9704641350210971] 

2024-03-19 05:11:46,691 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:11:46,691 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:11:46,691 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9261603375527426
evaluate on task refcoco, val, 6, res: {'refcoco': [0.3291139240506329, 0.9177215189873418, 0.9704641350210971], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:11:46,710 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 7
2024-03-19 05:12:36,626 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:12:36,630 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:12:36,826 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.31, 0.772, 0.872] 

2024-03-19 05:12:36,826 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:12:36,826 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:12:36,826 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.616
evaluate on task refcoco, val, 7, res: {'refcoco': [0.31, 0.772, 0.872], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:12:36,871 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 05:12:38,129 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 05:12:39,461 maskrcnn_benchmark.trainer INFO: Total training time: 0:20:33.890314 (1.9742 s / it)
2024-03-19 05:12:39,490 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 05:12:39,491 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 05:12:39,491 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 05:12:39,491 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 05:12:39,491 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 05:12:39,491 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 05:12:39,491 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 05:12:39,491 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 05:12:39,491 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 05:12:39,491 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 05:12:39,492 maskrcnn_benchmark INFO: visual_prompt.8.dim_1 : Not Frozen, param number, 36
2024-03-19 05:12:39,492 maskrcnn_benchmark INFO: visual_prompt.8.dim_2 : Not Frozen, param number, 64
2024-03-19 05:12:39,492 maskrcnn_benchmark INFO: visual_prompt.8.dim_3 : Not Frozen, param number, 384
2024-03-19 05:12:39,492 maskrcnn_benchmark INFO: textual_prompt.8.dim_1 : Not Frozen, param number, 36
2024-03-19 05:12:39,492 maskrcnn_benchmark INFO: textual_prompt.8.dim_2 : Not Frozen, param number, 64
2024-03-19 05:12:39,492 maskrcnn_benchmark INFO: textual_prompt.8.dim_3 : Not Frozen, param number, 3072
2024-03-19 05:12:39,495 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 05:12:39,495 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.61s)
creating index...
index created!
2024-03-19 05:12:41,961 maskrcnn_benchmark INFO: Training on task 8: vehicle, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.12s)
creating index...
index created!
2024-03-19 05:12:43,227 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:12:43,415 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:12:43,605 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 05:12:43,798 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 05:12:43,986 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 05:12:44,176 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:12:44,361 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 05:12:44,551 maskrcnn_benchmark INFO: Testing on task 7: furniture, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:12:46,032 maskrcnn_benchmark INFO: Testing on task 8: vehicle, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
2024-03-19 05:12:46,345 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:39  iter: 20  loss: 2.1157 (1.7550)  loss_reg: 0.2319 (0.2392)  loss_centerness: 0.4771 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2690 (0.9134)  time: 1.4069 (1.4544)  data: 0.0145 (0.1392)  task_loss: 0.1344 (0.1321)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:14:10  iter: 40  loss: 1.9163 (1.7555)  loss_reg: 0.2458 (0.2393)  loss_centerness: 0.4790 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0361 (0.9138)  time: 1.4098 (1.4546)  data: 0.0151 (0.1392)  task_loss: 0.1344 (0.1321)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:41  iter: 60  loss: 1.8213 (1.7559)  loss_reg: 0.2622 (0.2394)  loss_centerness: 0.4805 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9234 (0.9140)  time: 1.4489 (1.4548)  data: 0.0178 (0.1392)  task_loss: 0.1344 (0.1322)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:12  iter: 80  loss: 1.6892 (1.7556)  loss_reg: 0.2568 (0.2394)  loss_centerness: 0.4779 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8157 (0.9137)  time: 1.4011 (1.4549)  data: 0.0136 (0.1392)  task_loss: 0.1344 (0.1322)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:43  iter: 100  loss: 1.6933 (1.7554)  loss_reg: 0.2564 (0.2395)  loss_centerness: 0.4789 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8274 (0.9133)  time: 1.4204 (1.4551)  data: 0.0151 (0.1391)  task_loss: 0.1344 (0.1322)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:14  iter: 120  loss: 1.6782 (1.7549)  loss_reg: 0.2438 (0.2395)  loss_centerness: 0.4785 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8060 (0.9127)  time: 1.3450 (1.4551)  data: 0.0116 (0.1391)  task_loss: 0.1344 (0.1322)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:45  iter: 140  loss: 1.6760 (1.7546)  loss_reg: 0.2526 (0.2396)  loss_centerness: 0.4795 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8215 (0.9123)  time: 1.4308 (1.4552)  data: 0.0139 (0.1390)  task_loss: 0.1344 (0.1322)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:16  iter: 160  loss: 1.5809 (1.7539)  loss_reg: 0.2287 (0.2396)  loss_centerness: 0.4774 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7276 (0.9115)  time: 1.4396 (1.4555)  data: 0.0160 (0.1390)  task_loss: 0.1344 (0.1322)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:47  iter: 180  loss: 1.6456 (1.7534)  loss_reg: 0.2628 (0.2397)  loss_centerness: 0.4790 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7615 (0.9109)  time: 1.4381 (1.4557)  data: 0.0161 (0.1390)  task_loss: 0.1344 (0.1322)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:18  iter: 200  loss: 1.6712 (1.7531)  loss_reg: 0.2566 (0.2398)  loss_centerness: 0.4800 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8078 (0.9105)  time: 1.4122 (1.4561)  data: 0.0165 (0.1391)  task_loss: 0.1344 (0.1322)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:49  iter: 220  loss: 1.6196 (1.7524)  loss_reg: 0.2365 (0.2398)  loss_centerness: 0.4773 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7680 (0.9097)  time: 1.4053 (1.4563)  data: 0.0140 (0.1391)  task_loss: 0.1344 (0.1322)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:20  iter: 240  loss: 1.6225 (1.7519)  loss_reg: 0.2428 (0.2398)  loss_centerness: 0.4771 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7814 (0.9091)  time: 1.4492 (1.4564)  data: 0.0148 (0.1390)  task_loss: 0.1344 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:51  iter: 260  loss: 1.6469 (1.7513)  loss_reg: 0.2579 (0.2399)  loss_centerness: 0.4822 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7840 (0.9084)  time: 1.4148 (1.4565)  data: 0.0136 (0.1390)  task_loss: 0.1344 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:22  iter: 280  loss: 1.6202 (1.7507)  loss_reg: 0.2518 (0.2399)  loss_centerness: 0.4783 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7295 (0.9077)  time: 1.4359 (1.4565)  data: 0.0130 (0.1389)  task_loss: 0.1344 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:53  iter: 300  loss: 1.5826 (1.7501)  loss_reg: 0.2407 (0.2400)  loss_centerness: 0.4773 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7513 (0.9070)  time: 1.4248 (1.4568)  data: 0.0155 (0.1391)  task_loss: 0.1344 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:24  iter: 320  loss: 1.5905 (1.7495)  loss_reg: 0.2508 (0.2400)  loss_centerness: 0.4802 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7444 (0.9063)  time: 1.4140 (1.4570)  data: 0.0232 (0.1390)  task_loss: 0.1344 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:55  iter: 340  loss: 1.5722 (1.7488)  loss_reg: 0.2359 (0.2400)  loss_centerness: 0.4774 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7334 (0.9056)  time: 1.4322 (1.4572)  data: 0.0137 (0.1390)  task_loss: 0.1344 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:26  iter: 360  loss: 1.6735 (1.7484)  loss_reg: 0.2563 (0.2401)  loss_centerness: 0.4785 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7880 (0.9050)  time: 1.4322 (1.4573)  data: 0.0133 (0.1390)  task_loss: 0.1344 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:57  iter: 380  loss: 1.6492 (1.7479)  loss_reg: 0.2421 (0.2402)  loss_centerness: 0.4810 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7495 (0.9044)  time: 1.3821 (1.4575)  data: 0.0133 (0.1389)  task_loss: 0.1344 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:27  iter: 400  loss: 1.5987 (1.7473)  loss_reg: 0.2469 (0.2402)  loss_centerness: 0.4792 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7372 (0.9037)  time: 1.4343 (1.4576)  data: 0.0162 (0.1389)  task_loss: 0.1344 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:58  iter: 420  loss: 1.5817 (1.7467)  loss_reg: 0.2414 (0.2403)  loss_centerness: 0.4790 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7340 (0.9030)  time: 1.4121 (1.4578)  data: 0.0183 (0.1389)  task_loss: 0.1344 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:29  iter: 440  loss: 1.6161 (1.7461)  loss_reg: 0.2490 (0.2403)  loss_centerness: 0.4790 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7444 (0.9023)  time: 1.3566 (1.4578)  data: 0.0158 (0.1388)  task_loss: 0.1344 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:00  iter: 460  loss: 1.5843 (1.7455)  loss_reg: 0.2382 (0.2404)  loss_centerness: 0.4765 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7349 (0.9017)  time: 1.4188 (1.4581)  data: 0.0173 (0.1388)  task_loss: 0.1344 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:31  iter: 480  loss: 1.5988 (1.7449)  loss_reg: 0.2418 (0.2404)  loss_centerness: 0.4798 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7227 (0.9010)  time: 1.4280 (1.4582)  data: 0.0138 (0.1388)  task_loss: 0.1344 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:02  iter: 500  loss: 1.5971 (1.7444)  loss_reg: 0.2487 (0.2404)  loss_centerness: 0.4790 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7132 (0.9004)  time: 1.4230 (1.4585)  data: 0.0188 (0.1387)  task_loss: 0.1344 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:33  iter: 520  loss: 1.5920 (1.7438)  loss_reg: 0.2513 (0.2405)  loss_centerness: 0.4781 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7040 (0.8997)  time: 1.4178 (1.4587)  data: 0.0154 (0.1387)  task_loss: 0.1344 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:04  iter: 540  loss: 1.5694 (1.7431)  loss_reg: 0.2452 (0.2405)  loss_centerness: 0.4790 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7125 (0.8990)  time: 1.4218 (1.4589)  data: 0.0175 (0.1387)  task_loss: 0.1344 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:34  iter: 560  loss: 1.5912 (1.7425)  loss_reg: 0.2329 (0.2405)  loss_centerness: 0.4773 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7447 (0.8982)  time: 1.4028 (1.4590)  data: 0.0187 (0.1387)  task_loss: 0.1344 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:05  iter: 580  loss: 1.6211 (1.7421)  loss_reg: 0.2559 (0.2406)  loss_centerness: 0.4784 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7658 (0.8977)  time: 1.4318 (1.4591)  data: 0.0141 (0.1386)  task_loss: 0.1344 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:36  iter: 600  loss: 1.5786 (1.7414)  loss_reg: 0.2454 (0.2406)  loss_centerness: 0.4792 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7111 (0.8970)  time: 1.4244 (1.4594)  data: 0.0168 (0.1388)  task_loss: 0.1343 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:07  iter: 620  loss: 1.5875 (1.7407)  loss_reg: 0.2371 (0.2406)  loss_centerness: 0.4778 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6984 (0.8962)  time: 1.4329 (1.4594)  data: 0.0191 (0.1387)  task_loss: 0.1343 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:00  iter: 625  loss: 1.5938 (1.7406)  loss_reg: 0.2371 (0.2407)  loss_centerness: 0.4776 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7140 (0.8961)  time: 1.4127 (1.4595)  data: 0.0154 (0.1387)  task_loss: 0.1343 (0.1324)  lr: 0.000000  wd: 0.000500  max mem: 12750
Evaluating
2024-03-19 05:30:18,927 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 05:30:28,422 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:30:28,426 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:30:28,458 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.5068493150684932, 0.6712328767123288] 

2024-03-19 05:30:28,458 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:30:28,458 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:30:28,458 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8493150684931506
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.5068493150684932, 0.6712328767123288], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:30:28,473 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 05:30:33,431 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:30:33,435 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 05:30:33,448 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2962962962962963, 0.8888888888888888, 1.0] 

2024-03-19 05:30:33,448 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:30:33,448 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:30:33,448 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2962962962962963, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:30:33,465 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 05:30:40,317 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:30:40,321 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:30:40,338 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2727272727272727, 0.5227272727272727, 0.7272727272727273] 

2024-03-19 05:30:40,339 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:30:40,339 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:30:40,339 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.2727272727272727, 0.5227272727272727, 0.7272727272727273], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:30:40,354 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 05:31:07,245 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:31:07,249 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:31:07,342 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2980392156862745, 0.807843137254902, 0.9098039215686274] 

2024-03-19 05:31:07,342 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:31:07,342 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:31:07,342 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8549019607843137
evaluate on task refcoco, val, 3, res: {'refcoco': [0.2980392156862745, 0.807843137254902, 0.9098039215686274], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:31:07,358 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 05:31:29,231 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:31:29,234 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 05:31:29,325 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2761904761904762, 0.8047619047619048, 0.8904761904761904] 

2024-03-19 05:31:29,326 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:31:29,326 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:31:29,326 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8809523809523809
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2761904761904762, 0.8047619047619048, 0.8904761904761904], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:31:29,343 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 05:32:01,086 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:32:01,091 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:32:01,244 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.23202614379084968, 0.7483660130718954, 0.8823529411764706] 

2024-03-19 05:32:01,244 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:32:01,244 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:32:01,244 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8954248366013072
evaluate on task refcoco, val, 5, res: {'refcoco': [0.23202614379084968, 0.7483660130718954, 0.8823529411764706], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:32:01,262 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 05:32:48,229 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:32:48,234 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:32:48,404 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.33122362869198313, 0.9177215189873418, 0.9704641350210971] 

2024-03-19 05:32:48,405 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:32:48,405 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:32:48,405 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9261603375527426
evaluate on task refcoco, val, 6, res: {'refcoco': [0.33122362869198313, 0.9177215189873418, 0.9704641350210971], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:32:48,423 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 7
2024-03-19 05:33:38,345 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:33:38,349 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:33:38,588 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.306, 0.774, 0.872] 

2024-03-19 05:33:38,589 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:33:38,589 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:33:38,589 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.616
evaluate on task refcoco, val, 7, res: {'refcoco': [0.306, 0.774, 0.872], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:33:38,607 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 8
2024-03-19 05:34:26,945 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:34:26,949 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 05:34:27,128 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.39, 0.932, 0.97] 

2024-03-19 05:34:27,128 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:34:27,128 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:34:27,128 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.91
evaluate on task refcoco, val, 8, res: {'refcoco': [0.39, 0.932, 0.97], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:34:27,182 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 05:34:28,320 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 05:34:29,614 maskrcnn_benchmark.trainer INFO: Total training time: 0:21:43.254130 (2.0852 s / it)
2024-03-19 05:34:29,645 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 05:34:29,646 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 05:34:29,646 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 05:34:29,646 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 05:34:29,646 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 05:34:29,646 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 05:34:29,646 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 05:34:29,646 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 05:34:29,646 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 05:34:29,646 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 05:34:29,647 maskrcnn_benchmark INFO: visual_prompt.9.dim_1 : Not Frozen, param number, 36
2024-03-19 05:34:29,647 maskrcnn_benchmark INFO: visual_prompt.9.dim_2 : Not Frozen, param number, 64
2024-03-19 05:34:29,647 maskrcnn_benchmark INFO: visual_prompt.9.dim_3 : Not Frozen, param number, 384
2024-03-19 05:34:29,647 maskrcnn_benchmark INFO: textual_prompt.9.dim_1 : Not Frozen, param number, 36
2024-03-19 05:34:29,647 maskrcnn_benchmark INFO: textual_prompt.9.dim_2 : Not Frozen, param number, 64
2024-03-19 05:34:29,647 maskrcnn_benchmark INFO: textual_prompt.9.dim_3 : Not Frozen, param number, 3072
2024-03-19 05:34:29,650 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 05:34:29,650 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=2.50s)
creating index...
index created!
2024-03-19 05:34:33,052 maskrcnn_benchmark INFO: Training on task 9: food, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 05:34:33,260 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 05:34:33,459 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:34:33,642 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:34:33,833 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.21s)
creating index...
index created!
2024-03-19 05:34:35,170 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:34:35,355 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:34:35,549 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:34:35,735 maskrcnn_benchmark INFO: Testing on task 7: furniture, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:34:35,916 maskrcnn_benchmark INFO: Testing on task 8: vehicle, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:34:36,111 maskrcnn_benchmark INFO: Testing on task 9: food, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
2024-03-19 05:34:36,406 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:43  iter: 20  loss: 2.1666 (1.7425)  loss_reg: 0.2293 (0.2406)  loss_centerness: 0.4738 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3263 (0.8981)  time: 1.4087 (1.4602)  data: 0.0137 (0.1392)  task_loss: 0.1373 (0.1325)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:14:14  iter: 40  loss: 2.0952 (1.7442)  loss_reg: 0.2384 (0.2406)  loss_centerness: 0.4750 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2889 (0.8998)  time: 1.4384 (1.4604)  data: 0.0207 (0.1392)  task_loss: 0.1373 (0.1325)  lr: 0.010000  wd: 0.000500  max mem: 12751
eta: 0:13:45  iter: 60  loss: 2.0042 (1.7454)  loss_reg: 0.2343 (0.2406)  loss_centerness: 0.4761 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1472 (0.9009)  time: 1.4097 (1.4605)  data: 0.0207 (0.1392)  task_loss: 0.1373 (0.1325)  lr: 0.010000  wd: 0.000500  max mem: 12751
eta: 0:13:16  iter: 80  loss: 1.9368 (1.7462)  loss_reg: 0.2328 (0.2405)  loss_centerness: 0.4742 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0877 (0.9017)  time: 1.4673 (1.4608)  data: 0.0140 (0.1392)  task_loss: 0.1373 (0.1325)  lr: 0.010000  wd: 0.000500  max mem: 12751
eta: 0:12:47  iter: 100  loss: 1.8949 (1.7471)  loss_reg: 0.2306 (0.2405)  loss_centerness: 0.4740 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0590 (0.9025)  time: 1.4533 (1.4610)  data: 0.0151 (0.1391)  task_loss: 0.1373 (0.1326)  lr: 0.010000  wd: 0.000500  max mem: 12751
eta: 0:12:17  iter: 120  loss: 1.9731 (1.7478)  loss_reg: 0.2367 (0.2405)  loss_centerness: 0.4758 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1137 (0.9033)  time: 1.3924 (1.4611)  data: 0.0134 (0.1391)  task_loss: 0.1373 (0.1326)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:11:48  iter: 140  loss: 1.8772 (1.7484)  loss_reg: 0.2307 (0.2405)  loss_centerness: 0.4754 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0344 (0.9039)  time: 1.4085 (1.4612)  data: 0.0176 (0.1391)  task_loss: 0.1373 (0.1326)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:11:19  iter: 160  loss: 1.8767 (1.7489)  loss_reg: 0.2111 (0.2404)  loss_centerness: 0.4749 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9703 (0.9043)  time: 1.4033 (1.4612)  data: 0.0161 (0.1390)  task_loss: 0.1373 (0.1326)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:10:50  iter: 180  loss: 1.8689 (1.7495)  loss_reg: 0.2399 (0.2404)  loss_centerness: 0.4748 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0408 (0.9050)  time: 1.4506 (1.4615)  data: 0.0191 (0.1391)  task_loss: 0.1373 (0.1326)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:10:21  iter: 200  loss: 1.8211 (1.7499)  loss_reg: 0.2103 (0.2403)  loss_centerness: 0.4746 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9783 (0.9054)  time: 1.4721 (1.4617)  data: 0.0178 (0.1391)  task_loss: 0.1373 (0.1327)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:09:52  iter: 220  loss: 1.8066 (1.7503)  loss_reg: 0.2353 (0.2403)  loss_centerness: 0.4747 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9631 (0.9058)  time: 1.4181 (1.4618)  data: 0.0153 (0.1391)  task_loss: 0.1373 (0.1327)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:09:22  iter: 240  loss: 1.8889 (1.7508)  loss_reg: 0.2283 (0.2403)  loss_centerness: 0.4756 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0192 (0.9063)  time: 1.4141 (1.4618)  data: 0.0184 (0.1390)  task_loss: 0.1373 (0.1327)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:08:53  iter: 260  loss: 1.8141 (1.7512)  loss_reg: 0.2187 (0.2402)  loss_centerness: 0.4752 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9742 (0.9067)  time: 1.4618 (1.4621)  data: 0.0144 (0.1390)  task_loss: 0.1373 (0.1327)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:08:24  iter: 280  loss: 1.8333 (1.7514)  loss_reg: 0.2327 (0.2402)  loss_centerness: 0.4734 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9872 (0.9069)  time: 1.4821 (1.4625)  data: 0.0158 (0.1392)  task_loss: 0.1373 (0.1327)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:07:55  iter: 300  loss: 1.8299 (1.7518)  loss_reg: 0.2205 (0.2401)  loss_centerness: 0.4754 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9959 (0.9073)  time: 1.4113 (1.4626)  data: 0.0174 (0.1392)  task_loss: 0.1373 (0.1328)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:07:26  iter: 320  loss: 1.8640 (1.7521)  loss_reg: 0.2312 (0.2401)  loss_centerness: 0.4753 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0009 (0.9076)  time: 1.4073 (1.4626)  data: 0.0157 (0.1391)  task_loss: 0.1373 (0.1328)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:06:56  iter: 340  loss: 1.8380 (1.7526)  loss_reg: 0.2319 (0.2401)  loss_centerness: 0.4773 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0296 (0.9081)  time: 1.4225 (1.4631)  data: 0.0146 (0.1394)  task_loss: 0.1373 (0.1328)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:06:27  iter: 360  loss: 1.8341 (1.7528)  loss_reg: 0.2261 (0.2400)  loss_centerness: 0.4718 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0021 (0.9083)  time: 1.4270 (1.4632)  data: 0.0162 (0.1394)  task_loss: 0.1373 (0.1328)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:05:58  iter: 380  loss: 1.8172 (1.7531)  loss_reg: 0.2416 (0.2400)  loss_centerness: 0.4762 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9727 (0.9086)  time: 1.4008 (1.4635)  data: 0.0150 (0.1395)  task_loss: 0.1373 (0.1328)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:05:29  iter: 400  loss: 1.7984 (1.7535)  loss_reg: 0.2239 (0.2400)  loss_centerness: 0.4736 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9485 (0.9090)  time: 1.4351 (1.4636)  data: 0.0140 (0.1395)  task_loss: 0.1373 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:05:00  iter: 420  loss: 1.8387 (1.7537)  loss_reg: 0.2296 (0.2400)  loss_centerness: 0.4738 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9813 (0.9092)  time: 1.3887 (1.4636)  data: 0.0167 (0.1395)  task_loss: 0.1373 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:04:30  iter: 440  loss: 1.8501 (1.7541)  loss_reg: 0.2147 (0.2399)  loss_centerness: 0.4748 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9694 (0.9096)  time: 1.4068 (1.4638)  data: 0.0177 (0.1394)  task_loss: 0.1373 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:04:01  iter: 460  loss: 1.7719 (1.7542)  loss_reg: 0.2193 (0.2399)  loss_centerness: 0.4759 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9262 (0.9097)  time: 1.4576 (1.4639)  data: 0.0175 (0.1394)  task_loss: 0.1373 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:03:32  iter: 480  loss: 1.8350 (1.7546)  loss_reg: 0.2279 (0.2398)  loss_centerness: 0.4747 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9890 (0.9101)  time: 1.4153 (1.4643)  data: 0.0154 (0.1396)  task_loss: 0.1373 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:03:03  iter: 500  loss: 1.7839 (1.7548)  loss_reg: 0.2285 (0.2398)  loss_centerness: 0.4759 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9295 (0.9103)  time: 1.4349 (1.4644)  data: 0.0155 (0.1395)  task_loss: 0.1373 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:02:33  iter: 520  loss: 1.7789 (1.7549)  loss_reg: 0.2199 (0.2398)  loss_centerness: 0.4745 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9345 (0.9105)  time: 1.4953 (1.4646)  data: 0.0132 (0.1395)  task_loss: 0.1373 (0.1330)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:02:04  iter: 540  loss: 1.7590 (1.7550)  loss_reg: 0.2235 (0.2397)  loss_centerness: 0.4756 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9281 (0.9105)  time: 1.4118 (1.4647)  data: 0.0131 (0.1395)  task_loss: 0.1373 (0.1330)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:01:35  iter: 560  loss: 1.8473 (1.7555)  loss_reg: 0.2392 (0.2397)  loss_centerness: 0.4772 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9932 (0.9110)  time: 1.4202 (1.4648)  data: 0.0216 (0.1395)  task_loss: 0.1372 (0.1330)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:01:05  iter: 580  loss: 1.8160 (1.7558)  loss_reg: 0.2318 (0.2397)  loss_centerness: 0.4747 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9611 (0.9112)  time: 1.4104 (1.4650)  data: 0.0133 (0.1395)  task_loss: 0.1372 (0.1330)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:00:36  iter: 600  loss: 1.7912 (1.7561)  loss_reg: 0.2320 (0.2397)  loss_centerness: 0.4747 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9649 (0.9116)  time: 1.4091 (1.4652)  data: 0.0175 (0.1394)  task_loss: 0.1372 (0.1330)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:00:07  iter: 620  loss: 1.7392 (1.7562)  loss_reg: 0.2259 (0.2396)  loss_centerness: 0.4736 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9231 (0.9117)  time: 1.4252 (1.4653)  data: 0.0181 (0.1394)  task_loss: 0.1372 (0.1330)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:00:00  iter: 625  loss: 1.7107 (1.7562)  loss_reg: 0.2259 (0.2396)  loss_centerness: 0.4736 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9084 (0.9117)  time: 1.4252 (1.4654)  data: 0.0181 (0.1394)  task_loss: 0.1372 (0.1331)  lr: 0.000000  wd: 0.000500  max mem: 12753
Evaluating
2024-03-19 05:52:12,038 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 05:52:20,851 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:52:20,855 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:52:20,893 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.5068493150684932, 0.6712328767123288] 

2024-03-19 05:52:20,894 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:52:20,894 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:52:20,894 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8493150684931506
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.5068493150684932, 0.6712328767123288], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:52:20,911 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 05:52:25,539 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:52:25,543 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 05:52:25,556 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2222222222222222, 0.8888888888888888, 1.0] 

2024-03-19 05:52:25,557 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:52:25,557 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:52:25,557 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2222222222222222, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:52:25,576 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 05:52:32,024 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:52:32,027 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:52:32,044 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2727272727272727, 0.5227272727272727, 0.75] 

2024-03-19 05:52:32,045 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:52:32,045 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:52:32,045 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.2727272727272727, 0.5227272727272727, 0.75], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:52:32,063 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 05:52:56,806 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:52:56,810 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:52:56,919 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2980392156862745, 0.807843137254902, 0.9176470588235294] 

2024-03-19 05:52:56,919 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:52:56,919 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:52:56,919 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8549019607843137
evaluate on task refcoco, val, 3, res: {'refcoco': [0.2980392156862745, 0.807843137254902, 0.9176470588235294], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:52:56,937 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 05:53:18,003 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:53:18,007 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 05:53:18,093 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2761904761904762, 0.8047619047619048, 0.8904761904761904] 

2024-03-19 05:53:18,093 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:53:18,093 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:53:18,094 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8809523809523809
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2761904761904762, 0.8047619047619048, 0.8904761904761904], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:53:18,112 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 05:53:48,577 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:53:48,580 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:53:48,715 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.22875816993464052, 0.7483660130718954, 0.8823529411764706] 

2024-03-19 05:53:48,716 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:53:48,716 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:53:48,716 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8790849673202614
evaluate on task refcoco, val, 5, res: {'refcoco': [0.22875816993464052, 0.7483660130718954, 0.8823529411764706], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:53:48,739 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 05:54:32,582 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:54:32,586 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:54:32,762 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3080168776371308, 0.8818565400843882, 0.9451476793248945] 

2024-03-19 05:54:32,762 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:54:32,762 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:54:32,762 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8354430379746836
evaluate on task refcoco, val, 6, res: {'refcoco': [0.3080168776371308, 0.8818565400843882, 0.9451476793248945], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:54:32,781 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 7
2024-03-19 05:55:18,796 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:55:18,800 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 05:55:19,000 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.294, 0.772, 0.866] 

2024-03-19 05:55:19,001 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:55:19,001 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:55:19,001 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.594
evaluate on task refcoco, val, 7, res: {'refcoco': [0.294, 0.772, 0.866], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:55:19,017 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 8
2024-03-19 05:56:05,204 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:56:05,208 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 05:56:05,411 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.39, 0.932, 0.97] 

2024-03-19 05:56:05,411 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:56:05,412 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:56:05,412 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.91
evaluate on task refcoco, val, 8, res: {'refcoco': [0.39, 0.932, 0.97], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:56:05,433 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 9
2024-03-19 05:56:50,698 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 05:56:50,703 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.30000001192092896), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.30000001192092896), ('AR@1000', 0.30000001192092896), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.30000001192092896)]))])
2024-03-19 05:56:50,886 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.228, 0.602, 0.78] 

2024-03-19 05:56:50,886 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 05:56:50,887 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 05:56:50,887 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.734
evaluate on task refcoco, val, 9, res: {'refcoco': [0.228, 0.602, 0.78], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 05:56:50,940 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 05:56:52,440 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 05:56:53,891 maskrcnn_benchmark.trainer INFO: Total training time: 0:22:17.469771 (2.1400 s / it)
2024-03-19 05:56:53,918 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 05:56:53,918 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 05:56:53,918 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 05:56:53,918 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 05:56:53,918 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 05:56:53,918 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 05:56:53,919 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 05:56:53,919 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 05:56:53,919 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 05:56:53,919 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 05:56:53,919 maskrcnn_benchmark INFO: visual_prompt.10.dim_1 : Not Frozen, param number, 36
2024-03-19 05:56:53,920 maskrcnn_benchmark INFO: visual_prompt.10.dim_2 : Not Frozen, param number, 64
2024-03-19 05:56:53,920 maskrcnn_benchmark INFO: visual_prompt.10.dim_3 : Not Frozen, param number, 384
2024-03-19 05:56:53,920 maskrcnn_benchmark INFO: textual_prompt.10.dim_1 : Not Frozen, param number, 36
2024-03-19 05:56:53,920 maskrcnn_benchmark INFO: textual_prompt.10.dim_2 : Not Frozen, param number, 64
2024-03-19 05:56:53,920 maskrcnn_benchmark INFO: textual_prompt.10.dim_3 : Not Frozen, param number, 3072
2024-03-19 05:56:53,922 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 05:56:53,922 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=2.52s)
creating index...
index created!
2024-03-19 05:56:57,357 maskrcnn_benchmark INFO: Training on task 10: animal, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 05:56:57,575 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 05:56:57,767 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:56:57,951 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.32s)
creating index...
index created!
2024-03-19 05:56:59,392 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 05:56:59,583 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:56:59,768 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:56:59,954 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:57:00,139 maskrcnn_benchmark INFO: Testing on task 7: furniture, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:57:00,322 maskrcnn_benchmark INFO: Testing on task 8: vehicle, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:57:00,505 maskrcnn_benchmark INFO: Testing on task 9: food, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 05:57:00,697 maskrcnn_benchmark INFO: Testing on task 10: animal, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
2024-03-19 05:57:01,057 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:46  iter: 20  loss: 1.9995 (1.7572)  loss_reg: 0.1999 (0.2395)  loss_centerness: 0.4746 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1644 (0.9128)  time: 1.3537 (1.4657)  data: 0.0132 (0.1398)  task_loss: 0.1381 (0.1331)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:14:17  iter: 40  loss: 1.7085 (1.7571)  loss_reg: 0.1815 (0.2393)  loss_centerness: 0.4755 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9021 (0.9129)  time: 1.3606 (1.4659)  data: 0.0130 (0.1397)  task_loss: 0.1381 (0.1331)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:13:48  iter: 60  loss: 1.6041 (1.7566)  loss_reg: 0.1819 (0.2391)  loss_centerness: 0.4752 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7755 (0.9125)  time: 1.3066 (1.4657)  data: 0.0125 (0.1397)  task_loss: 0.1381 (0.1331)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:13:18  iter: 80  loss: 1.5599 (1.7559)  loss_reg: 0.1932 (0.2389)  loss_centerness: 0.4742 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7413 (0.9119)  time: 1.3483 (1.4657)  data: 0.0127 (0.1396)  task_loss: 0.1381 (0.1331)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:12:49  iter: 100  loss: 1.5147 (1.7551)  loss_reg: 0.1877 (0.2388)  loss_centerness: 0.4738 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7215 (0.9112)  time: 1.3608 (1.4656)  data: 0.0129 (0.1396)  task_loss: 0.1381 (0.1332)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:12:20  iter: 120  loss: 1.5164 (1.7542)  loss_reg: 0.1815 (0.2386)  loss_centerness: 0.4732 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7176 (0.9105)  time: 1.3011 (1.4654)  data: 0.0134 (0.1396)  task_loss: 0.1381 (0.1332)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:11:50  iter: 140  loss: 1.4925 (1.7533)  loss_reg: 0.1863 (0.2384)  loss_centerness: 0.4736 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6903 (0.9097)  time: 1.3624 (1.4654)  data: 0.0132 (0.1395)  task_loss: 0.1381 (0.1332)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:11:21  iter: 160  loss: 1.5457 (1.7524)  loss_reg: 0.1975 (0.2383)  loss_centerness: 0.4743 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7001 (0.9089)  time: 1.3288 (1.4655)  data: 0.0134 (0.1397)  task_loss: 0.1381 (0.1332)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:10:52  iter: 180  loss: 1.5074 (1.7515)  loss_reg: 0.1993 (0.2382)  loss_centerness: 0.4727 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7048 (0.9082)  time: 1.3506 (1.4657)  data: 0.0128 (0.1399)  task_loss: 0.1381 (0.1332)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:10:22  iter: 200  loss: 1.4798 (1.7506)  loss_reg: 0.1894 (0.2380)  loss_centerness: 0.4736 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6661 (0.9074)  time: 1.2959 (1.4656)  data: 0.0113 (0.1400)  task_loss: 0.1381 (0.1332)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:09:53  iter: 220  loss: 1.4808 (1.7496)  loss_reg: 0.2010 (0.2379)  loss_centerness: 0.4745 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6768 (0.9065)  time: 1.3058 (1.4655)  data: 0.0121 (0.1400)  task_loss: 0.1381 (0.1333)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:09:24  iter: 240  loss: 1.4494 (1.7486)  loss_reg: 0.1983 (0.2377)  loss_centerness: 0.4756 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6413 (0.9057)  time: 1.3530 (1.4654)  data: 0.0130 (0.1399)  task_loss: 0.1381 (0.1333)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:08:54  iter: 260  loss: 1.4486 (1.7477)  loss_reg: 0.1909 (0.2376)  loss_centerness: 0.4726 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6239 (0.9048)  time: 1.3518 (1.4655)  data: 0.0128 (0.1400)  task_loss: 0.1381 (0.1333)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:08:25  iter: 280  loss: 1.4716 (1.7466)  loss_reg: 0.1849 (0.2374)  loss_centerness: 0.4726 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6649 (0.9039)  time: 1.2995 (1.4653)  data: 0.0117 (0.1400)  task_loss: 0.1381 (0.1333)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:07:56  iter: 300  loss: 1.4620 (1.7457)  loss_reg: 0.1893 (0.2372)  loss_centerness: 0.4748 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6699 (0.9032)  time: 1.3594 (1.4653)  data: 0.0130 (0.1400)  task_loss: 0.1381 (0.1333)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:07:26  iter: 320  loss: 1.4351 (1.7447)  loss_reg: 0.1972 (0.2371)  loss_centerness: 0.4732 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6536 (0.9023)  time: 1.3081 (1.4651)  data: 0.0115 (0.1399)  task_loss: 0.1380 (0.1334)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:06:57  iter: 340  loss: 1.4518 (1.7438)  loss_reg: 0.1883 (0.2370)  loss_centerness: 0.4719 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6585 (0.9015)  time: 1.3396 (1.4651)  data: 0.0129 (0.1399)  task_loss: 0.1380 (0.1334)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:06:28  iter: 360  loss: 1.4484 (1.7429)  loss_reg: 0.1925 (0.2368)  loss_centerness: 0.4767 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6213 (0.9007)  time: 1.3061 (1.4651)  data: 0.0116 (0.1398)  task_loss: 0.1380 (0.1334)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:05:58  iter: 380  loss: 1.4720 (1.7420)  loss_reg: 0.1870 (0.2367)  loss_centerness: 0.4734 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6628 (0.8999)  time: 1.3284 (1.4649)  data: 0.0131 (0.1398)  task_loss: 0.1380 (0.1334)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:05:29  iter: 400  loss: 1.4261 (1.7409)  loss_reg: 0.1789 (0.2365)  loss_centerness: 0.4716 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6507 (0.8990)  time: 1.3425 (1.4648)  data: 0.0127 (0.1397)  task_loss: 0.1380 (0.1334)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:05:00  iter: 420  loss: 1.4648 (1.7400)  loss_reg: 0.1997 (0.2364)  loss_centerness: 0.4726 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6321 (0.8981)  time: 1.3060 (1.4647)  data: 0.0122 (0.1397)  task_loss: 0.1380 (0.1334)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:04:30  iter: 440  loss: 1.4782 (1.7391)  loss_reg: 0.2034 (0.2363)  loss_centerness: 0.4744 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6618 (0.8973)  time: 1.2980 (1.4645)  data: 0.0115 (0.1396)  task_loss: 0.1380 (0.1335)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:04:01  iter: 460  loss: 1.4197 (1.7380)  loss_reg: 0.1812 (0.2361)  loss_centerness: 0.4719 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6245 (0.8964)  time: 1.3003 (1.4643)  data: 0.0114 (0.1395)  task_loss: 0.1380 (0.1335)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:03:32  iter: 480  loss: 1.4338 (1.7370)  loss_reg: 0.1914 (0.2359)  loss_centerness: 0.4745 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6291 (0.8956)  time: 1.3162 (1.4644)  data: 0.0115 (0.1395)  task_loss: 0.1380 (0.1335)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:03:03  iter: 500  loss: 1.4633 (1.7362)  loss_reg: 0.2025 (0.2359)  loss_centerness: 0.4776 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6493 (0.8948)  time: 1.2965 (1.4643)  data: 0.0128 (0.1395)  task_loss: 0.1380 (0.1335)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:02:33  iter: 520  loss: 1.4206 (1.7352)  loss_reg: 0.1807 (0.2357)  loss_centerness: 0.4721 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6231 (0.8939)  time: 1.3549 (1.4642)  data: 0.0131 (0.1394)  task_loss: 0.1380 (0.1335)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:02:04  iter: 540  loss: 1.4722 (1.7343)  loss_reg: 0.2055 (0.2356)  loss_centerness: 0.4737 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6479 (0.8931)  time: 1.3522 (1.4642)  data: 0.0132 (0.1394)  task_loss: 0.1380 (0.1335)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:01:35  iter: 560  loss: 1.4901 (1.7335)  loss_reg: 0.2070 (0.2354)  loss_centerness: 0.4742 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6673 (0.8924)  time: 1.3463 (1.4641)  data: 0.0130 (0.1394)  task_loss: 0.1380 (0.1336)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:01:05  iter: 580  loss: 1.4417 (1.7325)  loss_reg: 0.2042 (0.2353)  loss_centerness: 0.4756 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6267 (0.8915)  time: 1.3638 (1.4642)  data: 0.0131 (0.1395)  task_loss: 0.1380 (0.1336)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:00:36  iter: 600  loss: 1.5008 (1.7316)  loss_reg: 0.2069 (0.2352)  loss_centerness: 0.4748 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6595 (0.8907)  time: 1.3003 (1.4641)  data: 0.0117 (0.1394)  task_loss: 0.1380 (0.1336)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:00:07  iter: 620  loss: 1.4370 (1.7306)  loss_reg: 0.1890 (0.2351)  loss_centerness: 0.4724 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6349 (0.8899)  time: 1.3160 (1.4640)  data: 0.0117 (0.1394)  task_loss: 0.1380 (0.1336)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:00:00  iter: 625  loss: 1.4370 (1.7304)  loss_reg: 0.1890 (0.2350)  loss_centerness: 0.4725 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6349 (0.8897)  time: 1.3464 (1.4640)  data: 0.0123 (0.1394)  task_loss: 0.1380 (0.1336)  lr: 0.000000  wd: 0.000500  max mem: 12753
Evaluating
2024-03-19 06:14:01,932 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 06:14:10,720 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:14:10,724 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:14:10,763 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.5205479452054794, 0.6712328767123288] 

2024-03-19 06:14:10,763 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:14:10,763 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:14:10,763 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8493150684931506
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.5205479452054794, 0.6712328767123288], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:14:10,786 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 06:14:17,328 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:14:17,332 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 06:14:17,345 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25925925925925924, 0.8888888888888888, 1.0] 

2024-03-19 06:14:17,346 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:14:17,346 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:14:17,346 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.25925925925925924, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:14:17,367 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 06:14:23,503 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:14:23,507 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:14:23,524 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2727272727272727, 0.5227272727272727, 0.75] 

2024-03-19 06:14:23,524 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:14:23,525 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:14:23,525 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.2727272727272727, 0.5227272727272727, 0.75], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:14:23,543 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 06:14:48,074 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:14:48,078 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:14:48,172 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2980392156862745, 0.807843137254902, 0.9176470588235294] 

2024-03-19 06:14:48,172 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:14:48,172 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:14:48,173 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8549019607843137
evaluate on task refcoco, val, 3, res: {'refcoco': [0.2980392156862745, 0.807843137254902, 0.9176470588235294], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:14:48,189 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 06:15:08,871 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:15:08,875 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 06:15:08,967 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.26666666666666666, 0.8, 0.8904761904761904] 

2024-03-19 06:15:08,967 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:15:08,967 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:15:08,968 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8523809523809524
evaluate on task refcoco, val, 4, res: {'refcoco': [0.26666666666666666, 0.8, 0.8904761904761904], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:15:08,986 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 06:15:37,940 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:15:37,944 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:15:38,079 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.22549019607843138, 0.7581699346405228, 0.8823529411764706] 

2024-03-19 06:15:38,080 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:15:38,080 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:15:38,080 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8790849673202614
evaluate on task refcoco, val, 5, res: {'refcoco': [0.22549019607843138, 0.7581699346405228, 0.8823529411764706], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:15:38,099 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 06:16:22,728 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:16:22,731 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:16:22,904 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3037974683544304, 0.8818565400843882, 0.9409282700421941] 

2024-03-19 06:16:22,904 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:16:22,904 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:16:22,905 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8354430379746836
evaluate on task refcoco, val, 6, res: {'refcoco': [0.3037974683544304, 0.8818565400843882, 0.9409282700421941], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:16:22,924 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 7
2024-03-19 06:17:10,523 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:17:10,528 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:17:10,776 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.274, 0.776, 0.868] 

2024-03-19 06:17:10,777 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:17:10,777 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:17:10,777 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.544
evaluate on task refcoco, val, 7, res: {'refcoco': [0.274, 0.776, 0.868], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:17:10,797 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 8
2024-03-19 06:17:57,423 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:17:57,428 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 06:17:57,641 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.388, 0.93, 0.97] 

2024-03-19 06:17:57,642 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:17:57,642 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:17:57,642 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9
evaluate on task refcoco, val, 8, res: {'refcoco': [0.388, 0.93, 0.97], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:17:57,661 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 9
2024-03-19 06:18:44,419 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:18:44,423 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.30000001192092896), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.30000001192092896), ('AR@1000', 0.30000001192092896), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.30000001192092896)]))])
2024-03-19 06:18:44,575 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.228, 0.606, 0.78] 

2024-03-19 06:18:44,575 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:18:44,575 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:18:44,575 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.734
evaluate on task refcoco, val, 9, res: {'refcoco': [0.228, 0.606, 0.78], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:18:44,592 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 10
2024-03-19 06:19:31,612 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:19:31,615 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:19:31,754 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.382, 0.944, 0.978] 

2024-03-19 06:19:31,754 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:19:31,755 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:19:31,755 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.872
evaluate on task refcoco, val, 10, res: {'refcoco': [0.382, 0.944, 0.978], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:19:31,802 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 06:19:32,849 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 06:19:34,046 maskrcnn_benchmark.trainer INFO: Total training time: 0:22:32.974340 (2.1648 s / it)
2024-03-19 06:19:34,073 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 06:19:34,073 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 06:19:34,073 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 06:19:34,073 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 06:19:34,073 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 06:19:34,073 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 06:19:34,073 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 06:19:34,073 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 06:19:34,073 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 06:19:34,073 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 06:19:34,074 maskrcnn_benchmark INFO: visual_prompt.11.dim_1 : Not Frozen, param number, 36
2024-03-19 06:19:34,074 maskrcnn_benchmark INFO: visual_prompt.11.dim_2 : Not Frozen, param number, 64
2024-03-19 06:19:34,074 maskrcnn_benchmark INFO: visual_prompt.11.dim_3 : Not Frozen, param number, 384
2024-03-19 06:19:34,074 maskrcnn_benchmark INFO: textual_prompt.11.dim_1 : Not Frozen, param number, 36
2024-03-19 06:19:34,074 maskrcnn_benchmark INFO: textual_prompt.11.dim_2 : Not Frozen, param number, 64
2024-03-19 06:19:34,074 maskrcnn_benchmark INFO: textual_prompt.11.dim_3 : Not Frozen, param number, 3072
2024-03-19 06:19:34,077 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 06:19:34,077 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=2.61s)
creating index...
index created!
2024-03-19 06:19:37,577 maskrcnn_benchmark INFO: Training on task 11: person, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 06:19:37,789 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 06:19:37,973 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 06:19:38,156 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 06:19:38,340 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 06:19:38,522 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 06:19:38,704 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.39s)
creating index...
index created!
2024-03-19 06:19:40,214 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 06:19:40,415 maskrcnn_benchmark INFO: Testing on task 7: furniture, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 06:19:40,611 maskrcnn_benchmark INFO: Testing on task 8: vehicle, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 06:19:40,796 maskrcnn_benchmark INFO: Testing on task 9: food, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 06:19:40,983 maskrcnn_benchmark INFO: Testing on task 10: animal, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 06:19:41,168 maskrcnn_benchmark INFO: Testing on task 11: person, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
2024-03-19 06:19:41,593 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:45  iter: 20  loss: 1.7893 (1.7307)  loss_reg: 0.1941 (0.2349)  loss_centerness: 0.4746 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9735 (0.8900)  time: 1.4209 (1.4642)  data: 0.1277 (0.1397)  task_loss: 0.1394 (0.1336)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:14:16  iter: 40  loss: 1.5950 (1.7303)  loss_reg: 0.1854 (0.2347)  loss_centerness: 0.4742 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7808 (0.8898)  time: 1.4100 (1.4641)  data: 0.1208 (0.1397)  task_loss: 0.1394 (0.1337)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:13:47  iter: 60  loss: 1.4940 (1.7296)  loss_reg: 0.1825 (0.2346)  loss_centerness: 0.4756 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6922 (0.8892)  time: 1.4491 (1.4641)  data: 0.1289 (0.1396)  task_loss: 0.1394 (0.1337)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:13:17  iter: 80  loss: 1.4716 (1.7287)  loss_reg: 0.1685 (0.2344)  loss_centerness: 0.4736 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6861 (0.8885)  time: 1.4440 (1.4642)  data: 0.1361 (0.1398)  task_loss: 0.1394 (0.1337)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:12:48  iter: 100  loss: 1.4826 (1.7280)  loss_reg: 0.1978 (0.2342)  loss_centerness: 0.4749 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6611 (0.8879)  time: 1.4190 (1.4641)  data: 0.1208 (0.1397)  task_loss: 0.1394 (0.1337)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:12:19  iter: 120  loss: 1.4557 (1.7271)  loss_reg: 0.1919 (0.2341)  loss_centerness: 0.4745 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6400 (0.8871)  time: 1.4366 (1.4641)  data: 0.1404 (0.1397)  task_loss: 0.1394 (0.1337)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:11:50  iter: 140  loss: 1.4245 (1.7261)  loss_reg: 0.1797 (0.2339)  loss_centerness: 0.4731 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6339 (0.8863)  time: 1.4237 (1.4640)  data: 0.1270 (0.1397)  task_loss: 0.1394 (0.1338)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:11:20  iter: 160  loss: 1.4689 (1.7253)  loss_reg: 0.1841 (0.2338)  loss_centerness: 0.4776 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6556 (0.8856)  time: 1.4186 (1.4639)  data: 0.1292 (0.1397)  task_loss: 0.1394 (0.1338)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:10:51  iter: 180  loss: 1.4011 (1.7243)  loss_reg: 0.1838 (0.2336)  loss_centerness: 0.4767 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6036 (0.8847)  time: 1.4349 (1.4639)  data: 0.1310 (0.1396)  task_loss: 0.1394 (0.1338)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:10:22  iter: 200  loss: 1.4117 (1.7233)  loss_reg: 0.1787 (0.2335)  loss_centerness: 0.4742 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6099 (0.8838)  time: 1.4254 (1.4640)  data: 0.1310 (0.1397)  task_loss: 0.1394 (0.1338)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:09:52  iter: 220  loss: 1.4578 (1.7224)  loss_reg: 0.1883 (0.2333)  loss_centerness: 0.4775 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6224 (0.8830)  time: 1.4264 (1.4639)  data: 0.1253 (0.1397)  task_loss: 0.1394 (0.1338)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:09:23  iter: 240  loss: 1.4738 (1.7215)  loss_reg: 0.1840 (0.2332)  loss_centerness: 0.4734 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6581 (0.8822)  time: 1.4115 (1.4638)  data: 0.1235 (0.1397)  task_loss: 0.1394 (0.1338)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:08:54  iter: 260  loss: 1.4399 (1.7206)  loss_reg: 0.1939 (0.2331)  loss_centerness: 0.4759 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6169 (0.8814)  time: 1.4620 (1.4638)  data: 0.1318 (0.1397)  task_loss: 0.1394 (0.1339)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:08:24  iter: 280  loss: 1.3905 (1.7196)  loss_reg: 0.1811 (0.2329)  loss_centerness: 0.4758 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6013 (0.8805)  time: 1.4274 (1.4638)  data: 0.1328 (0.1396)  task_loss: 0.1394 (0.1339)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:07:55  iter: 300  loss: 1.4174 (1.7186)  loss_reg: 0.1831 (0.2328)  loss_centerness: 0.4733 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5892 (0.8797)  time: 1.4381 (1.4637)  data: 0.1257 (0.1396)  task_loss: 0.1394 (0.1339)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:07:26  iter: 320  loss: 1.3838 (1.7175)  loss_reg: 0.1804 (0.2326)  loss_centerness: 0.4757 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5813 (0.8787)  time: 1.4121 (1.4637)  data: 0.1293 (0.1396)  task_loss: 0.1394 (0.1339)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:06:57  iter: 340  loss: 1.4182 (1.7166)  loss_reg: 0.1972 (0.2325)  loss_centerness: 0.4743 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6468 (0.8779)  time: 1.4120 (1.4636)  data: 0.1197 (0.1395)  task_loss: 0.1394 (0.1339)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:06:27  iter: 360  loss: 1.3796 (1.7156)  loss_reg: 0.1804 (0.2323)  loss_centerness: 0.4761 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5933 (0.8770)  time: 1.4354 (1.4635)  data: 0.1255 (0.1395)  task_loss: 0.1394 (0.1340)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:05:58  iter: 380  loss: 1.4134 (1.7147)  loss_reg: 0.1910 (0.2322)  loss_centerness: 0.4744 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6176 (0.8762)  time: 1.4725 (1.4635)  data: 0.1255 (0.1395)  task_loss: 0.1394 (0.1340)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:05:29  iter: 400  loss: 1.3870 (1.7137)  loss_reg: 0.1765 (0.2320)  loss_centerness: 0.4741 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6118 (0.8754)  time: 1.4769 (1.4635)  data: 0.1282 (0.1394)  task_loss: 0.1394 (0.1340)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:05:00  iter: 420  loss: 1.3939 (1.7127)  loss_reg: 0.1851 (0.2319)  loss_centerness: 0.4745 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5793 (0.8745)  time: 1.4212 (1.4638)  data: 0.1273 (0.1396)  task_loss: 0.1394 (0.1340)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:04:30  iter: 440  loss: 1.4000 (1.7117)  loss_reg: 0.1882 (0.2317)  loss_centerness: 0.4769 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5990 (0.8736)  time: 1.4181 (1.4639)  data: 0.1262 (0.1397)  task_loss: 0.1394 (0.1340)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:04:01  iter: 460  loss: 1.3892 (1.7107)  loss_reg: 0.1849 (0.2316)  loss_centerness: 0.4752 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5805 (0.8727)  time: 1.4092 (1.4638)  data: 0.1186 (0.1396)  task_loss: 0.1394 (0.1340)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:03:32  iter: 480  loss: 1.4100 (1.7098)  loss_reg: 0.1777 (0.2315)  loss_centerness: 0.4745 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6069 (0.8719)  time: 1.4266 (1.4637)  data: 0.1342 (0.1396)  task_loss: 0.1394 (0.1341)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:03:02  iter: 500  loss: 1.3837 (1.7088)  loss_reg: 0.1759 (0.2313)  loss_centerness: 0.4745 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5909 (0.8710)  time: 1.4025 (1.4636)  data: 0.1175 (0.1396)  task_loss: 0.1394 (0.1341)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:02:33  iter: 520  loss: 1.4371 (1.7080)  loss_reg: 0.1952 (0.2312)  loss_centerness: 0.4756 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6235 (0.8703)  time: 1.4867 (1.4637)  data: 0.1387 (0.1396)  task_loss: 0.1394 (0.1341)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:02:04  iter: 540  loss: 1.3958 (1.7070)  loss_reg: 0.1859 (0.2311)  loss_centerness: 0.4763 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5866 (0.8694)  time: 1.4248 (1.4638)  data: 0.1311 (0.1397)  task_loss: 0.1394 (0.1341)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:01:35  iter: 560  loss: 1.3637 (1.7059)  loss_reg: 0.1828 (0.2309)  loss_centerness: 0.4755 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5582 (0.8685)  time: 1.4171 (1.4637)  data: 0.1239 (0.1397)  task_loss: 0.1394 (0.1341)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:01:05  iter: 580  loss: 1.3708 (1.7049)  loss_reg: 0.1769 (0.2308)  loss_centerness: 0.4740 (0.4776)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5749 (0.8676)  time: 1.4202 (1.4636)  data: 0.1306 (0.1396)  task_loss: 0.1394 (0.1342)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:00:36  iter: 600  loss: 1.3815 (1.7040)  loss_reg: 0.1920 (0.2307)  loss_centerness: 0.4750 (0.4776)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5825 (0.8668)  time: 1.4012 (1.4635)  data: 0.1196 (0.1396)  task_loss: 0.1393 (0.1342)  lr: 0.010000  wd: 0.000500  max mem: 12779
eta: 0:00:07  iter: 620  loss: 1.3780 (1.7031)  loss_reg: 0.1898 (0.2305)  loss_centerness: 0.4738 (0.4776)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5905 (0.8660)  time: 1.4330 (1.4634)  data: 0.1283 (0.1396)  task_loss: 0.1393 (0.1342)  lr: 0.010000  wd: 0.000500  max mem: 12780
eta: 0:00:00  iter: 625  loss: 1.3932 (1.7029)  loss_reg: 0.1949 (0.2305)  loss_centerness: 0.4740 (0.4776)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5889 (0.8658)  time: 1.4154 (1.4634)  data: 0.1283 (0.1396)  task_loss: 0.1393 (0.1342)  lr: 0.000000  wd: 0.000500  max mem: 12780
Evaluating
2024-03-19 06:36:43,052 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 06:36:51,487 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:36:51,492 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:36:51,526 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.5205479452054794, 0.6712328767123288] 

2024-03-19 06:36:51,526 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:36:51,527 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:36:51,527 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8493150684931506
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.5205479452054794, 0.6712328767123288], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:36:51,543 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 06:36:55,863 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:36:55,866 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 06:36:55,879 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2222222222222222, 0.8888888888888888, 1.0] 

2024-03-19 06:36:55,879 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:36:55,879 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:36:55,879 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8148148148148148
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2222222222222222, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:36:55,895 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 06:37:01,837 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:37:01,841 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:37:01,858 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.29545454545454547, 0.5227272727272727, 0.75] 

2024-03-19 06:37:01,858 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:37:01,858 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:37:01,858 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.29545454545454547, 0.5227272727272727, 0.75], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:37:01,875 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 06:37:26,494 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:37:26,498 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:37:26,605 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2784313725490196, 0.7725490196078432, 0.8862745098039215] 

2024-03-19 06:37:26,606 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:37:26,606 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:37:26,606 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8352941176470589
evaluate on task refcoco, val, 3, res: {'refcoco': [0.2784313725490196, 0.7725490196078432, 0.8862745098039215], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:37:26,625 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 06:37:47,778 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:37:47,783 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 06:37:47,882 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.26666666666666666, 0.8, 0.8952380952380953] 

2024-03-19 06:37:47,882 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:37:47,882 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:37:47,883 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8523809523809524
evaluate on task refcoco, val, 4, res: {'refcoco': [0.26666666666666666, 0.8, 0.8952380952380953], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:37:47,904 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 06:38:16,642 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:38:16,646 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:38:16,779 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.22549019607843138, 0.7581699346405228, 0.8823529411764706] 

2024-03-19 06:38:16,779 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:38:16,780 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:38:16,780 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8790849673202614
evaluate on task refcoco, val, 5, res: {'refcoco': [0.22549019607843138, 0.7581699346405228, 0.8823529411764706], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:38:16,798 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 06:39:01,119 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:39:01,123 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:39:01,268 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2974683544303797, 0.8818565400843882, 0.9367088607594937] 

2024-03-19 06:39:01,268 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:39:01,268 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:39:01,268 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8227848101265823
evaluate on task refcoco, val, 6, res: {'refcoco': [0.2974683544303797, 0.8818565400843882, 0.9367088607594937], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:39:01,286 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 7
2024-03-19 06:39:46,481 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:39:46,485 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:39:46,679 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.238, 0.724, 0.824] 

2024-03-19 06:39:46,679 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:39:46,679 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:39:46,679 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.458
evaluate on task refcoco, val, 7, res: {'refcoco': [0.238, 0.724, 0.824], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:39:46,700 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 8
2024-03-19 06:40:32,987 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:40:32,990 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 06:40:33,162 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.382, 0.918, 0.958] 

2024-03-19 06:40:33,162 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:40:33,162 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:40:33,162 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.888
evaluate on task refcoco, val, 8, res: {'refcoco': [0.382, 0.918, 0.958], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:40:33,179 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 9
2024-03-19 06:41:19,454 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:41:19,457 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.30000001192092896), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.30000001192092896), ('AR@1000', 0.30000001192092896), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.30000001192092896)]))])
2024-03-19 06:41:19,639 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.218, 0.612, 0.79] 

2024-03-19 06:41:19,639 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:41:19,640 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:41:19,640 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.722
evaluate on task refcoco, val, 9, res: {'refcoco': [0.218, 0.612, 0.79], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:41:19,659 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 10
2024-03-19 06:42:05,648 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:42:05,651 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:42:05,788 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.374, 0.942, 0.98] 

2024-03-19 06:42:05,789 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:42:05,789 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:42:05,789 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.86
evaluate on task refcoco, val, 10, res: {'refcoco': [0.374, 0.942, 0.98], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:42:05,806 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 11
2024-03-19 06:42:52,022 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:42:52,026 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:42:52,240 maskrcnn_benchmark INFO: Task[[tensor([11], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.298, 0.838, 0.932] 

2024-03-19 06:42:52,241 maskrcnn_benchmark INFO: Task[[tensor([11], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:42:52,241 maskrcnn_benchmark INFO: Task[[tensor([11], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:42:52,241 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.602
evaluate on task refcoco, val, 11, res: {'refcoco': [0.298, 0.838, 0.932], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:42:52,296 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 06:42:54,296 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 06:42:55,518 maskrcnn_benchmark.trainer INFO: Total training time: 0:23:13.909507 (2.2303 s / it)
{0: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.5205479452054794, 0.6575342465753424]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 1: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.5205479452054794, 0.6575342465753424], 1: [0.2222222222222222, 0.8518518518518519, 1.0]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 2: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.5205479452054794, 0.6575342465753424], 1: [0.2222222222222222, 0.8518518518518519, 1.0], 2: [0.3409090909090909, 0.5454545454545454, 0.7954545454545454]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 3: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.5205479452054794, 0.6575342465753424], 1: [0.2962962962962963, 0.8888888888888888, 1.0], 2: [0.36363636363636365, 0.5454545454545454, 0.75], 3: [0.30196078431372547, 0.8156862745098039, 0.9215686274509803]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 4: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1506849315068493, 0.5205479452054794, 0.6575342465753424], 1: [0.2962962962962963, 0.8888888888888888, 1.0], 2: [0.3181818181818182, 0.5227272727272727, 0.7272727272727273], 3: [0.2980392156862745, 0.8196078431372549, 0.9215686274509803], 4: [0.2714285714285714, 0.7857142857142857, 0.9]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 5: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.4794520547945205, 0.6575342465753424], 1: [0.2962962962962963, 0.8888888888888888, 1.0], 2: [0.3181818181818182, 0.5227272727272727, 0.7272727272727273], 3: [0.3176470588235294, 0.8235294117647058, 0.9215686274509803], 4: [0.2761904761904762, 0.8047619047619048, 0.9], 5: [0.23529411764705882, 0.7483660130718954, 0.8921568627450981]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 6: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.4931506849315068, 0.6438356164383562], 1: [0.2222222222222222, 0.8888888888888888, 1.0], 2: [0.2727272727272727, 0.5227272727272727, 0.7272727272727273], 3: [0.3176470588235294, 0.8274509803921568, 0.9215686274509803], 4: [0.2761904761904762, 0.8, 0.8857142857142857], 5: [0.23202614379084968, 0.7483660130718954, 0.8823529411764706], 6: [0.339662447257384, 0.919831223628692, 0.9704641350210971]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 7: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.4931506849315068, 0.6712328767123288], 1: [0.2962962962962963, 0.8888888888888888, 1.0], 2: [0.2727272727272727, 0.5227272727272727, 0.7272727272727273], 3: [0.30196078431372547, 0.807843137254902, 0.9098039215686274], 4: [0.2761904761904762, 0.8047619047619048, 0.8857142857142857], 5: [0.22875816993464052, 0.7450980392156863, 0.8823529411764706], 6: [0.3291139240506329, 0.9177215189873418, 0.9704641350210971], 7: [0.31, 0.772, 0.872]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 8: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.5068493150684932, 0.6712328767123288], 1: [0.2962962962962963, 0.8888888888888888, 1.0], 2: [0.2727272727272727, 0.5227272727272727, 0.7272727272727273], 3: [0.2980392156862745, 0.807843137254902, 0.9098039215686274], 4: [0.2761904761904762, 0.8047619047619048, 0.8904761904761904], 5: [0.23202614379084968, 0.7483660130718954, 0.8823529411764706], 6: [0.33122362869198313, 0.9177215189873418, 0.9704641350210971], 7: [0.306, 0.774, 0.872], 8: [0.39, 0.932, 0.97]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 9: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.5068493150684932, 0.6712328767123288], 1: [0.2222222222222222, 0.8888888888888888, 1.0], 2: [0.2727272727272727, 0.5227272727272727, 0.75], 3: [0.2980392156862745, 0.807843137254902, 0.9176470588235294], 4: [0.2761904761904762, 0.8047619047619048, 0.8904761904761904], 5: [0.22875816993464052, 0.7483660130718954, 0.8823529411764706], 6: [0.3080168776371308, 0.8818565400843882, 0.9451476793248945], 7: [0.294, 0.772, 0.866], 8: [0.39, 0.932, 0.97], 9: [0.228, 0.602, 0.78]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 10: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.5205479452054794, 0.6712328767123288], 1: [0.25925925925925924, 0.8888888888888888, 1.0], 2: [0.2727272727272727, 0.5227272727272727, 0.75], 3: [0.2980392156862745, 0.807843137254902, 0.9176470588235294], 4: [0.26666666666666666, 0.8, 0.8904761904761904], 5: [0.22549019607843138, 0.7581699346405228, 0.8823529411764706], 6: [0.3037974683544304, 0.8818565400843882, 0.9409282700421941], 7: [0.274, 0.776, 0.868], 8: [0.388, 0.93, 0.97], 9: [0.228, 0.606, 0.78], 10: [0.382, 0.944, 0.978]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 11: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.5205479452054794, 0.6712328767123288], 1: [0.2222222222222222, 0.8888888888888888, 1.0], 2: [0.29545454545454547, 0.5227272727272727, 0.75], 3: [0.2784313725490196, 0.7725490196078432, 0.8862745098039215], 4: [0.26666666666666666, 0.8, 0.8952380952380953], 5: [0.22549019607843138, 0.7581699346405228, 0.8823529411764706], 6: [0.2974683544303797, 0.8818565400843882, 0.9367088607594937], 7: [0.238, 0.724, 0.824], 8: [0.382, 0.918, 0.958], 9: [0.218, 0.612, 0.79], 10: [0.374, 0.942, 0.98], 11: [0.298, 0.838, 0.932]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}}
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: False
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 3
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('refexp_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('refexp_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: True
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
LPAI:
  INTERACT: True
  INTERACT_LORA_D: 4
  LAYER_ALIGNMENT: True
  PROMPT_DEPTH: 9
  PROMPT_LORA: True
  PROMPT_LORA_D: 4
  TASK_ALIGNMENT: False
  TEXTUAL_PROMPT: True
  VISUAL_PROMPT: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: False
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: False
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: MODEL/glip_a_tiny_o365.pth
OUTPUT_DIR: OUTPUT
PATHS_CATALOG: /root/workspace/grounding/prompt_grounding/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: 4
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 0.0001
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: True
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 32
  LANG_LR: 0.0001
  MAX_EPOCH: 30
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.0
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 10
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 2
  TEST_WITH_INFERENCE: True
  TUNING_HIGHLEVEL_OVERRIDE: language_prompt_v4
  USE_AMP: True
  USE_AUTOSTEP: True
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: True
  EVAL_TASK: grounding
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 1
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
args.opts []
2024-03-19 06:43:00,338 maskrcnn_benchmark INFO: Using 1 GPUs
2024-03-19 06:43:00,338 maskrcnn_benchmark INFO: Namespace(config_file='configs/refcoco/finetune_A_decompose_layer_interact.yaml', custom_shot_and_epoch_and_general_copy='0_10_1', distributed=False, evaluate_only_best_on_test=False, ft_tasks='', keep_testing=False, local_rank=0, opts=[], push_both_val_and_test=False, shuffle_seeds=None, skip_optimizer_resume=False, skip_test=True, skip_train=False, use_prepared_data=False)
2024-03-19 06:43:00,338 maskrcnn_benchmark INFO: Loaded configuration file configs/refcoco/finetune_A_decompose_layer_interact.yaml
2024-03-19 06:43:00,338 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "MODEL/glip_a_tiny_o365.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: False
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True

    USE_CHECKPOINT: False

TEST:
  DURING_TRAINING: True
  IMS_PER_BATCH: 1
  EVAL_TASK: grounding
# use for grounding model
DATASETS:
  TRAIN: ("refexp_train", )
  TEST: ("refexp_val",)
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

  USE_OVERRIDE_CATEGORY: True
  SHUFFLE_SEED: 3

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.0001
  WEIGHT_DECAY: 0.05
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 32
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.0
  FIND_UNUSED_PARAMETERS: True

  TEST_WITH_INFERENCE: True
  USE_AUTOSTEP: True
#  USE_COSINE: True

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0

  SEED: 10
  STEP_PATIENCE: 2
  AUTO_TERMINATE_PATIENCE: 4
  TUNING_HIGHLEVEL_OVERRIDE: language_prompt_v4

LPAI:
  VISUAL_PROMPT: True
  TEXTUAL_PROMPT: True
  TASK_ALIGNMENT: False
  LAYER_ALIGNMENT: True
  INTERACT: True
  PROMPT_DEPTH: 9

  PROMPT_LORA_D: 4
  INTERACT_LORA_D: 4
  PROMPT_LORA: True

2024-03-19 06:43:00,339 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: False
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 3
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('refexp_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('refexp_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: True
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
LPAI:
  INTERACT: True
  INTERACT_LORA_D: 4
  LAYER_ALIGNMENT: True
  PROMPT_DEPTH: 9
  PROMPT_LORA: True
  PROMPT_LORA_D: 4
  TASK_ALIGNMENT: False
  TEXTUAL_PROMPT: True
  VISUAL_PROMPT: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: False
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: False
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: MODEL/glip_a_tiny_o365.pth
OUTPUT_DIR: OUTPUT
PATHS_CATALOG: /root/workspace/grounding/prompt_grounding/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: 4
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 0.0001
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: True
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 32
  LANG_LR: 0.0001
  MAX_EPOCH: 30
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.0
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 10
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 2
  TEST_WITH_INFERENCE: True
  TUNING_HIGHLEVEL_OVERRIDE: language_prompt_v4
  USE_AMP: True
  USE_AUTOSTEP: True
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: True
  EVAL_TASK: grounding
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 1
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
2024-03-19 06:43:00,339 maskrcnn_benchmark INFO: Saving config into: OUTPUT/config.yml
2024-03-19 06:43:00,394 maskrcnn_benchmark INFO: Loaded fine-tune configuration file configs/refcoco/finetune_A_decompose_layer_interact.yaml
2024-03-19 06:43:00,394 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "MODEL/glip_a_tiny_o365.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: False
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True

    USE_CHECKPOINT: False

TEST:
  DURING_TRAINING: True
  IMS_PER_BATCH: 1
  EVAL_TASK: grounding
# use for grounding model
DATASETS:
  TRAIN: ("refexp_train", )
  TEST: ("refexp_val",)
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

  USE_OVERRIDE_CATEGORY: True
  SHUFFLE_SEED: 3

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.0001
  WEIGHT_DECAY: 0.05
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 32
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.0
  FIND_UNUSED_PARAMETERS: True

  TEST_WITH_INFERENCE: True
  USE_AUTOSTEP: True
#  USE_COSINE: True

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0

  SEED: 10
  STEP_PATIENCE: 2
  AUTO_TERMINATE_PATIENCE: 4
  TUNING_HIGHLEVEL_OVERRIDE: language_prompt_v4

LPAI:
  VISUAL_PROMPT: True
  TEXTUAL_PROMPT: True
  TASK_ALIGNMENT: False
  LAYER_ALIGNMENT: True
  INTERACT: True
  PROMPT_DEPTH: 9

  PROMPT_LORA_D: 4
  INTERACT_LORA_D: 4
  PROMPT_LORA: True

Saving config into: OUTPUT/ft_task_1/config.yml
2024-03-19 06:43:00,429 maskrcnn_benchmark INFO: Training configs/refcoco/finetune_A_decompose_layer_interact.yaml
VISION BACKBONE USE GRADIENT CHECKPOINTING:  False
LANGUAGE BACKBONE USE GRADIENT CHECKPOINTING:  False
2024-03-19 06:43:08,577 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.proj.bias                                          loaded from backbone.body.layers.0.blocks.0.attn.proj.bias                                  of shape (96,)
2024-03-19 06:43:08,577 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.proj.weight                                        loaded from backbone.body.layers.0.blocks.0.attn.proj.weight                                of shape (96, 96)
2024-03-19 06:43:08,577 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.qkv.bias                                           loaded from backbone.body.layers.0.blocks.0.attn.qkv.bias                                   of shape (288,)
2024-03-19 06:43:08,577 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.qkv.weight                                         loaded from backbone.body.layers.0.blocks.0.attn.qkv.weight                                 of shape (288, 96)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.relative_position_bias_table                       loaded from backbone.body.layers.0.blocks.0.attn.relative_position_bias_table               of shape (169, 3)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.relative_position_index                            loaded from backbone.body.layers.0.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.mlp.fc1.bias                                            loaded from backbone.body.layers.0.blocks.0.mlp.fc1.bias                                    of shape (384,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.mlp.fc1.weight                                          loaded from backbone.body.layers.0.blocks.0.mlp.fc1.weight                                  of shape (384, 96)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.mlp.fc2.bias                                            loaded from backbone.body.layers.0.blocks.0.mlp.fc2.bias                                    of shape (96,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.mlp.fc2.weight                                          loaded from backbone.body.layers.0.blocks.0.mlp.fc2.weight                                  of shape (96, 384)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.norm1.bias                                              loaded from backbone.body.layers.0.blocks.0.norm1.bias                                      of shape (96,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.norm1.weight                                            loaded from backbone.body.layers.0.blocks.0.norm1.weight                                    of shape (96,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.norm2.bias                                              loaded from backbone.body.layers.0.blocks.0.norm2.bias                                      of shape (96,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.norm2.weight                                            loaded from backbone.body.layers.0.blocks.0.norm2.weight                                    of shape (96,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.proj.bias                                          loaded from backbone.body.layers.0.blocks.1.attn.proj.bias                                  of shape (96,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.proj.weight                                        loaded from backbone.body.layers.0.blocks.1.attn.proj.weight                                of shape (96, 96)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.qkv.bias                                           loaded from backbone.body.layers.0.blocks.1.attn.qkv.bias                                   of shape (288,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.qkv.weight                                         loaded from backbone.body.layers.0.blocks.1.attn.qkv.weight                                 of shape (288, 96)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.relative_position_bias_table                       loaded from backbone.body.layers.0.blocks.1.attn.relative_position_bias_table               of shape (169, 3)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.relative_position_index                            loaded from backbone.body.layers.0.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.mlp.fc1.bias                                            loaded from backbone.body.layers.0.blocks.1.mlp.fc1.bias                                    of shape (384,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.mlp.fc1.weight                                          loaded from backbone.body.layers.0.blocks.1.mlp.fc1.weight                                  of shape (384, 96)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.mlp.fc2.bias                                            loaded from backbone.body.layers.0.blocks.1.mlp.fc2.bias                                    of shape (96,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.mlp.fc2.weight                                          loaded from backbone.body.layers.0.blocks.1.mlp.fc2.weight                                  of shape (96, 384)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.norm1.bias                                              loaded from backbone.body.layers.0.blocks.1.norm1.bias                                      of shape (96,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.norm1.weight                                            loaded from backbone.body.layers.0.blocks.1.norm1.weight                                    of shape (96,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.norm2.bias                                              loaded from backbone.body.layers.0.blocks.1.norm2.bias                                      of shape (96,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.norm2.weight                                            loaded from backbone.body.layers.0.blocks.1.norm2.weight                                    of shape (96,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.downsample.norm.bias                                             loaded from backbone.body.layers.0.downsample.norm.bias                                     of shape (384,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.downsample.norm.weight                                           loaded from backbone.body.layers.0.downsample.norm.weight                                   of shape (384,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.downsample.reduction.weight                                      loaded from backbone.body.layers.0.downsample.reduction.weight                              of shape (192, 384)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.proj.bias                                          loaded from backbone.body.layers.1.blocks.0.attn.proj.bias                                  of shape (192,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.proj.weight                                        loaded from backbone.body.layers.1.blocks.0.attn.proj.weight                                of shape (192, 192)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.qkv.bias                                           loaded from backbone.body.layers.1.blocks.0.attn.qkv.bias                                   of shape (576,)
2024-03-19 06:43:08,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.qkv.weight                                         loaded from backbone.body.layers.1.blocks.0.attn.qkv.weight                                 of shape (576, 192)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.relative_position_bias_table                       loaded from backbone.body.layers.1.blocks.0.attn.relative_position_bias_table               of shape (169, 6)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.relative_position_index                            loaded from backbone.body.layers.1.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.mlp.fc1.bias                                            loaded from backbone.body.layers.1.blocks.0.mlp.fc1.bias                                    of shape (768,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.mlp.fc1.weight                                          loaded from backbone.body.layers.1.blocks.0.mlp.fc1.weight                                  of shape (768, 192)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.mlp.fc2.bias                                            loaded from backbone.body.layers.1.blocks.0.mlp.fc2.bias                                    of shape (192,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.mlp.fc2.weight                                          loaded from backbone.body.layers.1.blocks.0.mlp.fc2.weight                                  of shape (192, 768)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.norm1.bias                                              loaded from backbone.body.layers.1.blocks.0.norm1.bias                                      of shape (192,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.norm1.weight                                            loaded from backbone.body.layers.1.blocks.0.norm1.weight                                    of shape (192,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.norm2.bias                                              loaded from backbone.body.layers.1.blocks.0.norm2.bias                                      of shape (192,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.norm2.weight                                            loaded from backbone.body.layers.1.blocks.0.norm2.weight                                    of shape (192,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.proj.bias                                          loaded from backbone.body.layers.1.blocks.1.attn.proj.bias                                  of shape (192,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.proj.weight                                        loaded from backbone.body.layers.1.blocks.1.attn.proj.weight                                of shape (192, 192)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.qkv.bias                                           loaded from backbone.body.layers.1.blocks.1.attn.qkv.bias                                   of shape (576,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.qkv.weight                                         loaded from backbone.body.layers.1.blocks.1.attn.qkv.weight                                 of shape (576, 192)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.relative_position_bias_table                       loaded from backbone.body.layers.1.blocks.1.attn.relative_position_bias_table               of shape (169, 6)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.relative_position_index                            loaded from backbone.body.layers.1.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.mlp.fc1.bias                                            loaded from backbone.body.layers.1.blocks.1.mlp.fc1.bias                                    of shape (768,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.mlp.fc1.weight                                          loaded from backbone.body.layers.1.blocks.1.mlp.fc1.weight                                  of shape (768, 192)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.mlp.fc2.bias                                            loaded from backbone.body.layers.1.blocks.1.mlp.fc2.bias                                    of shape (192,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.mlp.fc2.weight                                          loaded from backbone.body.layers.1.blocks.1.mlp.fc2.weight                                  of shape (192, 768)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.norm1.bias                                              loaded from backbone.body.layers.1.blocks.1.norm1.bias                                      of shape (192,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.norm1.weight                                            loaded from backbone.body.layers.1.blocks.1.norm1.weight                                    of shape (192,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.norm2.bias                                              loaded from backbone.body.layers.1.blocks.1.norm2.bias                                      of shape (192,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.norm2.weight                                            loaded from backbone.body.layers.1.blocks.1.norm2.weight                                    of shape (192,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.downsample.norm.bias                                             loaded from backbone.body.layers.1.downsample.norm.bias                                     of shape (768,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.downsample.norm.weight                                           loaded from backbone.body.layers.1.downsample.norm.weight                                   of shape (768,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.downsample.reduction.weight                                      loaded from backbone.body.layers.1.downsample.reduction.weight                              of shape (384, 768)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.0.attn.proj.bias                                  of shape (384,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.0.attn.proj.weight                                of shape (384, 384)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.0.attn.qkv.bias                                   of shape (1152,)
2024-03-19 06:43:08,579 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.0.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.0.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.0.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.0.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.0.mlp.fc2.bias                                    of shape (384,)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.0.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.norm1.bias                                              loaded from backbone.body.layers.2.blocks.0.norm1.bias                                      of shape (384,)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.norm1.weight                                            loaded from backbone.body.layers.2.blocks.0.norm1.weight                                    of shape (384,)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.norm2.bias                                              loaded from backbone.body.layers.2.blocks.0.norm2.bias                                      of shape (384,)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.norm2.weight                                            loaded from backbone.body.layers.2.blocks.0.norm2.weight                                    of shape (384,)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.1.attn.proj.bias                                  of shape (384,)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.1.attn.proj.weight                                of shape (384, 384)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.1.attn.qkv.bias                                   of shape (1152,)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.1.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.1.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.1.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.1.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.1.mlp.fc2.bias                                    of shape (384,)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.1.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 06:43:08,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.norm1.bias                                              loaded from backbone.body.layers.2.blocks.1.norm1.bias                                      of shape (384,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.norm1.weight                                            loaded from backbone.body.layers.2.blocks.1.norm1.weight                                    of shape (384,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.norm2.bias                                              loaded from backbone.body.layers.2.blocks.1.norm2.bias                                      of shape (384,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.norm2.weight                                            loaded from backbone.body.layers.2.blocks.1.norm2.weight                                    of shape (384,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.2.attn.proj.bias                                  of shape (384,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.2.attn.proj.weight                                of shape (384, 384)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.2.attn.qkv.bias                                   of shape (1152,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.2.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.2.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.2.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.2.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.2.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.2.mlp.fc2.bias                                    of shape (384,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.2.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.norm1.bias                                              loaded from backbone.body.layers.2.blocks.2.norm1.bias                                      of shape (384,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.norm1.weight                                            loaded from backbone.body.layers.2.blocks.2.norm1.weight                                    of shape (384,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.norm2.bias                                              loaded from backbone.body.layers.2.blocks.2.norm2.bias                                      of shape (384,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.norm2.weight                                            loaded from backbone.body.layers.2.blocks.2.norm2.weight                                    of shape (384,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.3.attn.proj.bias                                  of shape (384,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.3.attn.proj.weight                                of shape (384, 384)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.3.attn.qkv.bias                                   of shape (1152,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.3.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.3.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.3.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.3.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.3.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.3.mlp.fc2.bias                                    of shape (384,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.3.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.norm1.bias                                              loaded from backbone.body.layers.2.blocks.3.norm1.bias                                      of shape (384,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.norm1.weight                                            loaded from backbone.body.layers.2.blocks.3.norm1.weight                                    of shape (384,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.norm2.bias                                              loaded from backbone.body.layers.2.blocks.3.norm2.bias                                      of shape (384,)
2024-03-19 06:43:08,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.norm2.weight                                            loaded from backbone.body.layers.2.blocks.3.norm2.weight                                    of shape (384,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.4.attn.proj.bias                                  of shape (384,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.4.attn.proj.weight                                of shape (384, 384)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.4.attn.qkv.bias                                   of shape (1152,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.4.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.4.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.4.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.4.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.4.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.4.mlp.fc2.bias                                    of shape (384,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.4.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.norm1.bias                                              loaded from backbone.body.layers.2.blocks.4.norm1.bias                                      of shape (384,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.norm1.weight                                            loaded from backbone.body.layers.2.blocks.4.norm1.weight                                    of shape (384,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.norm2.bias                                              loaded from backbone.body.layers.2.blocks.4.norm2.bias                                      of shape (384,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.norm2.weight                                            loaded from backbone.body.layers.2.blocks.4.norm2.weight                                    of shape (384,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.5.attn.proj.bias                                  of shape (384,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.5.attn.proj.weight                                of shape (384, 384)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.5.attn.qkv.bias                                   of shape (1152,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.5.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.5.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.5.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.5.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.5.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.5.mlp.fc2.bias                                    of shape (384,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.5.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.norm1.bias                                              loaded from backbone.body.layers.2.blocks.5.norm1.bias                                      of shape (384,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.norm1.weight                                            loaded from backbone.body.layers.2.blocks.5.norm1.weight                                    of shape (384,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.norm2.bias                                              loaded from backbone.body.layers.2.blocks.5.norm2.bias                                      of shape (384,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.norm2.weight                                            loaded from backbone.body.layers.2.blocks.5.norm2.weight                                    of shape (384,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.downsample.norm.bias                                             loaded from backbone.body.layers.2.downsample.norm.bias                                     of shape (1536,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.downsample.norm.weight                                           loaded from backbone.body.layers.2.downsample.norm.weight                                   of shape (1536,)
2024-03-19 06:43:08,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.downsample.reduction.weight                                      loaded from backbone.body.layers.2.downsample.reduction.weight                              of shape (768, 1536)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.proj.bias                                          loaded from backbone.body.layers.3.blocks.0.attn.proj.bias                                  of shape (768,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.proj.weight                                        loaded from backbone.body.layers.3.blocks.0.attn.proj.weight                                of shape (768, 768)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.qkv.bias                                           loaded from backbone.body.layers.3.blocks.0.attn.qkv.bias                                   of shape (2304,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.qkv.weight                                         loaded from backbone.body.layers.3.blocks.0.attn.qkv.weight                                 of shape (2304, 768)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.relative_position_bias_table                       loaded from backbone.body.layers.3.blocks.0.attn.relative_position_bias_table               of shape (169, 24)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.relative_position_index                            loaded from backbone.body.layers.3.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.mlp.fc1.bias                                            loaded from backbone.body.layers.3.blocks.0.mlp.fc1.bias                                    of shape (3072,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.mlp.fc1.weight                                          loaded from backbone.body.layers.3.blocks.0.mlp.fc1.weight                                  of shape (3072, 768)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.mlp.fc2.bias                                            loaded from backbone.body.layers.3.blocks.0.mlp.fc2.bias                                    of shape (768,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.mlp.fc2.weight                                          loaded from backbone.body.layers.3.blocks.0.mlp.fc2.weight                                  of shape (768, 3072)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.norm1.bias                                              loaded from backbone.body.layers.3.blocks.0.norm1.bias                                      of shape (768,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.norm1.weight                                            loaded from backbone.body.layers.3.blocks.0.norm1.weight                                    of shape (768,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.norm2.bias                                              loaded from backbone.body.layers.3.blocks.0.norm2.bias                                      of shape (768,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.norm2.weight                                            loaded from backbone.body.layers.3.blocks.0.norm2.weight                                    of shape (768,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.proj.bias                                          loaded from backbone.body.layers.3.blocks.1.attn.proj.bias                                  of shape (768,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.proj.weight                                        loaded from backbone.body.layers.3.blocks.1.attn.proj.weight                                of shape (768, 768)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.qkv.bias                                           loaded from backbone.body.layers.3.blocks.1.attn.qkv.bias                                   of shape (2304,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.qkv.weight                                         loaded from backbone.body.layers.3.blocks.1.attn.qkv.weight                                 of shape (2304, 768)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.relative_position_bias_table                       loaded from backbone.body.layers.3.blocks.1.attn.relative_position_bias_table               of shape (169, 24)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.relative_position_index                            loaded from backbone.body.layers.3.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.mlp.fc1.bias                                            loaded from backbone.body.layers.3.blocks.1.mlp.fc1.bias                                    of shape (3072,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.mlp.fc1.weight                                          loaded from backbone.body.layers.3.blocks.1.mlp.fc1.weight                                  of shape (3072, 768)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.mlp.fc2.bias                                            loaded from backbone.body.layers.3.blocks.1.mlp.fc2.bias                                    of shape (768,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.mlp.fc2.weight                                          loaded from backbone.body.layers.3.blocks.1.mlp.fc2.weight                                  of shape (768, 3072)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.norm1.bias                                              loaded from backbone.body.layers.3.blocks.1.norm1.bias                                      of shape (768,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.norm1.weight                                            loaded from backbone.body.layers.3.blocks.1.norm1.weight                                    of shape (768,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.norm2.bias                                              loaded from backbone.body.layers.3.blocks.1.norm2.bias                                      of shape (768,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.norm2.weight                                            loaded from backbone.body.layers.3.blocks.1.norm2.weight                                    of shape (768,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm1.bias                                                                loaded from backbone.body.norm1.bias                                                        of shape (192,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm1.weight                                                              loaded from backbone.body.norm1.weight                                                      of shape (192,)
2024-03-19 06:43:08,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm2.bias                                                                loaded from backbone.body.norm2.bias                                                        of shape (384,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm2.weight                                                              loaded from backbone.body.norm2.weight                                                      of shape (384,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm3.bias                                                                loaded from backbone.body.norm3.bias                                                        of shape (768,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm3.weight                                                              loaded from backbone.body.norm3.weight                                                      of shape (768,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.patch_embed.norm.bias                                                     loaded from backbone.body.patch_embed.norm.bias                                             of shape (96,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.patch_embed.norm.weight                                                   loaded from backbone.body.patch_embed.norm.weight                                           of shape (96,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.patch_embed.proj.bias                                                     loaded from backbone.body.patch_embed.proj.bias                                             of shape (96,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.patch_embed.proj.weight                                                   loaded from backbone.body.patch_embed.proj.weight                                           of shape (96, 3, 4, 4)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                                                            loaded from backbone.fpn.fpn_inner2.bias                                                    of shape (256,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                                                          loaded from backbone.fpn.fpn_inner2.weight                                                  of shape (256, 192, 1, 1)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                                                            loaded from backbone.fpn.fpn_inner3.bias                                                    of shape (256,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                                                          loaded from backbone.fpn.fpn_inner3.weight                                                  of shape (256, 384, 1, 1)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                                                            loaded from backbone.fpn.fpn_inner4.bias                                                    of shape (256,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                                                          loaded from backbone.fpn.fpn_inner4.weight                                                  of shape (256, 768, 1, 1)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                                                            loaded from backbone.fpn.fpn_layer2.bias                                                    of shape (256,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                                                          loaded from backbone.fpn.fpn_layer2.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                                                            loaded from backbone.fpn.fpn_layer3.bias                                                    of shape (256,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                                                          loaded from backbone.fpn.fpn_layer3.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                                                            loaded from backbone.fpn.fpn_layer4.bias                                                    of shape (256,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                                                          loaded from backbone.fpn.fpn_layer4.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.top_blocks.p6.bias                                                         loaded from backbone.fpn.top_blocks.p6.bias                                                 of shape (256,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.top_blocks.p6.weight                                                       loaded from backbone.fpn.top_blocks.p6.weight                                               of shape (256, 256, 3, 3)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.top_blocks.p7.bias                                                         loaded from backbone.fpn.top_blocks.p7.bias                                                 of shape (256,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.top_blocks.p7.weight                                                       loaded from backbone.fpn.top_blocks.p7.weight                                               of shape (256, 256, 3, 3)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.proj.bias                                  loaded from backbone.body.layers.0.blocks.0.attn.proj.bias                                  of shape (96,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.proj.weight                                loaded from backbone.body.layers.0.blocks.0.attn.proj.weight                                of shape (96, 96)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.qkv.bias                                   loaded from backbone.body.layers.0.blocks.0.attn.qkv.bias                                   of shape (288,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.qkv.weight                                 loaded from backbone.body.layers.0.blocks.0.attn.qkv.weight                                 of shape (288, 96)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.relative_position_bias_table               loaded from backbone.body.layers.0.blocks.0.attn.relative_position_bias_table               of shape (169, 3)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.relative_position_index                    loaded from backbone.body.layers.0.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.mlp.fc1.bias                                    loaded from backbone.body.layers.0.blocks.0.mlp.fc1.bias                                    of shape (384,)
2024-03-19 06:43:08,584 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.mlp.fc1.weight                                  loaded from backbone.body.layers.0.blocks.0.mlp.fc1.weight                                  of shape (384, 96)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.mlp.fc2.bias                                    loaded from backbone.body.layers.0.blocks.0.mlp.fc2.bias                                    of shape (96,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.mlp.fc2.weight                                  loaded from backbone.body.layers.0.blocks.0.mlp.fc2.weight                                  of shape (96, 384)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.norm1.bias                                      loaded from backbone.body.layers.0.blocks.0.norm1.bias                                      of shape (96,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.norm1.weight                                    loaded from backbone.body.layers.0.blocks.0.norm1.weight                                    of shape (96,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.norm2.bias                                      loaded from backbone.body.layers.0.blocks.0.norm2.bias                                      of shape (96,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.norm2.weight                                    loaded from backbone.body.layers.0.blocks.0.norm2.weight                                    of shape (96,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.proj.bias                                  loaded from backbone.body.layers.0.blocks.1.attn.proj.bias                                  of shape (96,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.proj.weight                                loaded from backbone.body.layers.0.blocks.1.attn.proj.weight                                of shape (96, 96)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.qkv.bias                                   loaded from backbone.body.layers.0.blocks.1.attn.qkv.bias                                   of shape (288,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.qkv.weight                                 loaded from backbone.body.layers.0.blocks.1.attn.qkv.weight                                 of shape (288, 96)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.relative_position_bias_table               loaded from backbone.body.layers.0.blocks.1.attn.relative_position_bias_table               of shape (169, 3)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.relative_position_index                    loaded from backbone.body.layers.0.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.mlp.fc1.bias                                    loaded from backbone.body.layers.0.blocks.1.mlp.fc1.bias                                    of shape (384,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.mlp.fc1.weight                                  loaded from backbone.body.layers.0.blocks.1.mlp.fc1.weight                                  of shape (384, 96)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.mlp.fc2.bias                                    loaded from backbone.body.layers.0.blocks.1.mlp.fc2.bias                                    of shape (96,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.mlp.fc2.weight                                  loaded from backbone.body.layers.0.blocks.1.mlp.fc2.weight                                  of shape (96, 384)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.norm1.bias                                      loaded from backbone.body.layers.0.blocks.1.norm1.bias                                      of shape (96,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.norm1.weight                                    loaded from backbone.body.layers.0.blocks.1.norm1.weight                                    of shape (96,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.norm2.bias                                      loaded from backbone.body.layers.0.blocks.1.norm2.bias                                      of shape (96,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.norm2.weight                                    loaded from backbone.body.layers.0.blocks.1.norm2.weight                                    of shape (96,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.downsample.norm.bias                                     loaded from backbone.body.layers.0.downsample.norm.bias                                     of shape (384,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.downsample.norm.weight                                   loaded from backbone.body.layers.0.downsample.norm.weight                                   of shape (384,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.downsample.reduction.weight                              loaded from backbone.body.layers.0.downsample.reduction.weight                              of shape (192, 384)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.proj.bias                                  loaded from backbone.body.layers.1.blocks.0.attn.proj.bias                                  of shape (192,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.proj.weight                                loaded from backbone.body.layers.1.blocks.0.attn.proj.weight                                of shape (192, 192)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.qkv.bias                                   loaded from backbone.body.layers.1.blocks.0.attn.qkv.bias                                   of shape (576,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.qkv.weight                                 loaded from backbone.body.layers.1.blocks.0.attn.qkv.weight                                 of shape (576, 192)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.relative_position_bias_table               loaded from backbone.body.layers.1.blocks.0.attn.relative_position_bias_table               of shape (169, 6)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.relative_position_index                    loaded from backbone.body.layers.1.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.mlp.fc1.bias                                    loaded from backbone.body.layers.1.blocks.0.mlp.fc1.bias                                    of shape (768,)
2024-03-19 06:43:08,585 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.mlp.fc1.weight                                  loaded from backbone.body.layers.1.blocks.0.mlp.fc1.weight                                  of shape (768, 192)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.mlp.fc2.bias                                    loaded from backbone.body.layers.1.blocks.0.mlp.fc2.bias                                    of shape (192,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.mlp.fc2.weight                                  loaded from backbone.body.layers.1.blocks.0.mlp.fc2.weight                                  of shape (192, 768)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.norm1.bias                                      loaded from backbone.body.layers.1.blocks.0.norm1.bias                                      of shape (192,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.norm1.weight                                    loaded from backbone.body.layers.1.blocks.0.norm1.weight                                    of shape (192,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.norm2.bias                                      loaded from backbone.body.layers.1.blocks.0.norm2.bias                                      of shape (192,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.norm2.weight                                    loaded from backbone.body.layers.1.blocks.0.norm2.weight                                    of shape (192,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.proj.bias                                  loaded from backbone.body.layers.1.blocks.1.attn.proj.bias                                  of shape (192,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.proj.weight                                loaded from backbone.body.layers.1.blocks.1.attn.proj.weight                                of shape (192, 192)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.qkv.bias                                   loaded from backbone.body.layers.1.blocks.1.attn.qkv.bias                                   of shape (576,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.qkv.weight                                 loaded from backbone.body.layers.1.blocks.1.attn.qkv.weight                                 of shape (576, 192)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.relative_position_bias_table               loaded from backbone.body.layers.1.blocks.1.attn.relative_position_bias_table               of shape (169, 6)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.relative_position_index                    loaded from backbone.body.layers.1.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.mlp.fc1.bias                                    loaded from backbone.body.layers.1.blocks.1.mlp.fc1.bias                                    of shape (768,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.mlp.fc1.weight                                  loaded from backbone.body.layers.1.blocks.1.mlp.fc1.weight                                  of shape (768, 192)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.mlp.fc2.bias                                    loaded from backbone.body.layers.1.blocks.1.mlp.fc2.bias                                    of shape (192,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.mlp.fc2.weight                                  loaded from backbone.body.layers.1.blocks.1.mlp.fc2.weight                                  of shape (192, 768)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.norm1.bias                                      loaded from backbone.body.layers.1.blocks.1.norm1.bias                                      of shape (192,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.norm1.weight                                    loaded from backbone.body.layers.1.blocks.1.norm1.weight                                    of shape (192,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.norm2.bias                                      loaded from backbone.body.layers.1.blocks.1.norm2.bias                                      of shape (192,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.norm2.weight                                    loaded from backbone.body.layers.1.blocks.1.norm2.weight                                    of shape (192,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.downsample.norm.bias                                     loaded from backbone.body.layers.1.downsample.norm.bias                                     of shape (768,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.downsample.norm.weight                                   loaded from backbone.body.layers.1.downsample.norm.weight                                   of shape (768,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.downsample.reduction.weight                              loaded from backbone.body.layers.1.downsample.reduction.weight                              of shape (384, 768)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.0.attn.proj.bias                                  of shape (384,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.0.attn.proj.weight                                of shape (384, 384)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.0.attn.qkv.bias                                   of shape (1152,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.0.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.0.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.0.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 06:43:08,586 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.0.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.0.mlp.fc2.bias                                    of shape (384,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.0.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.norm1.bias                                      loaded from backbone.body.layers.2.blocks.0.norm1.bias                                      of shape (384,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.norm1.weight                                    loaded from backbone.body.layers.2.blocks.0.norm1.weight                                    of shape (384,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.norm2.bias                                      loaded from backbone.body.layers.2.blocks.0.norm2.bias                                      of shape (384,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.norm2.weight                                    loaded from backbone.body.layers.2.blocks.0.norm2.weight                                    of shape (384,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.1.attn.proj.bias                                  of shape (384,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.1.attn.proj.weight                                of shape (384, 384)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.1.attn.qkv.bias                                   of shape (1152,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.1.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.1.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.1.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.1.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.1.mlp.fc2.bias                                    of shape (384,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.1.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.norm1.bias                                      loaded from backbone.body.layers.2.blocks.1.norm1.bias                                      of shape (384,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.norm1.weight                                    loaded from backbone.body.layers.2.blocks.1.norm1.weight                                    of shape (384,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.norm2.bias                                      loaded from backbone.body.layers.2.blocks.1.norm2.bias                                      of shape (384,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.norm2.weight                                    loaded from backbone.body.layers.2.blocks.1.norm2.weight                                    of shape (384,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.2.attn.proj.bias                                  of shape (384,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.2.attn.proj.weight                                of shape (384, 384)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.2.attn.qkv.bias                                   of shape (1152,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.2.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.2.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.2.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.2.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.2.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.2.mlp.fc2.bias                                    of shape (384,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.2.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.norm1.bias                                      loaded from backbone.body.layers.2.blocks.2.norm1.bias                                      of shape (384,)
2024-03-19 06:43:08,587 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.norm1.weight                                    loaded from backbone.body.layers.2.blocks.2.norm1.weight                                    of shape (384,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.norm2.bias                                      loaded from backbone.body.layers.2.blocks.2.norm2.bias                                      of shape (384,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.norm2.weight                                    loaded from backbone.body.layers.2.blocks.2.norm2.weight                                    of shape (384,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.3.attn.proj.bias                                  of shape (384,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.3.attn.proj.weight                                of shape (384, 384)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.3.attn.qkv.bias                                   of shape (1152,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.3.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.3.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.3.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.3.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.3.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.3.mlp.fc2.bias                                    of shape (384,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.3.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.norm1.bias                                      loaded from backbone.body.layers.2.blocks.3.norm1.bias                                      of shape (384,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.norm1.weight                                    loaded from backbone.body.layers.2.blocks.3.norm1.weight                                    of shape (384,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.norm2.bias                                      loaded from backbone.body.layers.2.blocks.3.norm2.bias                                      of shape (384,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.norm2.weight                                    loaded from backbone.body.layers.2.blocks.3.norm2.weight                                    of shape (384,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.4.attn.proj.bias                                  of shape (384,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.4.attn.proj.weight                                of shape (384, 384)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.4.attn.qkv.bias                                   of shape (1152,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.4.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.4.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.4.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.4.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.4.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.4.mlp.fc2.bias                                    of shape (384,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.4.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.norm1.bias                                      loaded from backbone.body.layers.2.blocks.4.norm1.bias                                      of shape (384,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.norm1.weight                                    loaded from backbone.body.layers.2.blocks.4.norm1.weight                                    of shape (384,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.norm2.bias                                      loaded from backbone.body.layers.2.blocks.4.norm2.bias                                      of shape (384,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.norm2.weight                                    loaded from backbone.body.layers.2.blocks.4.norm2.weight                                    of shape (384,)
2024-03-19 06:43:08,588 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.5.attn.proj.bias                                  of shape (384,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.5.attn.proj.weight                                of shape (384, 384)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.5.attn.qkv.bias                                   of shape (1152,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.5.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.5.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.5.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.5.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.5.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.5.mlp.fc2.bias                                    of shape (384,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.5.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.norm1.bias                                      loaded from backbone.body.layers.2.blocks.5.norm1.bias                                      of shape (384,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.norm1.weight                                    loaded from backbone.body.layers.2.blocks.5.norm1.weight                                    of shape (384,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.norm2.bias                                      loaded from backbone.body.layers.2.blocks.5.norm2.bias                                      of shape (384,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.norm2.weight                                    loaded from backbone.body.layers.2.blocks.5.norm2.weight                                    of shape (384,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.downsample.norm.bias                                     loaded from backbone.body.layers.2.downsample.norm.bias                                     of shape (1536,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.downsample.norm.weight                                   loaded from backbone.body.layers.2.downsample.norm.weight                                   of shape (1536,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.downsample.reduction.weight                              loaded from backbone.body.layers.2.downsample.reduction.weight                              of shape (768, 1536)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.proj.bias                                  loaded from backbone.body.layers.3.blocks.0.attn.proj.bias                                  of shape (768,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.proj.weight                                loaded from backbone.body.layers.3.blocks.0.attn.proj.weight                                of shape (768, 768)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.qkv.bias                                   loaded from backbone.body.layers.3.blocks.0.attn.qkv.bias                                   of shape (2304,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.qkv.weight                                 loaded from backbone.body.layers.3.blocks.0.attn.qkv.weight                                 of shape (2304, 768)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.relative_position_bias_table               loaded from backbone.body.layers.3.blocks.0.attn.relative_position_bias_table               of shape (169, 24)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.relative_position_index                    loaded from backbone.body.layers.3.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.mlp.fc1.bias                                    loaded from backbone.body.layers.3.blocks.0.mlp.fc1.bias                                    of shape (3072,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.mlp.fc1.weight                                  loaded from backbone.body.layers.3.blocks.0.mlp.fc1.weight                                  of shape (3072, 768)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.mlp.fc2.bias                                    loaded from backbone.body.layers.3.blocks.0.mlp.fc2.bias                                    of shape (768,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.mlp.fc2.weight                                  loaded from backbone.body.layers.3.blocks.0.mlp.fc2.weight                                  of shape (768, 3072)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.norm1.bias                                      loaded from backbone.body.layers.3.blocks.0.norm1.bias                                      of shape (768,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.norm1.weight                                    loaded from backbone.body.layers.3.blocks.0.norm1.weight                                    of shape (768,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.norm2.bias                                      loaded from backbone.body.layers.3.blocks.0.norm2.bias                                      of shape (768,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.norm2.weight                                    loaded from backbone.body.layers.3.blocks.0.norm2.weight                                    of shape (768,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.proj.bias                                  loaded from backbone.body.layers.3.blocks.1.attn.proj.bias                                  of shape (768,)
2024-03-19 06:43:08,589 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.proj.weight                                loaded from backbone.body.layers.3.blocks.1.attn.proj.weight                                of shape (768, 768)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.qkv.bias                                   loaded from backbone.body.layers.3.blocks.1.attn.qkv.bias                                   of shape (2304,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.qkv.weight                                 loaded from backbone.body.layers.3.blocks.1.attn.qkv.weight                                 of shape (2304, 768)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.relative_position_bias_table               loaded from backbone.body.layers.3.blocks.1.attn.relative_position_bias_table               of shape (169, 24)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.relative_position_index                    loaded from backbone.body.layers.3.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.mlp.fc1.bias                                    loaded from backbone.body.layers.3.blocks.1.mlp.fc1.bias                                    of shape (3072,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.mlp.fc1.weight                                  loaded from backbone.body.layers.3.blocks.1.mlp.fc1.weight                                  of shape (3072, 768)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.mlp.fc2.bias                                    loaded from backbone.body.layers.3.blocks.1.mlp.fc2.bias                                    of shape (768,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.mlp.fc2.weight                                  loaded from backbone.body.layers.3.blocks.1.mlp.fc2.weight                                  of shape (768, 3072)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.norm1.bias                                      loaded from backbone.body.layers.3.blocks.1.norm1.bias                                      of shape (768,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.norm1.weight                                    loaded from backbone.body.layers.3.blocks.1.norm1.weight                                    of shape (768,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.norm2.bias                                      loaded from backbone.body.layers.3.blocks.1.norm2.bias                                      of shape (768,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.norm2.weight                                    loaded from backbone.body.layers.3.blocks.1.norm2.weight                                    of shape (768,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm1.bias                                                        loaded from backbone.body.norm1.bias                                                        of shape (192,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm1.weight                                                      loaded from backbone.body.norm1.weight                                                      of shape (192,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm2.bias                                                        loaded from backbone.body.norm2.bias                                                        of shape (384,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm2.weight                                                      loaded from backbone.body.norm2.weight                                                      of shape (384,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm3.bias                                                        loaded from backbone.body.norm3.bias                                                        of shape (768,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm3.weight                                                      loaded from backbone.body.norm3.weight                                                      of shape (768,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.patch_embed.norm.bias                                             loaded from backbone.body.patch_embed.norm.bias                                             of shape (96,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.patch_embed.norm.weight                                           loaded from backbone.body.patch_embed.norm.weight                                           of shape (96,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.patch_embed.proj.bias                                             loaded from backbone.body.patch_embed.proj.bias                                             of shape (96,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.patch_embed.proj.weight                                           loaded from backbone.body.patch_embed.proj.weight                                           of shape (96, 3, 4, 4)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner2.bias                                                    loaded from backbone.fpn.fpn_inner2.bias                                                    of shape (256,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner2.weight                                                  loaded from backbone.fpn.fpn_inner2.weight                                                  of shape (256, 192, 1, 1)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner3.bias                                                    loaded from backbone.fpn.fpn_inner3.bias                                                    of shape (256,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner3.weight                                                  loaded from backbone.fpn.fpn_inner3.weight                                                  of shape (256, 384, 1, 1)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner4.bias                                                    loaded from backbone.fpn.fpn_inner4.bias                                                    of shape (256,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner4.weight                                                  loaded from backbone.fpn.fpn_inner4.weight                                                  of shape (256, 768, 1, 1)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer2.bias                                                    loaded from backbone.fpn.fpn_layer2.bias                                                    of shape (256,)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer2.weight                                                  loaded from backbone.fpn.fpn_layer2.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 06:43:08,590 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer3.bias                                                    loaded from backbone.fpn.fpn_layer3.bias                                                    of shape (256,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer3.weight                                                  loaded from backbone.fpn.fpn_layer3.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer4.bias                                                    loaded from backbone.fpn.fpn_layer4.bias                                                    of shape (256,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer4.weight                                                  loaded from backbone.fpn.fpn_layer4.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.top_blocks.p6.bias                                                 loaded from backbone.fpn.top_blocks.p6.bias                                                 of shape (256,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.top_blocks.p6.weight                                               loaded from backbone.fpn.top_blocks.p6.weight                                               of shape (256, 256, 3, 3)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.top_blocks.p7.bias                                                 loaded from backbone.fpn.top_blocks.p7.bias                                                 of shape (256,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.top_blocks.p7.weight                                               loaded from backbone.fpn.top_blocks.p7.weight                                               of shape (256, 256, 3, 3)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.embeddings.LayerNorm.bias                          loaded from language_backbone.body.model.embeddings.LayerNorm.bias                          of shape (768,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.embeddings.LayerNorm.weight                        loaded from language_backbone.body.model.embeddings.LayerNorm.weight                        of shape (768,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.embeddings.position_embeddings.weight              loaded from language_backbone.body.model.embeddings.position_embeddings.weight              of shape (512, 768)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.embeddings.token_type_embeddings.weight            loaded from language_backbone.body.model.embeddings.token_type_embeddings.weight            of shape (2, 768)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.embeddings.word_embeddings.weight                  loaded from language_backbone.body.model.embeddings.word_embeddings.weight                  of shape (30522, 768)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.0.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.0.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.0.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.0.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.0.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.0.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.0.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.0.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.0.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.0.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.0.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.0.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.0.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.0.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,591 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.1.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.1.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.1.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.1.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.1.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.1.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.1.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.1.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.1.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.1.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.1.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.1.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.1.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.1.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.bias   loaded from language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.bias   of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.weight loaded from language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.weight of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.output.dense.bias       loaded from language_backbone.body.model.encoder.layer.10.attention.output.dense.bias       of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.output.dense.weight     loaded from language_backbone.body.model.encoder.layer.10.attention.output.dense.weight     of shape (768, 768)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.key.bias           loaded from language_backbone.body.model.encoder.layer.10.attention.self.key.bias           of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.key.weight         loaded from language_backbone.body.model.encoder.layer.10.attention.self.key.weight         of shape (768, 768)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.query.bias         loaded from language_backbone.body.model.encoder.layer.10.attention.self.query.bias         of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.query.weight       loaded from language_backbone.body.model.encoder.layer.10.attention.self.query.weight       of shape (768, 768)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.value.bias         loaded from language_backbone.body.model.encoder.layer.10.attention.self.value.bias         of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.value.weight       loaded from language_backbone.body.model.encoder.layer.10.attention.self.value.weight       of shape (768, 768)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.intermediate.dense.bias           loaded from language_backbone.body.model.encoder.layer.10.intermediate.dense.bias           of shape (3072,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.intermediate.dense.weight         loaded from language_backbone.body.model.encoder.layer.10.intermediate.dense.weight         of shape (3072, 768)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.output.LayerNorm.bias             loaded from language_backbone.body.model.encoder.layer.10.output.LayerNorm.bias             of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.output.LayerNorm.weight           loaded from language_backbone.body.model.encoder.layer.10.output.LayerNorm.weight           of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.output.dense.bias                 loaded from language_backbone.body.model.encoder.layer.10.output.dense.bias                 of shape (768,)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.output.dense.weight               loaded from language_backbone.body.model.encoder.layer.10.output.dense.weight               of shape (768, 3072)
2024-03-19 06:43:08,592 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.bias   loaded from language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.bias   of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.weight loaded from language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.weight of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.output.dense.bias       loaded from language_backbone.body.model.encoder.layer.11.attention.output.dense.bias       of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.output.dense.weight     loaded from language_backbone.body.model.encoder.layer.11.attention.output.dense.weight     of shape (768, 768)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.key.bias           loaded from language_backbone.body.model.encoder.layer.11.attention.self.key.bias           of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.key.weight         loaded from language_backbone.body.model.encoder.layer.11.attention.self.key.weight         of shape (768, 768)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.query.bias         loaded from language_backbone.body.model.encoder.layer.11.attention.self.query.bias         of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.query.weight       loaded from language_backbone.body.model.encoder.layer.11.attention.self.query.weight       of shape (768, 768)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.value.bias         loaded from language_backbone.body.model.encoder.layer.11.attention.self.value.bias         of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.value.weight       loaded from language_backbone.body.model.encoder.layer.11.attention.self.value.weight       of shape (768, 768)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.intermediate.dense.bias           loaded from language_backbone.body.model.encoder.layer.11.intermediate.dense.bias           of shape (3072,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.intermediate.dense.weight         loaded from language_backbone.body.model.encoder.layer.11.intermediate.dense.weight         of shape (3072, 768)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.output.LayerNorm.bias             loaded from language_backbone.body.model.encoder.layer.11.output.LayerNorm.bias             of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.output.LayerNorm.weight           loaded from language_backbone.body.model.encoder.layer.11.output.LayerNorm.weight           of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.output.dense.bias                 loaded from language_backbone.body.model.encoder.layer.11.output.dense.bias                 of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.output.dense.weight               loaded from language_backbone.body.model.encoder.layer.11.output.dense.weight               of shape (768, 3072)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.2.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.2.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.2.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.2.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.2.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.2.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.2.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.2.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.2.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.2.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.2.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.2.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.2.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,593 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.2.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.3.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.3.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.3.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.3.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.3.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.3.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.3.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.3.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.3.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.3.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.3.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.3.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.3.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.3.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.4.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.4.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.4.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.4.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.4.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.4.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.4.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.4.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.4.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.4.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.4.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.4.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,594 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.4.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.4.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.5.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.5.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.5.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.5.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.5.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.5.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.5.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.5.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.5.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.5.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.5.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.5.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.5.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.5.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.6.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.6.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.6.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.6.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.6.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.6.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.6.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.6.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.6.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.6.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.6.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.6.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,595 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.6.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.6.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.7.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.7.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.7.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.7.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.7.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.7.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.7.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.7.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.7.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.7.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.7.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.7.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.7.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.7.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.8.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.8.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.8.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.8.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.8.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.8.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.8.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.8.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.8.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.8.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.8.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,596 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.8.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.8.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.8.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.9.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.9.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.9.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.9.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.9.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.9.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.9.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.9.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.9.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.9.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.9.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.9.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.9.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.9.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.embeddings.LayerNorm.bias                                  loaded from language_backbone.body.model.embeddings.LayerNorm.bias                          of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.embeddings.LayerNorm.weight                                loaded from language_backbone.body.model.embeddings.LayerNorm.weight                        of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.embeddings.position_embeddings.weight                      loaded from language_backbone.body.model.embeddings.position_embeddings.weight              of shape (512, 768)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.embeddings.token_type_embeddings.weight                    loaded from language_backbone.body.model.embeddings.token_type_embeddings.weight            of shape (2, 768)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.embeddings.word_embeddings.weight                          loaded from language_backbone.body.model.embeddings.word_embeddings.weight                  of shape (30522, 768)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.0.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,597 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.0.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.0.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.0.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.0.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.0.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.0.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.0.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.0.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.0.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.0.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.0.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.0.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.0.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.1.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.1.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.1.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.1.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.1.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.1.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.1.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.1.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.1.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.1.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.1.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.1.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.1.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.1.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.bias           loaded from language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.bias   of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.weight         loaded from language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.weight of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.output.dense.bias               loaded from language_backbone.body.model.encoder.layer.10.attention.output.dense.bias       of shape (768,)
2024-03-19 06:43:08,598 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.output.dense.weight             loaded from language_backbone.body.model.encoder.layer.10.attention.output.dense.weight     of shape (768, 768)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.key.bias                   loaded from language_backbone.body.model.encoder.layer.10.attention.self.key.bias           of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.key.weight                 loaded from language_backbone.body.model.encoder.layer.10.attention.self.key.weight         of shape (768, 768)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.query.bias                 loaded from language_backbone.body.model.encoder.layer.10.attention.self.query.bias         of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.query.weight               loaded from language_backbone.body.model.encoder.layer.10.attention.self.query.weight       of shape (768, 768)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.value.bias                 loaded from language_backbone.body.model.encoder.layer.10.attention.self.value.bias         of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.value.weight               loaded from language_backbone.body.model.encoder.layer.10.attention.self.value.weight       of shape (768, 768)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.intermediate.dense.bias                   loaded from language_backbone.body.model.encoder.layer.10.intermediate.dense.bias           of shape (3072,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.intermediate.dense.weight                 loaded from language_backbone.body.model.encoder.layer.10.intermediate.dense.weight         of shape (3072, 768)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.output.LayerNorm.bias                     loaded from language_backbone.body.model.encoder.layer.10.output.LayerNorm.bias             of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.output.LayerNorm.weight                   loaded from language_backbone.body.model.encoder.layer.10.output.LayerNorm.weight           of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.output.dense.bias                         loaded from language_backbone.body.model.encoder.layer.10.output.dense.bias                 of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.output.dense.weight                       loaded from language_backbone.body.model.encoder.layer.10.output.dense.weight               of shape (768, 3072)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.bias           loaded from language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.bias   of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.weight         loaded from language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.weight of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.output.dense.bias               loaded from language_backbone.body.model.encoder.layer.11.attention.output.dense.bias       of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.output.dense.weight             loaded from language_backbone.body.model.encoder.layer.11.attention.output.dense.weight     of shape (768, 768)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.key.bias                   loaded from language_backbone.body.model.encoder.layer.11.attention.self.key.bias           of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.key.weight                 loaded from language_backbone.body.model.encoder.layer.11.attention.self.key.weight         of shape (768, 768)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.query.bias                 loaded from language_backbone.body.model.encoder.layer.11.attention.self.query.bias         of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.query.weight               loaded from language_backbone.body.model.encoder.layer.11.attention.self.query.weight       of shape (768, 768)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.value.bias                 loaded from language_backbone.body.model.encoder.layer.11.attention.self.value.bias         of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.value.weight               loaded from language_backbone.body.model.encoder.layer.11.attention.self.value.weight       of shape (768, 768)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.intermediate.dense.bias                   loaded from language_backbone.body.model.encoder.layer.11.intermediate.dense.bias           of shape (3072,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.intermediate.dense.weight                 loaded from language_backbone.body.model.encoder.layer.11.intermediate.dense.weight         of shape (3072, 768)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.output.LayerNorm.bias                     loaded from language_backbone.body.model.encoder.layer.11.output.LayerNorm.bias             of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.output.LayerNorm.weight                   loaded from language_backbone.body.model.encoder.layer.11.output.LayerNorm.weight           of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.output.dense.bias                         loaded from language_backbone.body.model.encoder.layer.11.output.dense.bias                 of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.output.dense.weight                       loaded from language_backbone.body.model.encoder.layer.11.output.dense.weight               of shape (768, 3072)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.2.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,599 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.2.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.2.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.2.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.2.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.2.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.2.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.2.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.2.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.2.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.2.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.2.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.2.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.2.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.3.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.3.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.3.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.3.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.3.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.3.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.3.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.3.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.3.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.3.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.3.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.3.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.3.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.3.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,600 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.4.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.4.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.4.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.4.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.4.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.4.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.4.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.4.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.4.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.4.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.4.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.4.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.4.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.4.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.5.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.5.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.5.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.5.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.5.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.5.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.5.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.5.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.5.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.5.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.5.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.5.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.5.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.5.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,601 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.6.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.6.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.6.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.6.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.6.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.6.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.6.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.6.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.6.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.6.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.6.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.6.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.6.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.6.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.7.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.7.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.7.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.7.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.7.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.7.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.7.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.7.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.7.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.7.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.7.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.7.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.7.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.7.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,602 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.8.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.8.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.8.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.8.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.8.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.8.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.8.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.8.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.8.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.8.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.8.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.8.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.8.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.8.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.9.attention.output.dense.bias        of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.9.attention.output.dense.weight      of shape (768, 768)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.9.attention.self.key.bias            of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.9.attention.self.key.weight          of shape (768, 768)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.9.attention.self.query.bias          of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.9.attention.self.query.weight        of shape (768, 768)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.9.attention.self.value.bias          of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.9.attention.self.value.weight        of shape (768, 768)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.9.intermediate.dense.bias            of shape (3072,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.9.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.9.output.LayerNorm.bias              of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.9.output.LayerNorm.weight            of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.9.output.dense.bias                  of shape (768,)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.9.output.dense.weight                of shape (768, 3072)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0                                                     loaded from rpn.anchor_generator.cell_anchors.0                                             of shape (1, 4)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1                                                     loaded from rpn.anchor_generator.cell_anchors.1                                             of shape (1, 4)
2024-03-19 06:43:08,603 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2                                                     loaded from rpn.anchor_generator.cell_anchors.2                                             of shape (1, 4)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3                                                     loaded from rpn.anchor_generator.cell_anchors.3                                             of shape (1, 4)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4                                                     loaded from rpn.anchor_generator.cell_anchors.4                                             of shape (1, 4)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                                                                 loaded from rpn.head.bbox_pred.bias                                                         of shape (4,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                                                               loaded from rpn.head.bbox_pred.weight                                                       of shape (4, 256, 1, 1)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bias0                                                                          loaded from rpn.head.bias0                                                                  of shape (1,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bias_lang                                                                      loaded from rpn.head.bias_lang                                                              of shape (768,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.centerness.bias                                                                loaded from rpn.head.centerness.bias                                                        of shape (1,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.centerness.weight                                                              loaded from rpn.head.centerness.weight                                                      of shape (1, 256, 1, 1)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                                                                loaded from rpn.head.cls_logits.bias                                                        of shape (80,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                                                              loaded from rpn.head.cls_logits.weight                                                      of shape (80, 256, 1, 1)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dot_product_projection_text.bias                                               loaded from rpn.head.dot_product_projection_text.bias                                       of shape (256,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dot_product_projection_text.weight                                             loaded from rpn.head.dot_product_projection_text.weight                                     of shape (256, 768)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.0.AttnConv.1.bias                                         of shape (1,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.0.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.0.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.0.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.0.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.0.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.0.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.0.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.0.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.0.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.0.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.0.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.0.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.0.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.offset.bias                                                     loaded from rpn.head.dyhead_tower.0.offset.bias                                             of shape (27,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.offset.weight                                                   loaded from rpn.head.dyhead_tower.0.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.0.relu.fc.0.bias                                          of shape (64,)
2024-03-19 06:43:08,604 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.0.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.0.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.0.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.1.AttnConv.1.bias                                         of shape (1,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.1.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.1.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.1.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.1.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.1.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.1.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.1.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.1.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.1.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.1.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.1.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.1.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.1.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.offset.bias                                                     loaded from rpn.head.dyhead_tower.1.offset.bias                                             of shape (27,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.offset.weight                                                   loaded from rpn.head.dyhead_tower.1.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.1.relu.fc.0.bias                                          of shape (64,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.1.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.1.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.1.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.2.AttnConv.1.bias                                         of shape (1,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.2.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.2.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.2.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.2.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.2.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.2.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.2.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,605 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.2.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.2.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.2.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.2.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.2.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.2.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.offset.bias                                                     loaded from rpn.head.dyhead_tower.2.offset.bias                                             of shape (27,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.offset.weight                                                   loaded from rpn.head.dyhead_tower.2.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.2.relu.fc.0.bias                                          of shape (64,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.2.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.2.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.2.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.3.AttnConv.1.bias                                         of shape (1,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.3.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.3.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.3.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.3.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.3.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.3.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.3.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.3.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.3.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.3.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.3.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.3.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.3.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.offset.bias                                                     loaded from rpn.head.dyhead_tower.3.offset.bias                                             of shape (27,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.offset.weight                                                   loaded from rpn.head.dyhead_tower.3.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.3.relu.fc.0.bias                                          of shape (64,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.3.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.3.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.3.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 06:43:08,606 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.4.AttnConv.1.bias                                         of shape (1,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.4.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.4.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.4.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.4.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.4.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.4.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.4.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.4.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.4.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.4.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.4.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.4.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.4.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.offset.bias                                                     loaded from rpn.head.dyhead_tower.4.offset.bias                                             of shape (27,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.offset.weight                                                   loaded from rpn.head.dyhead_tower.4.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.4.relu.fc.0.bias                                          of shape (64,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.4.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.4.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.4.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.5.AttnConv.1.bias                                         of shape (1,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.5.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.5.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.5.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.5.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.5.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.5.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.5.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.5.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.5.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.5.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 06:43:08,607 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.5.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 06:43:08,608 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.5.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 06:43:08,608 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.5.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 06:43:08,608 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.offset.bias                                                     loaded from rpn.head.dyhead_tower.5.offset.bias                                             of shape (27,)
2024-03-19 06:43:08,608 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.offset.weight                                                   loaded from rpn.head.dyhead_tower.5.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 06:43:08,608 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.5.relu.fc.0.bias                                          of shape (64,)
2024-03-19 06:43:08,608 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.5.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 06:43:08,608 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.5.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 06:43:08,608 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.5.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 06:43:08,608 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.log_scale                                                                      loaded from rpn.head.log_scale                                                              of shape (1,)
2024-03-19 06:43:08,608 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.scales.0.scale                                                                 loaded from rpn.head.scales.0.scale                                                         of shape (1,)
2024-03-19 06:43:08,608 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.scales.1.scale                                                                 loaded from rpn.head.scales.1.scale                                                         of shape (1,)
2024-03-19 06:43:08,608 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.scales.2.scale                                                                 loaded from rpn.head.scales.2.scale                                                         of shape (1,)
2024-03-19 06:43:08,608 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.scales.3.scale                                                                 loaded from rpn.head.scales.3.scale                                                         of shape (1,)
2024-03-19 06:43:08,608 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.scales.4.scale                                                                 loaded from rpn.head.scales.4.scale                                                         of shape (1,)
2024-03-19 06:43:08,612 maskrcnn_benchmark.utils.model_serialization WARNING: Some layers unloaded with pre-trained weight: 
encoder.embeddings.LayerNorm.{bias, weight}
encoder.embeddings.position_embeddings.weight
encoder.embeddings.token_type_embeddings.weight
encoder.embeddings.word_embeddings.weight
encoder.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.0.attention.output.dense.{bias, weight}
encoder.encoder.layer.0.attention.self.key.{bias, weight}
encoder.encoder.layer.0.attention.self.query.{bias, weight}
encoder.encoder.layer.0.attention.self.value.{bias, weight}
encoder.encoder.layer.0.intermediate.dense.{bias, weight}
encoder.encoder.layer.0.output.LayerNorm.{bias, weight}
encoder.encoder.layer.0.output.dense.{bias, weight}
encoder.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.1.attention.output.dense.{bias, weight}
encoder.encoder.layer.1.attention.self.key.{bias, weight}
encoder.encoder.layer.1.attention.self.query.{bias, weight}
encoder.encoder.layer.1.attention.self.value.{bias, weight}
encoder.encoder.layer.1.intermediate.dense.{bias, weight}
encoder.encoder.layer.1.output.LayerNorm.{bias, weight}
encoder.encoder.layer.1.output.dense.{bias, weight}
encoder.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.10.attention.output.dense.{bias, weight}
encoder.encoder.layer.10.attention.self.key.{bias, weight}
encoder.encoder.layer.10.attention.self.query.{bias, weight}
encoder.encoder.layer.10.attention.self.value.{bias, weight}
encoder.encoder.layer.10.intermediate.dense.{bias, weight}
encoder.encoder.layer.10.output.LayerNorm.{bias, weight}
encoder.encoder.layer.10.output.dense.{bias, weight}
encoder.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.11.attention.output.dense.{bias, weight}
encoder.encoder.layer.11.attention.self.key.{bias, weight}
encoder.encoder.layer.11.attention.self.query.{bias, weight}
encoder.encoder.layer.11.attention.self.value.{bias, weight}
encoder.encoder.layer.11.intermediate.dense.{bias, weight}
encoder.encoder.layer.11.output.LayerNorm.{bias, weight}
encoder.encoder.layer.11.output.dense.{bias, weight}
encoder.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.2.attention.output.dense.{bias, weight}
encoder.encoder.layer.2.attention.self.key.{bias, weight}
encoder.encoder.layer.2.attention.self.query.{bias, weight}
encoder.encoder.layer.2.attention.self.value.{bias, weight}
encoder.encoder.layer.2.intermediate.dense.{bias, weight}
encoder.encoder.layer.2.output.LayerNorm.{bias, weight}
encoder.encoder.layer.2.output.dense.{bias, weight}
encoder.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.3.attention.output.dense.{bias, weight}
encoder.encoder.layer.3.attention.self.key.{bias, weight}
encoder.encoder.layer.3.attention.self.query.{bias, weight}
encoder.encoder.layer.3.attention.self.value.{bias, weight}
encoder.encoder.layer.3.intermediate.dense.{bias, weight}
encoder.encoder.layer.3.output.LayerNorm.{bias, weight}
encoder.encoder.layer.3.output.dense.{bias, weight}
encoder.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.4.attention.output.dense.{bias, weight}
encoder.encoder.layer.4.attention.self.key.{bias, weight}
encoder.encoder.layer.4.attention.self.query.{bias, weight}
encoder.encoder.layer.4.attention.self.value.{bias, weight}
encoder.encoder.layer.4.intermediate.dense.{bias, weight}
encoder.encoder.layer.4.output.LayerNorm.{bias, weight}
encoder.encoder.layer.4.output.dense.{bias, weight}
encoder.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.5.attention.output.dense.{bias, weight}
encoder.encoder.layer.5.attention.self.key.{bias, weight}
encoder.encoder.layer.5.attention.self.query.{bias, weight}
encoder.encoder.layer.5.attention.self.value.{bias, weight}
encoder.encoder.layer.5.intermediate.dense.{bias, weight}
encoder.encoder.layer.5.output.LayerNorm.{bias, weight}
encoder.encoder.layer.5.output.dense.{bias, weight}
encoder.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.6.attention.output.dense.{bias, weight}
encoder.encoder.layer.6.attention.self.key.{bias, weight}
encoder.encoder.layer.6.attention.self.query.{bias, weight}
encoder.encoder.layer.6.attention.self.value.{bias, weight}
encoder.encoder.layer.6.intermediate.dense.{bias, weight}
encoder.encoder.layer.6.output.LayerNorm.{bias, weight}
encoder.encoder.layer.6.output.dense.{bias, weight}
encoder.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.7.attention.output.dense.{bias, weight}
encoder.encoder.layer.7.attention.self.key.{bias, weight}
encoder.encoder.layer.7.attention.self.query.{bias, weight}
encoder.encoder.layer.7.attention.self.value.{bias, weight}
encoder.encoder.layer.7.intermediate.dense.{bias, weight}
encoder.encoder.layer.7.output.LayerNorm.{bias, weight}
encoder.encoder.layer.7.output.dense.{bias, weight}
encoder.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.8.attention.output.dense.{bias, weight}
encoder.encoder.layer.8.attention.self.key.{bias, weight}
encoder.encoder.layer.8.attention.self.query.{bias, weight}
encoder.encoder.layer.8.attention.self.value.{bias, weight}
encoder.encoder.layer.8.intermediate.dense.{bias, weight}
encoder.encoder.layer.8.output.LayerNorm.{bias, weight}
encoder.encoder.layer.8.output.dense.{bias, weight}
encoder.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.9.attention.output.dense.{bias, weight}
encoder.encoder.layer.9.attention.self.key.{bias, weight}
encoder.encoder.layer.9.attention.self.query.{bias, weight}
encoder.encoder.layer.9.attention.self.value.{bias, weight}
encoder.encoder.layer.9.intermediate.dense.{bias, weight}
encoder.encoder.layer.9.output.LayerNorm.{bias, weight}
encoder.encoder.layer.9.output.dense.{bias, weight}
encoder.fpn.fpn_inner2.{bias, weight}
encoder.fpn.fpn_inner3.{bias, weight}
encoder.fpn.fpn_inner4.{bias, weight}
encoder.fpn.fpn_layer2.{bias, weight}
encoder.fpn.fpn_layer3.{bias, weight}
encoder.fpn.fpn_layer4.{bias, weight}
encoder.fpn.top_blocks.p6.{bias, weight}
encoder.fpn.top_blocks.p7.{bias, weight}
encoder.language_backbone.body.embeddings.LayerNorm.{bias, weight}
encoder.language_backbone.body.embeddings.position_embeddings.weight
encoder.language_backbone.body.embeddings.token_type_embeddings.weight
encoder.language_backbone.body.embeddings.word_embeddings.weight
encoder.language_backbone.body.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.output.dense.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.embeddings.LayerNorm.{bias, weight}
encoder.language_encoder.embeddings.position_embeddings.weight
encoder.language_encoder.embeddings.token_type_embeddings.weight
encoder.language_encoder.embeddings.word_embeddings.weight
encoder.language_encoder.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.0.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.0.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.0.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.0.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.0.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.0.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.0.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.1.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.1.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.1.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.1.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.1.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.1.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.1.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.10.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.10.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.10.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.10.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.10.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.10.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.10.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.11.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.11.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.11.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.11.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.11.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.11.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.11.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.2.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.2.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.2.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.2.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.2.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.2.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.2.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.3.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.3.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.3.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.3.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.3.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.3.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.3.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.4.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.4.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.4.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.4.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.4.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.4.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.4.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.5.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.5.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.5.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.5.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.5.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.5.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.5.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.6.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.6.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.6.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.6.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.6.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.6.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.6.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.7.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.7.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.7.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.7.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.7.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.7.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.7.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.8.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.8.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.8.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.8.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.8.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.8.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.8.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.9.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.9.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.9.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.9.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.9.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.9.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.9.output.dense.{bias, weight}
encoder.language_encoder.model.embeddings.LayerNorm.{bias, weight}
encoder.language_encoder.model.embeddings.position_embeddings.weight
encoder.language_encoder.model.embeddings.token_type_embeddings.weight
encoder.language_encoder.model.embeddings.word_embeddings.weight
encoder.language_encoder.model.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.output.dense.{bias, weight}
encoder.layers.0.blocks.0.attn.proj.{bias, weight}
encoder.layers.0.blocks.0.attn.qkv.{bias, weight}
encoder.layers.0.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.0.blocks.0.mlp.fc1.{bias, weight}
encoder.layers.0.blocks.0.mlp.fc2.{bias, weight}
encoder.layers.0.blocks.0.norm1.{bias, weight}
encoder.layers.0.blocks.0.norm2.{bias, weight}
encoder.layers.0.blocks.1.attn.proj.{bias, weight}
encoder.layers.0.blocks.1.attn.qkv.{bias, weight}
encoder.layers.0.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.0.blocks.1.mlp.fc1.{bias, weight}
encoder.layers.0.blocks.1.mlp.fc2.{bias, weight}
encoder.layers.0.blocks.1.norm1.{bias, weight}
encoder.layers.0.blocks.1.norm2.{bias, weight}
encoder.layers.0.downsample.norm.{bias, weight}
encoder.layers.0.downsample.reduction.weight
encoder.layers.1.blocks.0.attn.proj.{bias, weight}
encoder.layers.1.blocks.0.attn.qkv.{bias, weight}
encoder.layers.1.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.1.blocks.0.mlp.fc1.{bias, weight}
encoder.layers.1.blocks.0.mlp.fc2.{bias, weight}
encoder.layers.1.blocks.0.norm1.{bias, weight}
encoder.layers.1.blocks.0.norm2.{bias, weight}
encoder.layers.1.blocks.1.attn.proj.{bias, weight}
encoder.layers.1.blocks.1.attn.qkv.{bias, weight}
encoder.layers.1.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.1.blocks.1.mlp.fc1.{bias, weight}
encoder.layers.1.blocks.1.mlp.fc2.{bias, weight}
encoder.layers.1.blocks.1.norm1.{bias, weight}
encoder.layers.1.blocks.1.norm2.{bias, weight}
encoder.layers.1.downsample.norm.{bias, weight}
encoder.layers.1.downsample.reduction.weight
encoder.layers.2.blocks.0.attn.proj.{bias, weight}
encoder.layers.2.blocks.0.attn.qkv.{bias, weight}
encoder.layers.2.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.0.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.0.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.0.norm1.{bias, weight}
encoder.layers.2.blocks.0.norm2.{bias, weight}
encoder.layers.2.blocks.1.attn.proj.{bias, weight}
encoder.layers.2.blocks.1.attn.qkv.{bias, weight}
encoder.layers.2.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.1.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.1.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.1.norm1.{bias, weight}
encoder.layers.2.blocks.1.norm2.{bias, weight}
encoder.layers.2.blocks.2.attn.proj.{bias, weight}
encoder.layers.2.blocks.2.attn.qkv.{bias, weight}
encoder.layers.2.blocks.2.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.2.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.2.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.2.norm1.{bias, weight}
encoder.layers.2.blocks.2.norm2.{bias, weight}
encoder.layers.2.blocks.3.attn.proj.{bias, weight}
encoder.layers.2.blocks.3.attn.qkv.{bias, weight}
encoder.layers.2.blocks.3.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.3.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.3.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.3.norm1.{bias, weight}
encoder.layers.2.blocks.3.norm2.{bias, weight}
encoder.layers.2.blocks.4.attn.proj.{bias, weight}
encoder.layers.2.blocks.4.attn.qkv.{bias, weight}
encoder.layers.2.blocks.4.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.4.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.4.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.4.norm1.{bias, weight}
encoder.layers.2.blocks.4.norm2.{bias, weight}
encoder.layers.2.blocks.5.attn.proj.{bias, weight}
encoder.layers.2.blocks.5.attn.qkv.{bias, weight}
encoder.layers.2.blocks.5.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.5.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.5.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.5.norm1.{bias, weight}
encoder.layers.2.blocks.5.norm2.{bias, weight}
encoder.layers.2.downsample.norm.{bias, weight}
encoder.layers.2.downsample.reduction.weight
encoder.layers.3.blocks.0.attn.proj.{bias, weight}
encoder.layers.3.blocks.0.attn.qkv.{bias, weight}
encoder.layers.3.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.3.blocks.0.mlp.fc1.{bias, weight}
encoder.layers.3.blocks.0.mlp.fc2.{bias, weight}
encoder.layers.3.blocks.0.norm1.{bias, weight}
encoder.layers.3.blocks.0.norm2.{bias, weight}
encoder.layers.3.blocks.1.attn.proj.{bias, weight}
encoder.layers.3.blocks.1.attn.qkv.{bias, weight}
encoder.layers.3.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.3.blocks.1.mlp.fc1.{bias, weight}
encoder.layers.3.blocks.1.mlp.fc2.{bias, weight}
encoder.layers.3.blocks.1.norm1.{bias, weight}
encoder.layers.3.blocks.1.norm2.{bias, weight}
encoder.model.embeddings.LayerNorm.{bias, weight}
encoder.model.embeddings.position_embeddings.weight
encoder.model.embeddings.token_type_embeddings.weight
encoder.model.embeddings.word_embeddings.weight
encoder.model.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.0.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.0.attention.self.key.{bias, weight}
encoder.model.encoder.layer.0.attention.self.query.{bias, weight}
encoder.model.encoder.layer.0.attention.self.value.{bias, weight}
encoder.model.encoder.layer.0.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.0.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.0.output.dense.{bias, weight}
encoder.model.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.1.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.1.attention.self.key.{bias, weight}
encoder.model.encoder.layer.1.attention.self.query.{bias, weight}
encoder.model.encoder.layer.1.attention.self.value.{bias, weight}
encoder.model.encoder.layer.1.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.1.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.1.output.dense.{bias, weight}
encoder.model.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.10.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.10.attention.self.key.{bias, weight}
encoder.model.encoder.layer.10.attention.self.query.{bias, weight}
encoder.model.encoder.layer.10.attention.self.value.{bias, weight}
encoder.model.encoder.layer.10.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.10.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.10.output.dense.{bias, weight}
encoder.model.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.11.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.11.attention.self.key.{bias, weight}
encoder.model.encoder.layer.11.attention.self.query.{bias, weight}
encoder.model.encoder.layer.11.attention.self.value.{bias, weight}
encoder.model.encoder.layer.11.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.11.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.11.output.dense.{bias, weight}
encoder.model.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.2.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.2.attention.self.key.{bias, weight}
encoder.model.encoder.layer.2.attention.self.query.{bias, weight}
encoder.model.encoder.layer.2.attention.self.value.{bias, weight}
encoder.model.encoder.layer.2.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.2.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.2.output.dense.{bias, weight}
encoder.model.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.3.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.3.attention.self.key.{bias, weight}
encoder.model.encoder.layer.3.attention.self.query.{bias, weight}
encoder.model.encoder.layer.3.attention.self.value.{bias, weight}
encoder.model.encoder.layer.3.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.3.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.3.output.dense.{bias, weight}
encoder.model.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.4.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.4.attention.self.key.{bias, weight}
encoder.model.encoder.layer.4.attention.self.query.{bias, weight}
encoder.model.encoder.layer.4.attention.self.value.{bias, weight}
encoder.model.encoder.layer.4.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.4.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.4.output.dense.{bias, weight}
encoder.model.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.5.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.5.attention.self.key.{bias, weight}
encoder.model.encoder.layer.5.attention.self.query.{bias, weight}
encoder.model.encoder.layer.5.attention.self.value.{bias, weight}
encoder.model.encoder.layer.5.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.5.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.5.output.dense.{bias, weight}
encoder.model.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.6.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.6.attention.self.key.{bias, weight}
encoder.model.encoder.layer.6.attention.self.query.{bias, weight}
encoder.model.encoder.layer.6.attention.self.value.{bias, weight}
encoder.model.encoder.layer.6.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.6.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.6.output.dense.{bias, weight}
encoder.model.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.7.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.7.attention.self.key.{bias, weight}
encoder.model.encoder.layer.7.attention.self.query.{bias, weight}
encoder.model.encoder.layer.7.attention.self.value.{bias, weight}
encoder.model.encoder.layer.7.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.7.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.7.output.dense.{bias, weight}
encoder.model.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.8.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.8.attention.self.key.{bias, weight}
encoder.model.encoder.layer.8.attention.self.query.{bias, weight}
encoder.model.encoder.layer.8.attention.self.value.{bias, weight}
encoder.model.encoder.layer.8.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.8.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.8.output.dense.{bias, weight}
encoder.model.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.9.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.9.attention.self.key.{bias, weight}
encoder.model.encoder.layer.9.attention.self.query.{bias, weight}
encoder.model.encoder.layer.9.attention.self.value.{bias, weight}
encoder.model.encoder.layer.9.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.9.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.9.output.dense.{bias, weight}
encoder.norm1.{bias, weight}
encoder.norm2.{bias, weight}
encoder.norm3.{bias, weight}
encoder.patch_embed.norm.{bias, weight}
encoder.patch_embed.proj.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.attn.proj.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.0.blocks.0.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.norm1.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.norm2.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.attn.proj.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.0.blocks.1.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.norm1.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.norm2.{bias, weight}
encoder.visual_encoder.layers.0.downsample.norm.{bias, weight}
encoder.visual_encoder.layers.0.downsample.reduction.weight
encoder.visual_encoder.layers.1.blocks.0.attn.proj.{bias, weight}
encoder.visual_encoder.layers.1.blocks.0.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.1.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.1.blocks.0.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.1.blocks.0.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.1.blocks.0.norm1.{bias, weight}
encoder.visual_encoder.layers.1.blocks.0.norm2.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.attn.proj.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.1.blocks.1.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.norm1.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.norm2.{bias, weight}
encoder.visual_encoder.layers.1.downsample.norm.{bias, weight}
encoder.visual_encoder.layers.1.downsample.reduction.weight
encoder.visual_encoder.layers.2.blocks.0.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.0.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.0.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.0.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.0.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.0.norm2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.1.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.norm2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.2.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.norm2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.3.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.norm2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.4.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.norm2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.5.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.norm2.{bias, weight}
encoder.visual_encoder.layers.2.downsample.norm.{bias, weight}
encoder.visual_encoder.layers.2.downsample.reduction.weight
encoder.visual_encoder.layers.3.blocks.0.attn.proj.{bias, weight}
encoder.visual_encoder.layers.3.blocks.0.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.3.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.3.blocks.0.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.3.blocks.0.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.3.blocks.0.norm1.{bias, weight}
encoder.visual_encoder.layers.3.blocks.0.norm2.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.attn.proj.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.3.blocks.1.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.norm1.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.norm2.{bias, weight}
encoder.visual_encoder.norm1.{bias, weight}
encoder.visual_encoder.norm2.{bias, weight}
encoder.visual_encoder.norm3.{bias, weight}
encoder.visual_encoder.patch_embed.norm.{bias, weight}
encoder.visual_encoder.patch_embed.proj.{bias, weight}
language_backbone.body.embeddings.LayerNorm.{bias, weight}
language_backbone.body.embeddings.position_embeddings.weight
language_backbone.body.embeddings.token_type_embeddings.weight
language_backbone.body.embeddings.word_embeddings.weight
language_backbone.body.encoder.interactModuleList.0.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.0.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.1.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.1.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.10.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.10.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.11.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.11.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.2.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.2.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.3.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.3.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.4.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.4.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.5.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.5.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.6.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.6.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.7.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.7.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.8.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.8.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.9.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.9.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.0.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.0.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.0.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.0.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.0.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.0.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.0.output.dense.{bias, weight}
language_backbone.body.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.1.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.1.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.1.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.1.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.1.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.1.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.1.output.dense.{bias, weight}
language_backbone.body.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.10.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.10.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.10.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.10.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.10.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.10.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.10.output.dense.{bias, weight}
language_backbone.body.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.11.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.11.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.11.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.11.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.11.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.11.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.11.output.dense.{bias, weight}
language_backbone.body.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.2.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.2.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.2.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.2.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.2.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.2.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.2.output.dense.{bias, weight}
language_backbone.body.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.3.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.3.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.3.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.3.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.3.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.3.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.3.output.dense.{bias, weight}
language_backbone.body.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.4.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.4.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.4.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.4.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.4.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.4.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.4.output.dense.{bias, weight}
language_backbone.body.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.5.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.5.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.5.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.5.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.5.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.5.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.5.output.dense.{bias, weight}
language_backbone.body.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.6.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.6.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.6.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.6.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.6.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.6.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.6.output.dense.{bias, weight}
language_backbone.body.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.7.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.7.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.7.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.7.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.7.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.7.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.7.output.dense.{bias, weight}
language_backbone.body.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.8.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.8.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.8.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.8.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.8.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.8.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.8.output.dense.{bias, weight}
language_backbone.body.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.9.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.9.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.9.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.9.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.9.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.9.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.9.output.dense.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.0.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.0.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.1.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.1.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.10.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.10.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.11.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.11.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.2.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.2.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.3.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.3.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.4.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.4.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.5.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.5.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.6.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.6.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.7.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.7.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.8.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.8.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.9.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.9.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
rpn.tunable_linear.weight
textual_prompt.0.{dim_1, dim_2, dim_3}
textual_prompt.1.{dim_1, dim_2, dim_3}
textual_prompt.10.{dim_1, dim_2, dim_3}
textual_prompt.11.{dim_1, dim_2, dim_3}
textual_prompt.2.{dim_1, dim_2, dim_3}
textual_prompt.3.{dim_1, dim_2, dim_3}
textual_prompt.4.{dim_1, dim_2, dim_3}
textual_prompt.5.{dim_1, dim_2, dim_3}
textual_prompt.6.{dim_1, dim_2, dim_3}
textual_prompt.7.{dim_1, dim_2, dim_3}
textual_prompt.8.{dim_1, dim_2, dim_3}
textual_prompt.9.{dim_1, dim_2, dim_3}
visual_prompt.0.{dim_1, dim_2, dim_3}
visual_prompt.1.{dim_1, dim_2, dim_3}
visual_prompt.10.{dim_1, dim_2, dim_3}
visual_prompt.11.{dim_1, dim_2, dim_3}
visual_prompt.2.{dim_1, dim_2, dim_3}
visual_prompt.3.{dim_1, dim_2, dim_3}
visual_prompt.4.{dim_1, dim_2, dim_3}
visual_prompt.5.{dim_1, dim_2, dim_3}
visual_prompt.6.{dim_1, dim_2, dim_3}
visual_prompt.7.{dim_1, dim_2, dim_3}
visual_prompt.8.{dim_1, dim_2, dim_3}
visual_prompt.9.{dim_1, dim_2, dim_3}
Backbone Freeze: True
FPN Freeze: True
RPN Freeze: True
Linear Probe: True
Language Freeze: True
Linear Layer (True Prmopt Tuning): True
High Level Override: language_prompt_v4
2024-03-19 06:43:10,452 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 06:43:10,452 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 06:43:10,452 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 06:43:10,452 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 06:43:10,452 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 06:43:10,452 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 06:43:10,452 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 06:43:10,452 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 06:43:10,452 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 06:43:10,452 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 06:43:10,453 maskrcnn_benchmark INFO: visual_prompt.0.dim_1 : Not Frozen, param number, 36
2024-03-19 06:43:10,453 maskrcnn_benchmark INFO: visual_prompt.0.dim_2 : Not Frozen, param number, 64
2024-03-19 06:43:10,453 maskrcnn_benchmark INFO: visual_prompt.0.dim_3 : Not Frozen, param number, 384
2024-03-19 06:43:10,453 maskrcnn_benchmark INFO: textual_prompt.0.dim_1 : Not Frozen, param number, 36
2024-03-19 06:43:10,453 maskrcnn_benchmark INFO: textual_prompt.0.dim_2 : Not Frozen, param number, 64
2024-03-19 06:43:10,453 maskrcnn_benchmark INFO: textual_prompt.0.dim_3 : Not Frozen, param number, 3072
2024-03-19 06:43:10,456 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 06:43:10,456 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.54s)
creating index...
index created!
2024-03-19 06:43:13,048 maskrcnn_benchmark INFO: Training on task 0: appliance, total training sample size: 804
refexp_train has the 804 data points RefExpDataset
Number of iterations are 251
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 06:43:13,256 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
2024-03-19 06:43:13,256 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  25
eta: 0:05:59  iter: 20  loss: 2.4305 (2.3954)  loss_reg: 0.2690 (0.2729)  loss_centerness: 0.4840 (0.4829)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4260 (1.4212)  alignment_loss: 0.2185 (0.2184)  time: 1.3844 (1.5557)  data: 0.1155 (0.2371)  lr: 0.010000  wd: 0.000500  max mem: 12747
eta: 0:05:15  iter: 40  loss: 2.1789 (2.3006)  loss_reg: 0.2606 (0.2745)  loss_centerness: 0.4828 (0.4840)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1984 (1.3239)  alignment_loss: 0.2181 (0.2182)  time: 1.3226 (1.4939)  data: 0.0147 (0.1916)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:04:41  iter: 60  loss: 2.0192 (2.2138)  loss_reg: 0.2840 (0.2784)  loss_centerness: 0.4847 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0338 (1.2332)  alignment_loss: 0.2176 (0.2180)  time: 1.3846 (1.4729)  data: 0.0167 (0.1710)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:04:09  iter: 80  loss: 2.0398 (2.1696)  loss_reg: 0.2758 (0.2812)  loss_centerness: 0.4843 (0.4847)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0001 (1.1859)  alignment_loss: 0.2172 (0.2178)  time: 1.3487 (1.4619)  data: 0.0135 (0.1597)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:03:40  iter: 100  loss: 1.9262 (2.1246)  loss_reg: 0.2714 (0.2801)  loss_centerness: 0.4805 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9709 (1.1427)  alignment_loss: 0.2167 (0.2176)  time: 1.3893 (1.4600)  data: 0.0138 (0.1575)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:03:10  iter: 120  loss: 1.9371 (2.1011)  loss_reg: 0.2821 (0.2802)  loss_centerness: 0.4838 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9657 (1.1193)  alignment_loss: 0.2162 (0.2173)  time: 1.3874 (1.4561)  data: 0.0131 (0.1526)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:02:41  iter: 140  loss: 1.9376 (2.0790)  loss_reg: 0.2690 (0.2798)  loss_centerness: 0.4834 (0.4840)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9718 (1.0981)  alignment_loss: 0.2157 (0.2171)  time: 1.3890 (1.4546)  data: 0.0174 (0.1490)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:02:12  iter: 160  loss: 1.9381 (2.0627)  loss_reg: 0.2867 (0.2808)  loss_centerness: 0.4854 (0.4843)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9408 (1.0808)  alignment_loss: 0.2151 (0.2168)  time: 1.3576 (1.4566)  data: 0.0160 (0.1497)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:01:43  iter: 180  loss: 1.9076 (2.0472)  loss_reg: 0.2724 (0.2801)  loss_centerness: 0.4825 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9436 (1.0663)  alignment_loss: 0.2144 (0.2166)  time: 1.3640 (1.4560)  data: 0.0149 (0.1502)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:01:14  iter: 200  loss: 1.8626 (2.0309)  loss_reg: 0.2643 (0.2795)  loss_centerness: 0.4820 (0.4840)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9060 (1.0511)  alignment_loss: 0.2137 (0.2163)  time: 1.3881 (1.4555)  data: 0.0132 (0.1481)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:00:45  iter: 220  loss: 1.9172 (2.0226)  loss_reg: 0.2734 (0.2796)  loss_centerness: 0.4824 (0.4841)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9259 (1.0430)  alignment_loss: 0.2130 (0.2160)  time: 1.3659 (1.4561)  data: 0.0194 (0.1468)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:00:16  iter: 240  loss: 1.8336 (2.0104)  loss_reg: 0.2777 (0.2798)  loss_centerness: 0.4849 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8722 (1.0308)  alignment_loss: 0.2121 (0.2157)  time: 1.3969 (1.4562)  data: 0.0130 (0.1473)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:00:00  iter: 251  loss: 1.8600 (2.0071)  loss_reg: 0.2861 (0.2807)  loss_centerness: 0.4856 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8925 (1.0268)  alignment_loss: 0.2116 (0.2155)  time: 1.3953 (1.4564)  data: 0.0130 (0.1468)  lr: 0.009045  wd: 0.000500  max mem: 12748
Evaluating
2024-03-19 06:50:04,912 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 06:50:13,964 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:50:13,968 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:50:13,999 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.5205479452054794, 0.6575342465753424] 

2024-03-19 06:50:13,999 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:50:14,000 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:50:14,000 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.5205479452054794, 0.6575342465753424], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:50:14,052 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 06:50:15,172 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 06:50:16,419 maskrcnn_benchmark.trainer INFO: Total training time: 0:07:03.149269 (1.6859 s / it)
2024-03-19 06:50:16,444 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 06:50:16,444 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 06:50:16,444 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 06:50:16,444 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 06:50:16,444 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 06:50:16,444 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 06:50:16,444 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 06:50:16,444 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 06:50:16,445 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 06:50:16,445 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 06:50:16,446 maskrcnn_benchmark INFO: visual_prompt.1.dim_1 : Not Frozen, param number, 36
2024-03-19 06:50:16,446 maskrcnn_benchmark INFO: visual_prompt.1.dim_2 : Not Frozen, param number, 64
2024-03-19 06:50:16,446 maskrcnn_benchmark INFO: visual_prompt.1.dim_3 : Not Frozen, param number, 384
2024-03-19 06:50:16,446 maskrcnn_benchmark INFO: textual_prompt.1.dim_1 : Not Frozen, param number, 36
2024-03-19 06:50:16,446 maskrcnn_benchmark INFO: textual_prompt.1.dim_2 : Not Frozen, param number, 64
2024-03-19 06:50:16,446 maskrcnn_benchmark INFO: textual_prompt.1.dim_3 : Not Frozen, param number, 3072
2024-03-19 06:50:16,452 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 06:50:16,452 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.73s)
creating index...
index created!
2024-03-19 06:50:19,006 maskrcnn_benchmark INFO: Training on task 1: sports, total training sample size: 853
refexp_train has the 853 data points RefExpDataset
Number of iterations are 266
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 06:50:19,208 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 06:50:19,402 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
2024-03-19 06:50:19,546 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  26
eta: 0:06:00  iter: 20  loss: 2.3923 (2.0371)  loss_reg: 0.3159 (0.2829)  loss_centerness: 0.4912 (0.4847)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3834 (1.0546)  alignment_loss: 0.2081 (0.2149)  time: 1.3713 (1.4647)  data: 0.0181 (0.1524)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:05:30  iter: 40  loss: 2.2171 (2.0490)  loss_reg: 0.3114 (0.2847)  loss_centerness: 0.4867 (0.4849)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1967 (1.0651)  alignment_loss: 0.2052 (0.2143)  time: 1.3544 (1.4626)  data: 0.0155 (0.1509)  lr: 0.010000  wd: 0.000500  max mem: 12748
eta: 0:05:02  iter: 60  loss: 2.1294 (2.0527)  loss_reg: 0.3022 (0.2866)  loss_centerness: 0.4853 (0.4851)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0874 (1.0674)  alignment_loss: 0.2019 (0.2135)  time: 1.3757 (1.4667)  data: 0.0146 (0.1531)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:04:32  iter: 80  loss: 2.0403 (2.0537)  loss_reg: 0.2969 (0.2882)  loss_centerness: 0.4870 (0.4853)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0370 (1.0676)  alignment_loss: 0.1984 (0.2126)  time: 1.3699 (1.4663)  data: 0.0198 (0.1532)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:04:03  iter: 100  loss: 2.0143 (2.0522)  loss_reg: 0.2942 (0.2893)  loss_centerness: 0.4900 (0.4856)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0130 (1.0658)  alignment_loss: 0.1949 (0.2116)  time: 1.3972 (1.4651)  data: 0.0135 (0.1518)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:03:33  iter: 120  loss: 2.0714 (2.0527)  loss_reg: 0.3096 (0.2908)  loss_centerness: 0.4883 (0.4858)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0511 (1.0656)  alignment_loss: 0.1913 (0.2105)  time: 1.3854 (1.4646)  data: 0.0135 (0.1508)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:03:04  iter: 140  loss: 1.9780 (2.0487)  loss_reg: 0.2849 (0.2912)  loss_centerness: 0.4874 (0.4859)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9937 (1.0624)  alignment_loss: 0.1876 (0.2093)  time: 1.3619 (1.4633)  data: 0.0144 (0.1497)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:02:35  iter: 160  loss: 1.9524 (2.0442)  loss_reg: 0.2896 (0.2915)  loss_centerness: 0.4856 (0.4860)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9480 (1.0586)  alignment_loss: 0.1838 (0.2081)  time: 1.4199 (1.4639)  data: 0.0147 (0.1488)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:02:05  iter: 180  loss: 1.9560 (2.0425)  loss_reg: 0.3078 (0.2926)  loss_centerness: 0.4886 (0.4862)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9962 (1.0569)  alignment_loss: 0.1800 (0.2067)  time: 1.3303 (1.4619)  data: 0.0173 (0.1478)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:01:36  iter: 200  loss: 1.9739 (2.0393)  loss_reg: 0.3068 (0.2933)  loss_centerness: 0.4906 (0.4864)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9849 (1.0542)  alignment_loss: 0.1761 (0.2054)  time: 1.3660 (1.4604)  data: 0.0132 (0.1468)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:01:07  iter: 220  loss: 1.9314 (2.0363)  loss_reg: 0.3143 (0.2942)  loss_centerness: 0.4889 (0.4865)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9814 (1.0516)  alignment_loss: 0.1722 (0.2040)  time: 1.3922 (1.4600)  data: 0.0160 (0.1460)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:37  iter: 240  loss: 1.9328 (2.0336)  loss_reg: 0.3101 (0.2947)  loss_centerness: 0.4878 (0.4866)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9813 (1.0497)  alignment_loss: 0.1684 (0.2025)  time: 1.3509 (1.4588)  data: 0.0148 (0.1453)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:08  iter: 260  loss: 1.8783 (2.0288)  loss_reg: 0.2839 (0.2950)  loss_centerness: 0.4854 (0.4867)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9509 (1.0461)  alignment_loss: 0.1647 (0.2010)  time: 1.3995 (1.4577)  data: 0.0132 (0.1445)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:00  iter: 266  loss: 1.9583 (2.0283)  loss_reg: 0.3037 (0.2952)  loss_centerness: 0.4898 (0.4868)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0318 (1.0457)  alignment_loss: 0.1635 (0.2006)  time: 1.3438 (1.4570)  data: 0.0145 (0.1443)  lr: 0.000955  wd: 0.000500  max mem: 12749
Evaluating
2024-03-19 06:57:36,230 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 06:57:45,349 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:57:45,353 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 06:57:45,388 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.5205479452054794, 0.6575342465753424] 

2024-03-19 06:57:45,389 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:57:45,389 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:57:45,389 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.5205479452054794, 0.6575342465753424], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:57:45,406 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 06:57:50,097 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 06:57:50,101 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 06:57:50,114 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2222222222222222, 0.8518518518518519, 1.0] 

2024-03-19 06:57:50,114 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 06:57:50,114 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 06:57:50,114 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2222222222222222, 0.8518518518518519, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 06:57:50,157 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 06:57:51,163 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 06:57:52,355 maskrcnn_benchmark.trainer INFO: Total training time: 0:07:32.796516 (1.7022 s / it)
2024-03-19 06:57:52,380 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 06:57:52,380 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 06:57:52,380 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 06:57:52,380 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 06:57:52,380 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 06:57:52,380 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 06:57:52,380 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 06:57:52,380 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 06:57:52,380 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 06:57:52,380 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 06:57:52,381 maskrcnn_benchmark INFO: visual_prompt.2.dim_1 : Not Frozen, param number, 36
2024-03-19 06:57:52,381 maskrcnn_benchmark INFO: visual_prompt.2.dim_2 : Not Frozen, param number, 64
2024-03-19 06:57:52,381 maskrcnn_benchmark INFO: visual_prompt.2.dim_3 : Not Frozen, param number, 384
2024-03-19 06:57:52,382 maskrcnn_benchmark INFO: textual_prompt.2.dim_1 : Not Frozen, param number, 36
2024-03-19 06:57:52,382 maskrcnn_benchmark INFO: textual_prompt.2.dim_2 : Not Frozen, param number, 64
2024-03-19 06:57:52,382 maskrcnn_benchmark INFO: textual_prompt.2.dim_3 : Not Frozen, param number, 3072
2024-03-19 06:57:52,384 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 06:57:52,384 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.77s)
creating index...
index created!
2024-03-19 06:57:54,964 maskrcnn_benchmark INFO: Training on task 2: outdoor, total training sample size: 1063
refexp_train has the 1063 data points RefExpDataset
Number of iterations are 332
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.86s)
creating index...
index created!
2024-03-19 06:57:55,958 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 06:57:56,140 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 06:57:56,329 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
2024-03-19 06:57:56,492 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  33
eta: 0:07:35  iter: 20  loss: 2.1549 (2.0334)  loss_reg: 0.2784 (0.2949)  loss_centerness: 0.4810 (0.4866)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1567 (1.0510)  alignment_loss: 0.2114 (0.2010)  time: 1.4647 (1.4603)  data: 0.1305 (0.1473)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:07:06  iter: 40  loss: 1.8987 (2.0303)  loss_reg: 0.2670 (0.2942)  loss_centerness: 0.4815 (0.4864)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9663 (1.0485)  alignment_loss: 0.2079 (0.2012)  time: 1.4747 (1.4607)  data: 0.1334 (0.1469)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:06:37  iter: 60  loss: 1.9283 (2.0272)  loss_reg: 0.2770 (0.2939)  loss_centerness: 0.4811 (0.4863)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9218 (1.0456)  alignment_loss: 0.2040 (0.2013)  time: 1.4559 (1.4605)  data: 0.1250 (0.1464)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:06:07  iter: 80  loss: 1.9125 (2.0238)  loss_reg: 0.2804 (0.2935)  loss_centerness: 0.4834 (0.4862)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9359 (1.0428)  alignment_loss: 0.2004 (0.2013)  time: 1.4101 (1.4603)  data: 0.1200 (0.1458)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:05:38  iter: 100  loss: 1.8945 (2.0197)  loss_reg: 0.2850 (0.2931)  loss_centerness: 0.4811 (0.4861)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9312 (1.0393)  alignment_loss: 0.1968 (0.2012)  time: 1.4554 (1.4603)  data: 0.1289 (0.1454)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:05:09  iter: 120  loss: 1.8614 (2.0146)  loss_reg: 0.2776 (0.2928)  loss_centerness: 0.4823 (0.4860)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9109 (1.0349)  alignment_loss: 0.1933 (0.2009)  time: 1.4527 (1.4601)  data: 0.1281 (0.1451)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:04:40  iter: 140  loss: 1.8007 (2.0087)  loss_reg: 0.2653 (0.2923)  loss_centerness: 0.4824 (0.4859)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8547 (1.0300)  alignment_loss: 0.1897 (0.2006)  time: 1.4018 (1.4595)  data: 0.1264 (0.1446)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:04:11  iter: 160  loss: 1.8842 (2.0039)  loss_reg: 0.2758 (0.2921)  loss_centerness: 0.4844 (0.4858)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9070 (1.0259)  alignment_loss: 0.1861 (0.2001)  time: 1.4554 (1.4599)  data: 0.1334 (0.1443)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:03:41  iter: 180  loss: 1.8298 (1.9987)  loss_reg: 0.2830 (0.2918)  loss_centerness: 0.4818 (0.4857)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8595 (1.0215)  alignment_loss: 0.1824 (0.1996)  time: 1.4529 (1.4597)  data: 0.1299 (0.1441)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:03:12  iter: 200  loss: 1.8000 (1.9935)  loss_reg: 0.2757 (0.2915)  loss_centerness: 0.4814 (0.4856)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8573 (1.0173)  alignment_loss: 0.1787 (0.1991)  time: 1.4401 (1.4594)  data: 0.1282 (0.1437)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:02:43  iter: 220  loss: 1.7399 (1.9871)  loss_reg: 0.2765 (0.2912)  loss_centerness: 0.4819 (0.4856)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8103 (1.0120)  alignment_loss: 0.1749 (0.1984)  time: 1.4168 (1.4594)  data: 0.1272 (0.1440)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:02:14  iter: 240  loss: 1.7522 (1.9811)  loss_reg: 0.2725 (0.2908)  loss_centerness: 0.4816 (0.4855)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8208 (1.0071)  alignment_loss: 0.1710 (0.1977)  time: 1.4046 (1.4589)  data: 0.1183 (0.1436)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:01:45  iter: 260  loss: 1.7716 (1.9760)  loss_reg: 0.2717 (0.2904)  loss_centerness: 0.4818 (0.4854)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8558 (1.0034)  alignment_loss: 0.1670 (0.1969)  time: 1.4591 (1.4586)  data: 0.1245 (0.1433)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:01:15  iter: 280  loss: 1.7396 (1.9705)  loss_reg: 0.2819 (0.2904)  loss_centerness: 0.4831 (0.4853)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8064 (0.9987)  alignment_loss: 0.1630 (0.1960)  time: 1.4141 (1.4578)  data: 0.1187 (0.1428)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:46  iter: 300  loss: 1.7455 (1.9658)  loss_reg: 0.2728 (0.2901)  loss_centerness: 0.4818 (0.4853)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8339 (0.9953)  alignment_loss: 0.1588 (0.1951)  time: 1.4111 (1.4576)  data: 0.1192 (0.1424)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:17  iter: 320  loss: 1.7359 (1.9603)  loss_reg: 0.2691 (0.2899)  loss_centerness: 0.4823 (0.4852)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7915 (0.9910)  alignment_loss: 0.1546 (0.1941)  time: 1.4394 (1.4573)  data: 0.1261 (0.1421)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:00  iter: 332  loss: 1.7225 (1.9568)  loss_reg: 0.2647 (0.2897)  loss_centerness: 0.4806 (0.4852)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7973 (0.9884)  alignment_loss: 0.1516 (0.1935)  time: 1.4394 (1.4574)  data: 0.1249 (0.1420)  lr: 0.006545  wd: 0.000500  max mem: 12749
Evaluating
2024-03-19 07:06:59,998 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 07:07:08,732 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 07:07:08,736 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 07:07:08,774 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.5205479452054794, 0.6575342465753424] 

2024-03-19 07:07:08,775 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 07:07:08,775 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 07:07:08,775 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.5205479452054794, 0.6575342465753424], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 07:07:08,792 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 07:07:13,514 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 07:07:13,518 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 07:07:13,534 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2222222222222222, 0.8518518518518519, 1.0] 

2024-03-19 07:07:13,534 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 07:07:13,534 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 07:07:13,535 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2222222222222222, 0.8518518518518519, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 07:07:13,553 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 07:07:19,359 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 07:07:19,363 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 07:07:19,379 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3409090909090909, 0.5681818181818182, 0.7954545454545454] 

2024-03-19 07:07:19,379 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 07:07:19,379 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 07:07:19,380 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8181818181818182
evaluate on task refcoco, val, 2, res: {'refcoco': [0.3409090909090909, 0.5681818181818182, 0.7954545454545454], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 07:07:19,422 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 07:07:20,546 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 07:07:22,181 maskrcnn_benchmark.trainer INFO: Total training time: 0:09:25.675699 (1.7038 s / it)
2024-03-19 07:07:22,203 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 07:07:22,204 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 07:07:22,204 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 07:07:22,204 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 07:07:22,204 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 07:07:22,204 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 07:07:22,204 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 07:07:22,204 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 07:07:22,204 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 07:07:22,204 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 07:07:22,207 maskrcnn_benchmark INFO: visual_prompt.3.dim_1 : Not Frozen, param number, 36
2024-03-19 07:07:22,208 maskrcnn_benchmark INFO: visual_prompt.3.dim_2 : Not Frozen, param number, 64
2024-03-19 07:07:22,208 maskrcnn_benchmark INFO: visual_prompt.3.dim_3 : Not Frozen, param number, 384
2024-03-19 07:07:22,208 maskrcnn_benchmark INFO: textual_prompt.3.dim_1 : Not Frozen, param number, 36
2024-03-19 07:07:22,208 maskrcnn_benchmark INFO: textual_prompt.3.dim_2 : Not Frozen, param number, 64
2024-03-19 07:07:22,208 maskrcnn_benchmark INFO: textual_prompt.3.dim_3 : Not Frozen, param number, 3072
2024-03-19 07:07:22,210 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 07:07:22,210 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.85s)
creating index...
index created!
2024-03-19 07:07:24,899 maskrcnn_benchmark INFO: Training on task 3: electronic, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 07:07:25,099 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 07:07:25,282 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 07:07:25,463 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 07:07:25,655 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
2024-03-19 07:07:25,838 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:43  iter: 20  loss: 2.1846 (1.9618)  loss_reg: 0.1881 (0.2877)  loss_centerness: 0.4741 (0.4849)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2861 (0.9951)  alignment_loss: 0.2206 (0.1942)  time: 1.4140 (1.4605)  data: 0.0162 (0.1448)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:14:14  iter: 40  loss: 1.9760 (1.9618)  loss_reg: 0.1965 (0.2858)  loss_centerness: 0.4749 (0.4847)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0709 (0.9965)  alignment_loss: 0.2200 (0.1947)  time: 1.3669 (1.4599)  data: 0.0153 (0.1444)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:13:45  iter: 60  loss: 1.8120 (1.9589)  loss_reg: 0.1878 (0.2838)  loss_centerness: 0.4718 (0.4844)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9235 (0.9954)  alignment_loss: 0.2193 (0.1953)  time: 1.3730 (1.4609)  data: 0.0160 (0.1454)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:13:16  iter: 80  loss: 1.6913 (1.9536)  loss_reg: 0.1990 (0.2820)  loss_centerness: 0.4732 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8051 (0.9916)  alignment_loss: 0.2187 (0.1958)  time: 1.3730 (1.4607)  data: 0.0171 (0.1451)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:12:46  iter: 100  loss: 1.7366 (1.9489)  loss_reg: 0.1932 (0.2802)  loss_centerness: 0.4707 (0.4840)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8305 (0.9885)  alignment_loss: 0.2181 (0.1963)  time: 1.3836 (1.4609)  data: 0.0159 (0.1454)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:12:17  iter: 120  loss: 1.6994 (1.9443)  loss_reg: 0.2034 (0.2788)  loss_centerness: 0.4737 (0.4838)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8312 (0.9851)  alignment_loss: 0.2175 (0.1967)  time: 1.3870 (1.4606)  data: 0.0174 (0.1451)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:11:48  iter: 140  loss: 1.6153 (1.9391)  loss_reg: 0.1873 (0.2773)  loss_centerness: 0.4720 (0.4836)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7486 (0.9811)  alignment_loss: 0.2168 (0.1971)  time: 1.3740 (1.4604)  data: 0.0132 (0.1448)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:11:18  iter: 160  loss: 1.6302 (1.9337)  loss_reg: 0.2024 (0.2759)  loss_centerness: 0.4735 (0.4834)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7414 (0.9769)  alignment_loss: 0.2161 (0.1975)  time: 1.3798 (1.4598)  data: 0.0181 (0.1445)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:10:49  iter: 180  loss: 1.6355 (1.9287)  loss_reg: 0.1923 (0.2745)  loss_centerness: 0.4720 (0.4832)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7696 (0.9731)  alignment_loss: 0.2154 (0.1978)  time: 1.4008 (1.4602)  data: 0.0181 (0.1442)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:10:20  iter: 200  loss: 1.6958 (1.9239)  loss_reg: 0.1884 (0.2731)  loss_centerness: 0.4742 (0.4831)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7822 (0.9696)  alignment_loss: 0.2147 (0.1981)  time: 1.3787 (1.4601)  data: 0.0204 (0.1439)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:09:51  iter: 220  loss: 1.5895 (1.9185)  loss_reg: 0.2021 (0.2718)  loss_centerness: 0.4742 (0.4829)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6991 (0.9654)  alignment_loss: 0.2139 (0.1984)  time: 1.3761 (1.4601)  data: 0.0137 (0.1436)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:09:22  iter: 240  loss: 1.6210 (1.9133)  loss_reg: 0.1984 (0.2704)  loss_centerness: 0.4731 (0.4827)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7527 (0.9615)  alignment_loss: 0.2131 (0.1987)  time: 1.3840 (1.4605)  data: 0.0177 (0.1439)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:08:52  iter: 260  loss: 1.6055 (1.9082)  loss_reg: 0.1876 (0.2692)  loss_centerness: 0.4726 (0.4826)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7290 (0.9575)  alignment_loss: 0.2122 (0.1990)  time: 1.3843 (1.4601)  data: 0.0157 (0.1437)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:08:23  iter: 280  loss: 1.5898 (1.9033)  loss_reg: 0.2041 (0.2680)  loss_centerness: 0.4753 (0.4824)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7300 (0.9537)  alignment_loss: 0.2113 (0.1992)  time: 1.3633 (1.4596)  data: 0.0131 (0.1433)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:07:54  iter: 300  loss: 1.5968 (1.8984)  loss_reg: 0.1752 (0.2669)  loss_centerness: 0.4725 (0.4823)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6937 (0.9499)  alignment_loss: 0.2102 (0.1994)  time: 1.3689 (1.4590)  data: 0.0139 (0.1430)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:07:25  iter: 320  loss: 1.6331 (1.8938)  loss_reg: 0.1854 (0.2657)  loss_centerness: 0.4717 (0.4821)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7381 (0.9465)  alignment_loss: 0.2092 (0.1995)  time: 1.3612 (1.4591)  data: 0.0132 (0.1427)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:06:55  iter: 340  loss: 1.6007 (1.8897)  loss_reg: 0.1993 (0.2648)  loss_centerness: 0.4746 (0.4820)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7073 (0.9433)  alignment_loss: 0.2080 (0.1997)  time: 1.3652 (1.4588)  data: 0.0177 (0.1425)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:06:26  iter: 360  loss: 1.5436 (1.8846)  loss_reg: 0.1769 (0.2636)  loss_centerness: 0.4739 (0.4818)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6911 (0.9394)  alignment_loss: 0.2067 (0.1998)  time: 1.3838 (1.4584)  data: 0.0191 (0.1422)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:05:57  iter: 380  loss: 1.6236 (1.8804)  loss_reg: 0.1871 (0.2624)  loss_centerness: 0.4733 (0.4817)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7450 (0.9364)  alignment_loss: 0.2053 (0.1999)  time: 1.3177 (1.4577)  data: 0.0145 (0.1419)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:05:28  iter: 400  loss: 1.5703 (1.8761)  loss_reg: 0.1897 (0.2614)  loss_centerness: 0.4711 (0.4815)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7086 (0.9332)  alignment_loss: 0.2039 (0.1999)  time: 1.3896 (1.4579)  data: 0.0174 (0.1417)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:04:58  iter: 420  loss: 1.5482 (1.8721)  loss_reg: 0.2164 (0.2607)  loss_centerness: 0.4753 (0.4815)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6940 (0.9299)  alignment_loss: 0.2022 (0.2000)  time: 1.3611 (1.4574)  data: 0.0152 (0.1415)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:04:29  iter: 440  loss: 1.5212 (1.8677)  loss_reg: 0.1868 (0.2597)  loss_centerness: 0.4722 (0.4813)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6812 (0.9267)  alignment_loss: 0.2005 (0.2000)  time: 1.3504 (1.4569)  data: 0.0170 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:04:00  iter: 460  loss: 1.6198 (1.8638)  loss_reg: 0.1897 (0.2587)  loss_centerness: 0.4722 (0.4812)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7399 (0.9239)  alignment_loss: 0.1986 (0.2000)  time: 1.3747 (1.4574)  data: 0.0165 (0.1418)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:03:31  iter: 480  loss: 1.5722 (1.8599)  loss_reg: 0.1967 (0.2580)  loss_centerness: 0.4749 (0.4811)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7085 (0.9209)  alignment_loss: 0.1966 (0.1999)  time: 1.3844 (1.4578)  data: 0.0170 (0.1417)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:03:02  iter: 500  loss: 1.5979 (1.8560)  loss_reg: 0.1939 (0.2572)  loss_centerness: 0.4738 (0.4810)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7081 (0.9180)  alignment_loss: 0.1945 (0.1998)  time: 1.3811 (1.4580)  data: 0.0149 (0.1416)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:02:33  iter: 520  loss: 1.5596 (1.8524)  loss_reg: 0.2023 (0.2565)  loss_centerness: 0.4736 (0.4809)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6970 (0.9153)  alignment_loss: 0.1922 (0.1997)  time: 1.3219 (1.4574)  data: 0.0156 (0.1414)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:02:03  iter: 540  loss: 1.5500 (1.8482)  loss_reg: 0.1888 (0.2556)  loss_centerness: 0.4724 (0.4808)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6919 (0.9122)  alignment_loss: 0.1898 (0.1996)  time: 1.4993 (1.4576)  data: 0.0137 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:01:34  iter: 560  loss: 1.6294 (1.8454)  loss_reg: 0.2146 (0.2551)  loss_centerness: 0.4754 (0.4807)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7713 (0.9102)  alignment_loss: 0.1873 (0.1994)  time: 1.3862 (1.4578)  data: 0.0145 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:01:05  iter: 580  loss: 1.5101 (1.8411)  loss_reg: 0.1872 (0.2542)  loss_centerness: 0.4738 (0.4806)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6888 (0.9071)  alignment_loss: 0.1848 (0.1992)  time: 1.4296 (1.4579)  data: 0.0147 (0.1409)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:36  iter: 600  loss: 1.5908 (1.8377)  loss_reg: 0.2037 (0.2535)  loss_centerness: 0.4737 (0.4805)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7205 (0.9048)  alignment_loss: 0.1822 (0.1990)  time: 1.4074 (1.4580)  data: 0.0150 (0.1408)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:07  iter: 620  loss: 1.5608 (1.8338)  loss_reg: 0.1937 (0.2528)  loss_centerness: 0.4723 (0.4804)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6835 (0.9019)  alignment_loss: 0.1795 (0.1987)  time: 1.3613 (1.4582)  data: 0.0182 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:00:00  iter: 625  loss: 1.5866 (1.8333)  loss_reg: 0.2034 (0.2527)  loss_centerness: 0.4745 (0.4804)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7141 (0.9016)  alignment_loss: 0.1787 (0.1986)  time: 1.3643 (1.4583)  data: 0.0133 (0.1410)  lr: 0.000000  wd: 0.000500  max mem: 12749
Evaluating
2024-03-19 07:24:28,817 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 07:24:38,337 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 07:24:38,341 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 07:24:38,375 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.5205479452054794, 0.6438356164383562] 

2024-03-19 07:24:38,375 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 07:24:38,376 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 07:24:38,376 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9178082191780822
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.5205479452054794, 0.6438356164383562], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 07:24:38,394 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 07:24:43,817 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 07:24:43,822 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 07:24:43,838 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2962962962962963, 0.8888888888888888, 1.0] 

2024-03-19 07:24:43,838 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 07:24:43,838 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 07:24:43,838 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2962962962962963, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 07:24:43,857 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 07:24:50,419 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 07:24:50,424 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 07:24:50,445 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.36363636363636365, 0.5454545454545454, 0.75] 

2024-03-19 07:24:50,446 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 07:24:50,446 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 07:24:50,446 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6818181818181818
evaluate on task refcoco, val, 2, res: {'refcoco': [0.36363636363636365, 0.5454545454545454, 0.75], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 07:24:50,466 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 07:25:16,279 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 07:25:16,284 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 07:25:16,404 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.29411764705882354, 0.807843137254902, 0.9215686274509803] 

2024-03-19 07:25:16,404 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 07:25:16,404 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 07:25:16,404 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9019607843137255
evaluate on task refcoco, val, 3, res: {'refcoco': [0.29411764705882354, 0.807843137254902, 0.9215686274509803], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 07:25:16,458 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 07:25:17,806 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 07:25:19,197 maskrcnn_benchmark.trainer INFO: Total training time: 0:17:53.340832 (1.7173 s / it)
2024-03-19 07:25:19,229 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 07:25:19,229 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 07:25:19,229 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 07:25:19,229 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 07:25:19,230 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 07:25:19,230 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 07:25:19,230 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 07:25:19,230 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 07:25:19,230 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 07:25:19,230 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 07:25:19,231 maskrcnn_benchmark INFO: visual_prompt.4.dim_1 : Not Frozen, param number, 36
2024-03-19 07:25:19,231 maskrcnn_benchmark INFO: visual_prompt.4.dim_2 : Not Frozen, param number, 64
2024-03-19 07:25:19,231 maskrcnn_benchmark INFO: visual_prompt.4.dim_3 : Not Frozen, param number, 384
2024-03-19 07:25:19,231 maskrcnn_benchmark INFO: textual_prompt.4.dim_1 : Not Frozen, param number, 36
2024-03-19 07:25:19,231 maskrcnn_benchmark INFO: textual_prompt.4.dim_2 : Not Frozen, param number, 64
2024-03-19 07:25:19,231 maskrcnn_benchmark INFO: textual_prompt.4.dim_3 : Not Frozen, param number, 3072
2024-03-19 07:25:19,234 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 07:25:19,235 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=2.04s)
creating index...
index created!
2024-03-19 07:25:22,202 maskrcnn_benchmark INFO: Training on task 4: accessory, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.06s)
creating index...
index created!
2024-03-19 07:25:23,417 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 07:25:23,602 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 07:25:23,786 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 07:25:23,969 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 07:25:24,152 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
2024-03-19 07:25:24,362 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:42  iter: 20  loss: 2.3610 (1.8410)  loss_reg: 0.2489 (0.2525)  loss_centerness: 0.4784 (0.4804)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4007 (0.9093)  alignment_loss: 0.2112 (0.1988)  time: 1.4037 (1.4595)  data: 0.1183 (0.1422)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:14:13  iter: 40  loss: 2.1267 (1.8449)  loss_reg: 0.2469 (0.2524)  loss_centerness: 0.4790 (0.4804)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1784 (0.9133)  alignment_loss: 0.2049 (0.1989)  time: 1.3167 (1.4588)  data: 0.0153 (0.1420)  lr: 0.010000  wd: 0.000500  max mem: 12749
eta: 0:13:44  iter: 60  loss: 2.0142 (1.8472)  loss_reg: 0.2198 (0.2520)  loss_centerness: 0.4778 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1214 (0.9159)  alignment_loss: 0.1992 (0.1989)  time: 1.3652 (1.4591)  data: 0.0183 (0.1422)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:15  iter: 80  loss: 1.9511 (1.8489)  loss_reg: 0.2352 (0.2519)  loss_centerness: 0.4770 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0409 (0.9178)  alignment_loss: 0.1941 (0.1988)  time: 1.3890 (1.4588)  data: 0.0142 (0.1420)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:45  iter: 100  loss: 1.9738 (1.8508)  loss_reg: 0.2365 (0.2518)  loss_centerness: 0.4760 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0766 (0.9200)  alignment_loss: 0.1888 (0.1987)  time: 1.3691 (1.4586)  data: 0.0133 (0.1419)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:16  iter: 120  loss: 1.8827 (1.8517)  loss_reg: 0.2204 (0.2514)  loss_centerness: 0.4800 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0114 (0.9215)  alignment_loss: 0.1832 (0.1985)  time: 1.3660 (1.4582)  data: 0.0150 (0.1417)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:47  iter: 140  loss: 1.8890 (1.8520)  loss_reg: 0.2162 (0.2512)  loss_centerness: 0.4770 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9811 (0.9223)  alignment_loss: 0.1773 (0.1982)  time: 1.4029 (1.4582)  data: 0.0131 (0.1415)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:17  iter: 160  loss: 1.9071 (1.8528)  loss_reg: 0.2257 (0.2510)  loss_centerness: 0.4773 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0147 (0.9236)  alignment_loss: 0.1711 (0.1979)  time: 1.3592 (1.4579)  data: 0.0133 (0.1414)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:48  iter: 180  loss: 1.9232 (1.8539)  loss_reg: 0.2334 (0.2509)  loss_centerness: 0.4790 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0439 (0.9253)  alignment_loss: 0.1648 (0.1975)  time: 1.3179 (1.4573)  data: 0.0164 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:19  iter: 200  loss: 1.8198 (1.8540)  loss_reg: 0.2113 (0.2505)  loss_centerness: 0.4770 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9718 (0.9263)  alignment_loss: 0.1584 (0.1970)  time: 1.3654 (1.4571)  data: 0.0131 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:50  iter: 220  loss: 1.8727 (1.8542)  loss_reg: 0.2481 (0.2505)  loss_centerness: 0.4799 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9857 (0.9270)  alignment_loss: 0.1520 (0.1965)  time: 1.3948 (1.4573)  data: 0.0131 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:21  iter: 240  loss: 1.8496 (1.8548)  loss_reg: 0.2328 (0.2504)  loss_centerness: 0.4794 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9812 (0.9283)  alignment_loss: 0.1456 (0.1959)  time: 1.3846 (1.4572)  data: 0.0132 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:51  iter: 260  loss: 1.8245 (1.8549)  loss_reg: 0.2358 (0.2503)  loss_centerness: 0.4789 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0019 (0.9292)  alignment_loss: 0.1395 (0.1953)  time: 1.3636 (1.4575)  data: 0.0165 (0.1413)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:22  iter: 280  loss: 1.8712 (1.8550)  loss_reg: 0.2369 (0.2501)  loss_centerness: 0.4784 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0124 (0.9301)  alignment_loss: 0.1337 (0.1946)  time: 1.3551 (1.4571)  data: 0.0152 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:53  iter: 300  loss: 1.7771 (1.8543)  loss_reg: 0.2174 (0.2499)  loss_centerness: 0.4784 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9430 (0.9304)  alignment_loss: 0.1282 (0.1938)  time: 1.3109 (1.4569)  data: 0.0163 (0.1413)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:24  iter: 320  loss: 1.8331 (1.8542)  loss_reg: 0.2433 (0.2499)  loss_centerness: 0.4769 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9854 (0.9311)  alignment_loss: 0.1230 (0.1930)  time: 1.3538 (1.4568)  data: 0.0160 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:55  iter: 340  loss: 1.8299 (1.8537)  loss_reg: 0.2286 (0.2497)  loss_centerness: 0.4780 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9758 (0.9316)  alignment_loss: 0.1181 (0.1922)  time: 1.3935 (1.4566)  data: 0.0140 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:25  iter: 360  loss: 1.7932 (1.8532)  loss_reg: 0.2340 (0.2496)  loss_centerness: 0.4781 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9628 (0.9321)  alignment_loss: 0.1134 (0.1913)  time: 1.3950 (1.4566)  data: 0.0195 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:56  iter: 380  loss: 1.7541 (1.8522)  loss_reg: 0.2184 (0.2494)  loss_centerness: 0.4758 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9390 (0.9323)  alignment_loss: 0.1090 (0.1904)  time: 1.3571 (1.4567)  data: 0.0151 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:27  iter: 400  loss: 1.7957 (1.8515)  loss_reg: 0.2431 (0.2493)  loss_centerness: 0.4774 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9555 (0.9326)  alignment_loss: 0.1047 (0.1895)  time: 1.3549 (1.4564)  data: 0.0135 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:58  iter: 420  loss: 1.7727 (1.8507)  loss_reg: 0.2365 (0.2492)  loss_centerness: 0.4802 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9324 (0.9327)  alignment_loss: 0.1006 (0.1886)  time: 1.3596 (1.4564)  data: 0.0142 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:29  iter: 440  loss: 1.7525 (1.8500)  loss_reg: 0.2283 (0.2491)  loss_centerness: 0.4795 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9446 (0.9332)  alignment_loss: 0.0968 (0.1876)  time: 1.3667 (1.4562)  data: 0.0164 (0.1409)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:00  iter: 460  loss: 1.7416 (1.8491)  loss_reg: 0.2246 (0.2489)  loss_centerness: 0.4771 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9317 (0.9334)  alignment_loss: 0.0930 (0.1867)  time: 1.3877 (1.4561)  data: 0.0148 (0.1407)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:31  iter: 480  loss: 1.7463 (1.8479)  loss_reg: 0.2330 (0.2488)  loss_centerness: 0.4810 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9418 (0.9334)  alignment_loss: 0.0895 (0.1857)  time: 1.3716 (1.4560)  data: 0.0151 (0.1406)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:01  iter: 500  loss: 1.7151 (1.8470)  loss_reg: 0.2279 (0.2487)  loss_centerness: 0.4767 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9462 (0.9336)  alignment_loss: 0.0861 (0.1847)  time: 1.3748 (1.4557)  data: 0.0131 (0.1404)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:32  iter: 520  loss: 1.7537 (1.8459)  loss_reg: 0.2227 (0.2485)  loss_centerness: 0.4786 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9189 (0.9338)  alignment_loss: 0.0829 (0.1836)  time: 1.3916 (1.4555)  data: 0.0144 (0.1403)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:03  iter: 540  loss: 1.7375 (1.8451)  loss_reg: 0.2450 (0.2485)  loss_centerness: 0.4791 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9424 (0.9340)  alignment_loss: 0.0798 (0.1826)  time: 1.3780 (1.4558)  data: 0.0136 (0.1405)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:34  iter: 560  loss: 1.7397 (1.8441)  loss_reg: 0.2238 (0.2483)  loss_centerness: 0.4776 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9301 (0.9342)  alignment_loss: 0.0769 (0.1816)  time: 1.3104 (1.4553)  data: 0.0161 (0.1403)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:05  iter: 580  loss: 1.7400 (1.8430)  loss_reg: 0.2300 (0.2482)  loss_centerness: 0.4780 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9347 (0.9342)  alignment_loss: 0.0741 (0.1805)  time: 1.3958 (1.4553)  data: 0.0193 (0.1403)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:36  iter: 600  loss: 1.6844 (1.8416)  loss_reg: 0.2463 (0.2481)  loss_centerness: 0.4787 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8937 (0.9340)  alignment_loss: 0.0714 (0.1795)  time: 1.3595 (1.4551)  data: 0.0132 (0.1402)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:07  iter: 620  loss: 1.7041 (1.8405)  loss_reg: 0.2393 (0.2480)  loss_centerness: 0.4762 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9158 (0.9341)  alignment_loss: 0.0688 (0.1784)  time: 1.3698 (1.4552)  data: 0.0175 (0.1401)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:00  iter: 625  loss: 1.6964 (1.8403)  loss_reg: 0.2355 (0.2480)  loss_centerness: 0.4776 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9153 (0.9342)  alignment_loss: 0.0680 (0.1781)  time: 1.3698 (1.4552)  data: 0.0175 (0.1400)  lr: 0.000000  wd: 0.000500  max mem: 12750
Evaluating
2024-03-19 07:42:16,398 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 07:42:25,087 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 07:42:25,091 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 07:42:25,122 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1506849315068493, 0.5205479452054794, 0.6575342465753424] 

2024-03-19 07:42:25,122 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 07:42:25,122 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 07:42:25,122 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9178082191780822
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1506849315068493, 0.5205479452054794, 0.6575342465753424], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 07:42:25,136 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 07:42:30,322 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 07:42:30,326 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 07:42:30,339 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2222222222222222, 0.8888888888888888, 1.0] 

2024-03-19 07:42:30,339 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 07:42:30,339 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 07:42:30,339 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2222222222222222, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 07:42:30,357 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 07:42:36,514 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 07:42:36,518 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 07:42:36,535 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3181818181818182, 0.5227272727272727, 0.7272727272727273] 

2024-03-19 07:42:36,535 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 07:42:36,535 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 07:42:36,535 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.3181818181818182, 0.5227272727272727, 0.7272727272727273], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 07:42:36,553 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 07:43:00,869 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 07:43:00,873 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 07:43:00,967 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2901960784313726, 0.8117647058823529, 0.9215686274509803] 

2024-03-19 07:43:00,968 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 07:43:00,968 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 07:43:00,968 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8784313725490196
evaluate on task refcoco, val, 3, res: {'refcoco': [0.2901960784313726, 0.8117647058823529, 0.9215686274509803], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 07:43:00,982 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 07:43:22,068 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 07:43:22,071 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 07:43:22,156 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2761904761904762, 0.8047619047619048, 0.8952380952380953] 

2024-03-19 07:43:22,156 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 07:43:22,157 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 07:43:22,157 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9095238095238095
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2761904761904762, 0.8047619047619048, 0.8952380952380953], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 07:43:22,201 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 07:43:23,243 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 07:43:24,460 maskrcnn_benchmark.trainer INFO: Total training time: 0:18:00.084137 (1.7281 s / it)
2024-03-19 07:43:24,485 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 07:43:24,485 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 07:43:24,485 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 07:43:24,485 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 07:43:24,485 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 07:43:24,485 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 07:43:24,485 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 07:43:24,485 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 07:43:24,485 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 07:43:24,485 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 07:43:24,486 maskrcnn_benchmark INFO: visual_prompt.5.dim_1 : Not Frozen, param number, 36
2024-03-19 07:43:24,486 maskrcnn_benchmark INFO: visual_prompt.5.dim_2 : Not Frozen, param number, 64
2024-03-19 07:43:24,486 maskrcnn_benchmark INFO: visual_prompt.5.dim_3 : Not Frozen, param number, 384
2024-03-19 07:43:24,486 maskrcnn_benchmark INFO: textual_prompt.5.dim_1 : Not Frozen, param number, 36
2024-03-19 07:43:24,486 maskrcnn_benchmark INFO: textual_prompt.5.dim_2 : Not Frozen, param number, 64
2024-03-19 07:43:24,486 maskrcnn_benchmark INFO: textual_prompt.5.dim_3 : Not Frozen, param number, 3072
2024-03-19 07:43:24,489 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 07:43:24,489 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.99s)
creating index...
index created!
2024-03-19 07:43:27,339 maskrcnn_benchmark INFO: Training on task 5: indoor, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.95s)
creating index...
index created!
2024-03-19 07:43:28,425 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 07:43:28,615 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 07:43:28,800 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 07:43:28,984 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 07:43:29,165 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 07:43:29,350 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
2024-03-19 07:43:29,567 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:40  iter: 20  loss: 2.2156 (1.8440)  loss_reg: 0.2290 (0.2479)  loss_centerness: 0.4783 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3081 (0.9376)  alignment_loss: 0.2182 (0.1785)  time: 1.3580 (1.4562)  data: 0.0135 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:14:11  iter: 40  loss: 2.0928 (1.8462)  loss_reg: 0.2357 (0.2478)  loss_centerness: 0.4778 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1446 (0.9396)  alignment_loss: 0.2171 (0.1789)  time: 1.4067 (1.4564)  data: 0.0132 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:42  iter: 60  loss: 1.8934 (1.8471)  loss_reg: 0.2207 (0.2476)  loss_centerness: 0.4783 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9914 (0.9403)  alignment_loss: 0.2159 (0.1792)  time: 1.3749 (1.4563)  data: 0.0133 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:13  iter: 80  loss: 1.9515 (1.8483)  loss_reg: 0.2402 (0.2476)  loss_centerness: 0.4804 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0348 (0.9412)  alignment_loss: 0.2149 (0.1796)  time: 1.3867 (1.4560)  data: 0.0141 (0.1409)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:44  iter: 100  loss: 1.8709 (1.8488)  loss_reg: 0.2140 (0.2474)  loss_centerness: 0.4758 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9811 (0.9416)  alignment_loss: 0.2140 (0.1799)  time: 1.3710 (1.4559)  data: 0.0168 (0.1408)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:15  iter: 120  loss: 1.8965 (1.8495)  loss_reg: 0.2278 (0.2473)  loss_centerness: 0.4775 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9662 (0.9421)  alignment_loss: 0.2131 (0.1802)  time: 1.3269 (1.4558)  data: 0.0184 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:45  iter: 140  loss: 1.9077 (1.8501)  loss_reg: 0.2405 (0.2472)  loss_centerness: 0.4798 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9819 (0.9425)  alignment_loss: 0.2122 (0.1805)  time: 1.4110 (1.4556)  data: 0.0153 (0.1408)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:16  iter: 160  loss: 1.9040 (1.8507)  loss_reg: 0.2302 (0.2472)  loss_centerness: 0.4769 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9787 (0.9429)  alignment_loss: 0.2113 (0.1807)  time: 1.3926 (1.4557)  data: 0.0152 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:47  iter: 180  loss: 1.9065 (1.8511)  loss_reg: 0.2324 (0.2470)  loss_centerness: 0.4777 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9827 (0.9432)  alignment_loss: 0.2104 (0.1810)  time: 1.3496 (1.4559)  data: 0.0130 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:18  iter: 200  loss: 1.8282 (1.8513)  loss_reg: 0.2293 (0.2469)  loss_centerness: 0.4782 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9312 (0.9433)  alignment_loss: 0.2094 (0.1812)  time: 1.3616 (1.4561)  data: 0.0130 (0.1414)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:49  iter: 220  loss: 1.8285 (1.8516)  loss_reg: 0.2178 (0.2468)  loss_centerness: 0.4760 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9149 (0.9435)  alignment_loss: 0.2083 (0.1815)  time: 1.3224 (1.4562)  data: 0.0118 (0.1413)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:20  iter: 240  loss: 1.8743 (1.8520)  loss_reg: 0.2384 (0.2466)  loss_centerness: 0.4775 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9589 (0.9438)  alignment_loss: 0.2071 (0.1817)  time: 1.3554 (1.4561)  data: 0.0129 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:51  iter: 260  loss: 1.8441 (1.8521)  loss_reg: 0.2488 (0.2467)  loss_centerness: 0.4792 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9257 (0.9437)  alignment_loss: 0.2058 (0.1819)  time: 1.2982 (1.4558)  data: 0.0116 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:22  iter: 280  loss: 1.9076 (1.8524)  loss_reg: 0.2373 (0.2466)  loss_centerness: 0.4788 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9839 (0.9440)  alignment_loss: 0.2044 (0.1821)  time: 1.3110 (1.4556)  data: 0.0129 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:53  iter: 300  loss: 1.8459 (1.8524)  loss_reg: 0.1930 (0.2463)  loss_centerness: 0.4751 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9405 (0.9441)  alignment_loss: 0.2028 (0.1822)  time: 1.2973 (1.4557)  data: 0.0125 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:23  iter: 320  loss: 1.8937 (1.8525)  loss_reg: 0.2410 (0.2462)  loss_centerness: 0.4786 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9556 (0.9441)  alignment_loss: 0.2010 (0.1824)  time: 1.3436 (1.4556)  data: 0.0127 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:54  iter: 340  loss: 1.8155 (1.8525)  loss_reg: 0.2047 (0.2461)  loss_centerness: 0.4754 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9083 (0.9442)  alignment_loss: 0.1989 (0.1825)  time: 1.2980 (1.4552)  data: 0.0115 (0.1409)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:25  iter: 360  loss: 1.8498 (1.8529)  loss_reg: 0.2416 (0.2460)  loss_centerness: 0.4799 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9408 (0.9445)  alignment_loss: 0.1966 (0.1827)  time: 1.3500 (1.4552)  data: 0.0131 (0.1408)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:56  iter: 380  loss: 1.7987 (1.8526)  loss_reg: 0.2263 (0.2459)  loss_centerness: 0.4778 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9031 (0.9442)  alignment_loss: 0.1941 (0.1827)  time: 1.3600 (1.4555)  data: 0.0132 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:27  iter: 400  loss: 1.8241 (1.8524)  loss_reg: 0.2273 (0.2458)  loss_centerness: 0.4790 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9276 (0.9440)  alignment_loss: 0.1912 (0.1828)  time: 1.3147 (1.4553)  data: 0.0118 (0.1408)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:58  iter: 420  loss: 1.8698 (1.8526)  loss_reg: 0.2442 (0.2458)  loss_centerness: 0.4772 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9439 (0.9442)  alignment_loss: 0.1881 (0.1829)  time: 1.3567 (1.4551)  data: 0.0131 (0.1407)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:29  iter: 440  loss: 1.8396 (1.8525)  loss_reg: 0.2315 (0.2457)  loss_centerness: 0.4790 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9303 (0.9442)  alignment_loss: 0.1847 (0.1829)  time: 1.3666 (1.4554)  data: 0.0133 (0.1407)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:00  iter: 460  loss: 1.8080 (1.8523)  loss_reg: 0.2217 (0.2456)  loss_centerness: 0.4762 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9193 (0.9441)  alignment_loss: 0.1809 (0.1829)  time: 1.3606 (1.4555)  data: 0.0135 (0.1407)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:31  iter: 480  loss: 1.8248 (1.8523)  loss_reg: 0.2255 (0.2456)  loss_centerness: 0.4768 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9540 (0.9442)  alignment_loss: 0.1770 (0.1828)  time: 1.3511 (1.4557)  data: 0.0131 (0.1408)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:01  iter: 500  loss: 1.7410 (1.8518)  loss_reg: 0.2176 (0.2455)  loss_centerness: 0.4788 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8449 (0.9439)  alignment_loss: 0.1727 (0.1827)  time: 1.3531 (1.4557)  data: 0.0129 (0.1408)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:32  iter: 520  loss: 1.8344 (1.8515)  loss_reg: 0.2430 (0.2454)  loss_centerness: 0.4803 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9290 (0.9438)  alignment_loss: 0.1684 (0.1826)  time: 1.3561 (1.4558)  data: 0.0134 (0.1407)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:03  iter: 540  loss: 1.7852 (1.8513)  loss_reg: 0.2238 (0.2453)  loss_centerness: 0.4756 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9307 (0.9438)  alignment_loss: 0.1639 (0.1825)  time: 1.3031 (1.4556)  data: 0.0115 (0.1407)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:34  iter: 560  loss: 1.7574 (1.8505)  loss_reg: 0.2290 (0.2452)  loss_centerness: 0.4774 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8685 (0.9434)  alignment_loss: 0.1593 (0.1823)  time: 1.3084 (1.4556)  data: 0.0127 (0.1406)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:05  iter: 580  loss: 1.8392 (1.8504)  loss_reg: 0.2273 (0.2452)  loss_centerness: 0.4767 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9340 (0.9435)  alignment_loss: 0.1548 (0.1821)  time: 1.3520 (1.4556)  data: 0.0128 (0.1405)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:36  iter: 600  loss: 1.7491 (1.8501)  loss_reg: 0.2394 (0.2451)  loss_centerness: 0.4791 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9043 (0.9434)  alignment_loss: 0.1502 (0.1819)  time: 1.3564 (1.4556)  data: 0.0129 (0.1405)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:07  iter: 620  loss: 1.7492 (1.8495)  loss_reg: 0.2268 (0.2450)  loss_centerness: 0.4765 (0.4796)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8995 (0.9432)  alignment_loss: 0.1456 (0.1816)  time: 1.3750 (1.4565)  data: 0.0127 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:00  iter: 625  loss: 1.7272 (1.8493)  loss_reg: 0.2269 (0.2450)  loss_centerness: 0.4775 (0.4796)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8762 (0.9431)  alignment_loss: 0.1442 (0.1815)  time: 1.3658 (1.4564)  data: 0.0124 (0.1409)  lr: 0.000000  wd: 0.000500  max mem: 12750
Evaluating
2024-03-19 08:00:32,833 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 08:00:41,368 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:00:41,372 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:00:41,407 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.4794520547945205, 0.6438356164383562] 

2024-03-19 08:00:41,408 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:00:41,408 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:00:41,408 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9178082191780822
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.4794520547945205, 0.6438356164383562], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:00:41,423 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 08:00:45,831 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:00:45,835 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 08:00:45,848 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2222222222222222, 0.8888888888888888, 1.0] 

2024-03-19 08:00:45,848 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:00:45,849 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:00:45,849 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2222222222222222, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:00:45,864 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 08:00:51,950 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:00:51,954 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:00:51,974 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3181818181818182, 0.5227272727272727, 0.7272727272727273] 

2024-03-19 08:00:51,975 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:00:51,975 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:00:51,975 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.3181818181818182, 0.5227272727272727, 0.7272727272727273], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:00:51,993 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 08:01:16,396 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:01:16,402 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:01:16,507 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.30196078431372547, 0.8196078431372549, 0.9215686274509803] 

2024-03-19 08:01:16,507 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:01:16,507 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:01:16,507 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8784313725490196
evaluate on task refcoco, val, 3, res: {'refcoco': [0.30196078431372547, 0.8196078431372549, 0.9215686274509803], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:01:16,522 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 08:01:38,014 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:01:38,017 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 08:01:38,111 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2761904761904762, 0.8095238095238095, 0.8952380952380953] 

2024-03-19 08:01:38,111 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:01:38,111 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:01:38,111 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9095238095238095
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2761904761904762, 0.8095238095238095, 0.8952380952380953], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:01:38,128 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 08:02:07,079 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:02:07,083 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:02:07,209 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.238562091503268, 0.7483660130718954, 0.8921568627450981] 

2024-03-19 08:02:07,209 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:02:07,210 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:02:07,210 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9248366013071896
evaluate on task refcoco, val, 5, res: {'refcoco': [0.238562091503268, 0.7483660130718954, 0.8921568627450981], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:02:07,254 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 08:02:08,248 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 08:02:09,594 maskrcnn_benchmark.trainer INFO: Total training time: 0:18:40.013127 (1.7920 s / it)
2024-03-19 08:02:09,623 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 08:02:09,623 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 08:02:09,623 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 08:02:09,623 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 08:02:09,623 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 08:02:09,623 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 08:02:09,623 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 08:02:09,624 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 08:02:09,624 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 08:02:09,624 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 08:02:09,625 maskrcnn_benchmark INFO: visual_prompt.6.dim_1 : Not Frozen, param number, 36
2024-03-19 08:02:09,625 maskrcnn_benchmark INFO: visual_prompt.6.dim_2 : Not Frozen, param number, 64
2024-03-19 08:02:09,625 maskrcnn_benchmark INFO: visual_prompt.6.dim_3 : Not Frozen, param number, 384
2024-03-19 08:02:09,625 maskrcnn_benchmark INFO: textual_prompt.6.dim_1 : Not Frozen, param number, 36
2024-03-19 08:02:09,625 maskrcnn_benchmark INFO: textual_prompt.6.dim_2 : Not Frozen, param number, 64
2024-03-19 08:02:09,625 maskrcnn_benchmark INFO: textual_prompt.6.dim_3 : Not Frozen, param number, 3072
2024-03-19 08:02:09,628 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 08:02:09,628 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=2.17s)
creating index...
index created!
2024-03-19 08:02:12,702 maskrcnn_benchmark INFO: Training on task 6: kitchen, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 08:02:12,914 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 08:02:13,107 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 08:02:13,290 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 08:02:13,477 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 08:02:13,664 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.15s)
creating index...
index created!
2024-03-19 08:02:14,940 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 08:02:15,126 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
2024-03-19 08:02:15,389 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:41  iter: 20  loss: 1.9212 (1.8499)  loss_reg: 0.1746 (0.2445)  loss_centerness: 0.4691 (0.4796)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0483 (0.9441)  alignment_loss: 0.2249 (0.1818)  time: 1.3182 (1.4570)  data: 0.0119 (0.1416)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:14:12  iter: 40  loss: 1.8331 (1.8497)  loss_reg: 0.1707 (0.2440)  loss_centerness: 0.4677 (0.4795)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9716 (0.9443)  alignment_loss: 0.2061 (0.1820)  time: 1.3504 (1.4569)  data: 0.0133 (0.1415)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:42  iter: 60  loss: 1.7075 (1.8492)  loss_reg: 0.1834 (0.2435)  loss_centerness: 0.4701 (0.4794)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8587 (0.9442)  alignment_loss: 0.1933 (0.1821)  time: 1.3002 (1.4566)  data: 0.0116 (0.1414)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:13  iter: 80  loss: 1.6547 (1.8480)  loss_reg: 0.1736 (0.2430)  loss_centerness: 0.4685 (0.4793)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8000 (0.9435)  alignment_loss: 0.1848 (0.1821)  time: 1.3530 (1.4566)  data: 0.0132 (0.1413)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:44  iter: 100  loss: 1.6659 (1.8467)  loss_reg: 0.1719 (0.2425)  loss_centerness: 0.4698 (0.4793)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8283 (0.9428)  alignment_loss: 0.1786 (0.1821)  time: 1.3019 (1.4562)  data: 0.0115 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:15  iter: 120  loss: 1.6494 (1.8453)  loss_reg: 0.1769 (0.2421)  loss_centerness: 0.4701 (0.4792)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8401 (0.9419)  alignment_loss: 0.1736 (0.1820)  time: 1.3541 (1.4562)  data: 0.0130 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:46  iter: 140  loss: 1.6463 (1.8437)  loss_reg: 0.1733 (0.2416)  loss_centerness: 0.4701 (0.4791)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8215 (0.9410)  alignment_loss: 0.1696 (0.1819)  time: 1.3062 (1.4562)  data: 0.0117 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:17  iter: 160  loss: 1.6302 (1.8422)  loss_reg: 0.1692 (0.2411)  loss_centerness: 0.4699 (0.4791)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8226 (0.9401)  alignment_loss: 0.1664 (0.1818)  time: 1.3581 (1.4563)  data: 0.0130 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:48  iter: 180  loss: 1.5994 (1.8407)  loss_reg: 0.1721 (0.2407)  loss_centerness: 0.4685 (0.4790)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8045 (0.9393)  alignment_loss: 0.1637 (0.1817)  time: 1.3583 (1.4564)  data: 0.0132 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:18  iter: 200  loss: 1.6175 (1.8393)  loss_reg: 0.1823 (0.2403)  loss_centerness: 0.4675 (0.4789)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8134 (0.9385)  alignment_loss: 0.1615 (0.1816)  time: 1.3340 (1.4563)  data: 0.0131 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:49  iter: 220  loss: 1.6216 (1.8379)  loss_reg: 0.1678 (0.2399)  loss_centerness: 0.4708 (0.4789)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8171 (0.9377)  alignment_loss: 0.1597 (0.1814)  time: 1.3277 (1.4564)  data: 0.0127 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:20  iter: 240  loss: 1.5581 (1.8361)  loss_reg: 0.1684 (0.2395)  loss_centerness: 0.4698 (0.4788)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7719 (0.9366)  alignment_loss: 0.1582 (0.1813)  time: 1.3027 (1.4561)  data: 0.0121 (0.1409)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:51  iter: 260  loss: 1.5602 (1.8343)  loss_reg: 0.1657 (0.2390)  loss_centerness: 0.4679 (0.4787)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7467 (0.9354)  alignment_loss: 0.1568 (0.1811)  time: 1.3416 (1.4559)  data: 0.0114 (0.1407)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:22  iter: 280  loss: 1.5593 (1.8327)  loss_reg: 0.1792 (0.2387)  loss_centerness: 0.4699 (0.4787)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7678 (0.9344)  alignment_loss: 0.1557 (0.1809)  time: 1.3027 (1.4557)  data: 0.0114 (0.1406)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:53  iter: 300  loss: 1.5374 (1.8308)  loss_reg: 0.1622 (0.2382)  loss_centerness: 0.4701 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7517 (0.9332)  alignment_loss: 0.1547 (0.1808)  time: 1.3776 (1.4558)  data: 0.0131 (0.1406)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:24  iter: 320  loss: 1.6149 (1.8294)  loss_reg: 0.1827 (0.2378)  loss_centerness: 0.4689 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8236 (0.9324)  alignment_loss: 0.1537 (0.1806)  time: 1.3555 (1.4559)  data: 0.0127 (0.1407)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:54  iter: 340  loss: 1.5451 (1.8278)  loss_reg: 0.1835 (0.2374)  loss_centerness: 0.4702 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7590 (0.9315)  alignment_loss: 0.1528 (0.1804)  time: 1.3466 (1.4558)  data: 0.0131 (0.1406)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:25  iter: 360  loss: 1.5813 (1.8263)  loss_reg: 0.1768 (0.2371)  loss_centerness: 0.4692 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7645 (0.9305)  alignment_loss: 0.1520 (0.1802)  time: 1.3434 (1.4557)  data: 0.0134 (0.1405)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:56  iter: 380  loss: 1.5375 (1.8246)  loss_reg: 0.1713 (0.2367)  loss_centerness: 0.4706 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7487 (0.9295)  alignment_loss: 0.1511 (0.1800)  time: 1.3356 (1.4556)  data: 0.0129 (0.1404)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:27  iter: 400  loss: 1.6030 (1.8232)  loss_reg: 0.1794 (0.2363)  loss_centerness: 0.4717 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7966 (0.9286)  alignment_loss: 0.1502 (0.1798)  time: 1.3720 (1.4559)  data: 0.0132 (0.1406)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:58  iter: 420  loss: 1.5239 (1.8214)  loss_reg: 0.1645 (0.2359)  loss_centerness: 0.4667 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7382 (0.9275)  alignment_loss: 0.1493 (0.1796)  time: 1.3215 (1.4559)  data: 0.0127 (0.1405)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:29  iter: 440  loss: 1.5631 (1.8198)  loss_reg: 0.1843 (0.2356)  loss_centerness: 0.4689 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7698 (0.9265)  alignment_loss: 0.1483 (0.1795)  time: 1.3589 (1.4559)  data: 0.0131 (0.1405)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:00  iter: 460  loss: 1.5342 (1.8180)  loss_reg: 0.1668 (0.2352)  loss_centerness: 0.4690 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7568 (0.9254)  alignment_loss: 0.1473 (0.1792)  time: 1.3258 (1.4558)  data: 0.0118 (0.1404)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:31  iter: 480  loss: 1.5668 (1.8164)  loss_reg: 0.1670 (0.2348)  loss_centerness: 0.4683 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7523 (0.9244)  alignment_loss: 0.1462 (0.1790)  time: 1.3528 (1.4557)  data: 0.0127 (0.1403)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:01  iter: 500  loss: 1.5555 (1.8148)  loss_reg: 0.1749 (0.2344)  loss_centerness: 0.4705 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7627 (0.9234)  alignment_loss: 0.1449 (0.1788)  time: 1.3156 (1.4558)  data: 0.0125 (0.1405)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:32  iter: 520  loss: 1.5303 (1.8132)  loss_reg: 0.1573 (0.2341)  loss_centerness: 0.4678 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7693 (0.9225)  alignment_loss: 0.1436 (0.1786)  time: 1.3071 (1.4557)  data: 0.0128 (0.1404)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:03  iter: 540  loss: 1.5318 (1.8116)  loss_reg: 0.1785 (0.2338)  loss_centerness: 0.4685 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7606 (0.9215)  alignment_loss: 0.1421 (0.1784)  time: 1.3403 (1.4556)  data: 0.0128 (0.1403)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:34  iter: 560  loss: 1.5646 (1.8102)  loss_reg: 0.1658 (0.2335)  loss_centerness: 0.4704 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7945 (0.9206)  alignment_loss: 0.1405 (0.1782)  time: 1.3513 (1.4556)  data: 0.0131 (0.1403)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:05  iter: 580  loss: 1.5293 (1.8086)  loss_reg: 0.1778 (0.2332)  loss_centerness: 0.4700 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7303 (0.9196)  alignment_loss: 0.1387 (0.1779)  time: 1.3634 (1.4557)  data: 0.0121 (0.1402)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:36  iter: 600  loss: 1.5126 (1.8069)  loss_reg: 0.1704 (0.2328)  loss_centerness: 0.4697 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7335 (0.9186)  alignment_loss: 0.1367 (0.1777)  time: 1.3569 (1.4557)  data: 0.0131 (0.1402)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:07  iter: 620  loss: 1.5365 (1.8055)  loss_reg: 0.1721 (0.2325)  loss_centerness: 0.4683 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7552 (0.9178)  alignment_loss: 0.1345 (0.1774)  time: 1.3119 (1.4555)  data: 0.0116 (0.1401)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:00  iter: 625  loss: 1.5297 (1.8051)  loss_reg: 0.1586 (0.2324)  loss_centerness: 0.4675 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7552 (0.9176)  alignment_loss: 0.1337 (0.1773)  time: 1.3119 (1.4556)  data: 0.0116 (0.1401)  lr: 0.000000  wd: 0.000500  max mem: 12750
Evaluating
2024-03-19 08:19:11,425 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 08:19:20,246 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:19:20,249 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:19:20,286 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.4931506849315068, 0.6438356164383562] 

2024-03-19 08:19:20,286 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:19:20,286 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:19:20,286 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9178082191780822
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.4931506849315068, 0.6438356164383562], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:19:20,303 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 08:19:25,095 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:19:25,098 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 08:19:25,112 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2222222222222222, 0.8888888888888888, 1.0] 

2024-03-19 08:19:25,112 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:19:25,112 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:19:25,112 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2222222222222222, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:19:25,126 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 08:19:31,893 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:19:31,897 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:19:31,914 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3181818181818182, 0.5227272727272727, 0.7272727272727273] 

2024-03-19 08:19:31,914 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:19:31,915 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:19:31,915 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.3181818181818182, 0.5227272727272727, 0.7272727272727273], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:19:31,934 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 08:19:56,288 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:19:56,292 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:19:56,388 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3137254901960784, 0.8235294117647058, 0.9215686274509803] 

2024-03-19 08:19:56,388 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:19:56,388 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:19:56,388 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8784313725490196
evaluate on task refcoco, val, 3, res: {'refcoco': [0.3137254901960784, 0.8235294117647058, 0.9215686274509803], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:19:56,403 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 08:20:16,695 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:20:16,698 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 08:20:16,775 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2714285714285714, 0.8, 0.8857142857142857] 

2024-03-19 08:20:16,776 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:20:16,776 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:20:16,776 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9095238095238095
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2714285714285714, 0.8, 0.8857142857142857], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:20:16,791 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 08:20:46,313 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:20:46,317 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:20:46,444 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.22875816993464052, 0.7483660130718954, 0.8823529411764706] 

2024-03-19 08:20:46,444 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:20:46,445 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:20:46,445 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8954248366013072
evaluate on task refcoco, val, 5, res: {'refcoco': [0.22875816993464052, 0.7483660130718954, 0.8823529411764706], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:20:46,462 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 08:21:31,511 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:21:31,515 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:21:31,656 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.339662447257384, 0.9219409282700421, 0.9704641350210971] 

2024-03-19 08:21:31,657 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:21:31,657 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:21:31,657 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9430379746835443
evaluate on task refcoco, val, 6, res: {'refcoco': [0.339662447257384, 0.9219409282700421, 0.9704641350210971], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:21:31,705 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 08:21:32,726 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 08:21:34,087 maskrcnn_benchmark.trainer INFO: Total training time: 0:19:18.682889 (1.8539 s / it)
2024-03-19 08:21:34,116 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 08:21:34,116 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 08:21:34,116 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 08:21:34,116 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 08:21:34,116 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 08:21:34,116 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 08:21:34,116 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 08:21:34,116 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 08:21:34,116 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 08:21:34,117 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 08:21:34,117 maskrcnn_benchmark INFO: visual_prompt.7.dim_1 : Not Frozen, param number, 36
2024-03-19 08:21:34,117 maskrcnn_benchmark INFO: visual_prompt.7.dim_2 : Not Frozen, param number, 64
2024-03-19 08:21:34,117 maskrcnn_benchmark INFO: visual_prompt.7.dim_3 : Not Frozen, param number, 384
2024-03-19 08:21:34,118 maskrcnn_benchmark INFO: textual_prompt.7.dim_1 : Not Frozen, param number, 36
2024-03-19 08:21:34,118 maskrcnn_benchmark INFO: textual_prompt.7.dim_2 : Not Frozen, param number, 64
2024-03-19 08:21:34,118 maskrcnn_benchmark INFO: textual_prompt.7.dim_3 : Not Frozen, param number, 3072
2024-03-19 08:21:34,120 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 08:21:34,120 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=2.14s)
creating index...
index created!
2024-03-19 08:21:37,130 maskrcnn_benchmark INFO: Training on task 7: furniture, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 08:21:37,344 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.21s)
creating index...
index created!
2024-03-19 08:21:38,675 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 08:21:38,859 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 08:21:39,043 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.11s)
creating index...
index created!
2024-03-19 08:21:39,313 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
2024-03-19 08:21:39,540 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
2024-03-19 08:21:39,773 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
2024-03-19 08:21:39,995 maskrcnn_benchmark INFO: Testing on task 7: furniture, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
2024-03-19 08:21:40,330 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:41  iter: 20  loss: 2.1918 (1.8074)  loss_reg: 0.2769 (0.2327)  loss_centerness: 0.4822 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2146 (0.9194)  alignment_loss: 0.2096 (0.1775)  time: 1.3722 (1.4564)  data: 0.0145 (0.1406)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:14:12  iter: 40  loss: 2.0960 (1.8091)  loss_reg: 0.2708 (0.2329)  loss_centerness: 0.4843 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0784 (0.9206)  alignment_loss: 0.2084 (0.1777)  time: 1.3503 (1.4566)  data: 0.0132 (0.1408)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:42  iter: 60  loss: 1.9877 (1.8101)  loss_reg: 0.2615 (0.2332)  loss_centerness: 0.4806 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9937 (0.9212)  alignment_loss: 0.2068 (0.1779)  time: 1.3491 (1.4566)  data: 0.0132 (0.1408)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:13  iter: 80  loss: 1.9175 (1.8108)  loss_reg: 0.2855 (0.2334)  loss_centerness: 0.4822 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9189 (0.9214)  alignment_loss: 0.2050 (0.1780)  time: 1.3541 (1.4564)  data: 0.0131 (0.1407)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:44  iter: 100  loss: 1.8510 (1.8112)  loss_reg: 0.2616 (0.2336)  loss_centerness: 0.4818 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9009 (0.9214)  alignment_loss: 0.2030 (0.1782)  time: 1.3059 (1.4565)  data: 0.0131 (0.1408)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:15  iter: 120  loss: 1.8659 (1.8117)  loss_reg: 0.2818 (0.2339)  loss_centerness: 0.4830 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8969 (0.9215)  alignment_loss: 0.2008 (0.1783)  time: 1.3922 (1.4571)  data: 0.1149 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:46  iter: 140  loss: 1.8194 (1.8120)  loss_reg: 0.2620 (0.2341)  loss_centerness: 0.4801 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8982 (0.9215)  alignment_loss: 0.1983 (0.1784)  time: 1.3898 (1.4570)  data: 0.0137 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:17  iter: 160  loss: 1.8321 (1.8121)  loss_reg: 0.2654 (0.2343)  loss_centerness: 0.4838 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8793 (0.9213)  alignment_loss: 0.1956 (0.1785)  time: 1.3604 (1.4569)  data: 0.0145 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:48  iter: 180  loss: 1.8232 (1.8123)  loss_reg: 0.2927 (0.2346)  loss_centerness: 0.4821 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8864 (0.9211)  alignment_loss: 0.1927 (0.1786)  time: 1.3695 (1.4569)  data: 0.0181 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:19  iter: 200  loss: 1.7875 (1.8123)  loss_reg: 0.2679 (0.2348)  loss_centerness: 0.4806 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8361 (0.9208)  alignment_loss: 0.1898 (0.1787)  time: 1.3927 (1.4567)  data: 0.0147 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:50  iter: 220  loss: 1.7655 (1.8122)  loss_reg: 0.2553 (0.2349)  loss_centerness: 0.4795 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8725 (0.9205)  alignment_loss: 0.1868 (0.1787)  time: 1.3908 (1.4569)  data: 0.0146 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:20  iter: 240  loss: 1.8085 (1.8122)  loss_reg: 0.2871 (0.2352)  loss_centerness: 0.4823 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8687 (0.9201)  alignment_loss: 0.1839 (0.1788)  time: 1.3655 (1.4568)  data: 0.0146 (0.1409)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:51  iter: 260  loss: 1.7765 (1.8122)  loss_reg: 0.2752 (0.2355)  loss_centerness: 0.4831 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8378 (0.9198)  alignment_loss: 0.1811 (0.1788)  time: 1.3963 (1.4568)  data: 0.0127 (0.1408)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:22  iter: 280  loss: 1.8116 (1.8124)  loss_reg: 0.2738 (0.2358)  loss_centerness: 0.4839 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8912 (0.9197)  alignment_loss: 0.1784 (0.1788)  time: 1.3559 (1.4567)  data: 0.0142 (0.1408)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:53  iter: 300  loss: 1.7020 (1.8120)  loss_reg: 0.2638 (0.2359)  loss_centerness: 0.4835 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7425 (0.9191)  alignment_loss: 0.1759 (0.1787)  time: 1.3664 (1.4566)  data: 0.0176 (0.1407)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:24  iter: 320  loss: 1.7478 (1.8117)  loss_reg: 0.2713 (0.2361)  loss_centerness: 0.4842 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8197 (0.9186)  alignment_loss: 0.1736 (0.1787)  time: 1.3927 (1.4567)  data: 0.0126 (0.1406)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:55  iter: 340  loss: 1.7470 (1.8114)  loss_reg: 0.2618 (0.2363)  loss_centerness: 0.4813 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8180 (0.9181)  alignment_loss: 0.1714 (0.1787)  time: 1.3535 (1.4566)  data: 0.0164 (0.1406)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:25  iter: 360  loss: 1.7911 (1.8113)  loss_reg: 0.2902 (0.2366)  loss_centerness: 0.4826 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8503 (0.9178)  alignment_loss: 0.1695 (0.1786)  time: 1.3933 (1.4565)  data: 0.0215 (0.1405)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:56  iter: 380  loss: 1.7780 (1.8111)  loss_reg: 0.2553 (0.2368)  loss_centerness: 0.4809 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8357 (0.9174)  alignment_loss: 0.1677 (0.1786)  time: 1.3610 (1.4564)  data: 0.0128 (0.1404)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:27  iter: 400  loss: 1.8071 (1.8110)  loss_reg: 0.2884 (0.2371)  loss_centerness: 0.4854 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8588 (0.9171)  alignment_loss: 0.1660 (0.1785)  time: 1.3769 (1.4565)  data: 0.0124 (0.1406)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:58  iter: 420  loss: 1.7130 (1.8105)  loss_reg: 0.2705 (0.2373)  loss_centerness: 0.4798 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8026 (0.9165)  alignment_loss: 0.1645 (0.1784)  time: 1.3487 (1.4563)  data: 0.0161 (0.1405)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:29  iter: 440  loss: 1.7248 (1.8099)  loss_reg: 0.2499 (0.2374)  loss_centerness: 0.4794 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7991 (0.9159)  alignment_loss: 0.1631 (0.1784)  time: 1.3510 (1.4562)  data: 0.0124 (0.1404)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:00  iter: 460  loss: 1.7220 (1.8097)  loss_reg: 0.2731 (0.2376)  loss_centerness: 0.4812 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8124 (0.9155)  alignment_loss: 0.1618 (0.1783)  time: 1.3756 (1.4561)  data: 0.0167 (0.1403)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:31  iter: 480  loss: 1.7359 (1.8094)  loss_reg: 0.2667 (0.2379)  loss_centerness: 0.4835 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8184 (0.9149)  alignment_loss: 0.1607 (0.1782)  time: 1.3604 (1.4560)  data: 0.0140 (0.1403)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:02  iter: 500  loss: 1.7416 (1.8091)  loss_reg: 0.2770 (0.2381)  loss_centerness: 0.4833 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8448 (0.9145)  alignment_loss: 0.1597 (0.1781)  time: 1.3673 (1.4562)  data: 0.0125 (0.1404)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:32  iter: 520  loss: 1.6983 (1.8085)  loss_reg: 0.2697 (0.2382)  loss_centerness: 0.4820 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8037 (0.9139)  alignment_loss: 0.1588 (0.1780)  time: 1.3648 (1.4561)  data: 0.0125 (0.1403)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:03  iter: 540  loss: 1.7154 (1.8082)  loss_reg: 0.2665 (0.2384)  loss_centerness: 0.4799 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7991 (0.9135)  alignment_loss: 0.1580 (0.1779)  time: 1.4209 (1.4560)  data: 0.0134 (0.1402)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:34  iter: 560  loss: 1.7477 (1.8078)  loss_reg: 0.2744 (0.2386)  loss_centerness: 0.4830 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8051 (0.9129)  alignment_loss: 0.1572 (0.1778)  time: 1.3676 (1.4559)  data: 0.0164 (0.1402)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:05  iter: 580  loss: 1.7328 (1.8075)  loss_reg: 0.2831 (0.2389)  loss_centerness: 0.4823 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8198 (0.9125)  alignment_loss: 0.1566 (0.1777)  time: 1.3755 (1.4559)  data: 0.0133 (0.1402)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:36  iter: 600  loss: 1.6923 (1.8070)  loss_reg: 0.2572 (0.2389)  loss_centerness: 0.4813 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8043 (0.9120)  alignment_loss: 0.1559 (0.1775)  time: 1.3897 (1.4561)  data: 0.1098 (0.1404)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:07  iter: 620  loss: 1.7177 (1.8066)  loss_reg: 0.2774 (0.2392)  loss_centerness: 0.4839 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7976 (0.9115)  alignment_loss: 0.1553 (0.1774)  time: 1.3965 (1.4562)  data: 0.1167 (0.1405)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:00  iter: 625  loss: 1.7370 (1.8067)  loss_reg: 0.2787 (0.2392)  loss_centerness: 0.4839 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8046 (0.9115)  alignment_loss: 0.1552 (0.1774)  time: 1.3955 (1.4562)  data: 0.1168 (0.1405)  lr: 0.000000  wd: 0.000500  max mem: 12750
Evaluating
2024-03-19 08:38:38,655 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 08:38:46,879 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:38:46,884 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:38:46,921 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.4931506849315068, 0.6712328767123288] 

2024-03-19 08:38:46,922 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:38:46,922 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:38:46,922 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8493150684931506
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.4931506849315068, 0.6712328767123288], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:38:46,936 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 08:38:51,370 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:38:51,374 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 08:38:51,387 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2222222222222222, 0.8888888888888888, 1.0] 

2024-03-19 08:38:51,387 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:38:51,387 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:38:51,388 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2222222222222222, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:38:51,402 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 08:38:57,859 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:38:57,865 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:38:57,891 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2727272727272727, 0.5227272727272727, 0.75] 

2024-03-19 08:38:57,892 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:38:57,892 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:38:57,892 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.2727272727272727, 0.5227272727272727, 0.75], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:38:57,909 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 08:39:22,687 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:39:22,691 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:39:22,805 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2980392156862745, 0.803921568627451, 0.9098039215686274] 

2024-03-19 08:39:22,806 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:39:22,806 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:39:22,806 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8549019607843137
evaluate on task refcoco, val, 3, res: {'refcoco': [0.2980392156862745, 0.803921568627451, 0.9098039215686274], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:39:22,824 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 08:39:44,148 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:39:44,152 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 08:39:44,241 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2714285714285714, 0.8047619047619048, 0.8857142857142857] 

2024-03-19 08:39:44,242 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:39:44,242 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:39:44,242 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8809523809523809
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2714285714285714, 0.8047619047619048, 0.8857142857142857], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:39:44,259 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 08:40:14,166 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:40:14,174 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:40:14,314 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.23202614379084968, 0.7450980392156863, 0.8823529411764706] 

2024-03-19 08:40:14,314 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:40:14,315 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:40:14,315 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8954248366013072
evaluate on task refcoco, val, 5, res: {'refcoco': [0.23202614379084968, 0.7450980392156863, 0.8823529411764706], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:40:14,333 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 08:40:58,573 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:40:58,577 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:40:58,731 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3333333333333333, 0.919831223628692, 0.9725738396624473] 

2024-03-19 08:40:58,732 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:40:58,732 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:40:58,732 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9261603375527426
evaluate on task refcoco, val, 6, res: {'refcoco': [0.3333333333333333, 0.919831223628692, 0.9725738396624473], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:40:58,751 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 7
2024-03-19 08:41:45,627 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:41:45,632 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:41:45,888 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.31, 0.774, 0.876] 

2024-03-19 08:41:45,888 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:41:45,888 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:41:45,889 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.616
evaluate on task refcoco, val, 7, res: {'refcoco': [0.31, 0.774, 0.876], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:41:45,941 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 08:41:47,098 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 08:41:48,362 maskrcnn_benchmark.trainer INFO: Total training time: 0:20:08.014416 (1.9328 s / it)
2024-03-19 08:41:48,387 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 08:41:48,387 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 08:41:48,387 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 08:41:48,387 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 08:41:48,387 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 08:41:48,387 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 08:41:48,387 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 08:41:48,387 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 08:41:48,388 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 08:41:48,388 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 08:41:48,388 maskrcnn_benchmark INFO: visual_prompt.8.dim_1 : Not Frozen, param number, 36
2024-03-19 08:41:48,389 maskrcnn_benchmark INFO: visual_prompt.8.dim_2 : Not Frozen, param number, 64
2024-03-19 08:41:48,389 maskrcnn_benchmark INFO: visual_prompt.8.dim_3 : Not Frozen, param number, 384
2024-03-19 08:41:48,389 maskrcnn_benchmark INFO: textual_prompt.8.dim_1 : Not Frozen, param number, 36
2024-03-19 08:41:48,389 maskrcnn_benchmark INFO: textual_prompt.8.dim_2 : Not Frozen, param number, 64
2024-03-19 08:41:48,389 maskrcnn_benchmark INFO: textual_prompt.8.dim_3 : Not Frozen, param number, 3072
2024-03-19 08:41:48,391 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 08:41:48,391 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=2.19s)
creating index...
index created!
2024-03-19 08:41:51,476 maskrcnn_benchmark INFO: Training on task 8: vehicle, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 08:41:51,692 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 08:41:51,875 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 08:41:53,217 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 08:41:53,403 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 08:41:53,584 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 08:41:53,768 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 08:41:53,960 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 08:41:54,141 maskrcnn_benchmark INFO: Testing on task 7: furniture, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 08:41:54,320 maskrcnn_benchmark INFO: Testing on task 8: vehicle, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
2024-03-19 08:41:54,589 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:41  iter: 20  loss: 2.2005 (1.8086)  loss_reg: 0.2319 (0.2392)  loss_centerness: 0.4771 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2687 (0.9132)  alignment_loss: 0.2190 (0.1776)  time: 1.4144 (1.4566)  data: 0.1255 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:14:12  iter: 40  loss: 1.9958 (1.8093)  loss_reg: 0.2460 (0.2393)  loss_centerness: 0.4790 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0349 (0.9136)  alignment_loss: 0.2156 (0.1778)  time: 1.4604 (1.4565)  data: 0.1273 (0.1409)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:43  iter: 60  loss: 1.8976 (1.8098)  loss_reg: 0.2623 (0.2394)  loss_centerness: 0.4805 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9225 (0.9138)  alignment_loss: 0.2122 (0.1780)  time: 1.4653 (1.4568)  data: 0.1307 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:13:14  iter: 80  loss: 1.7624 (1.8096)  loss_reg: 0.2569 (0.2394)  loss_centerness: 0.4779 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8148 (0.9135)  alignment_loss: 0.2093 (0.1781)  time: 1.4866 (1.4570)  data: 0.1427 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:44  iter: 100  loss: 1.7658 (1.8094)  loss_reg: 0.2563 (0.2395)  loss_centerness: 0.4789 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8276 (0.9131)  alignment_loss: 0.2067 (0.1783)  time: 1.4623 (1.4570)  data: 0.1274 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:12:15  iter: 120  loss: 1.7477 (1.8090)  loss_reg: 0.2438 (0.2395)  loss_centerness: 0.4785 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8061 (0.9126)  alignment_loss: 0.2041 (0.1784)  time: 1.4677 (1.4571)  data: 0.1332 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:46  iter: 140  loss: 1.7412 (1.8088)  loss_reg: 0.2528 (0.2396)  loss_centerness: 0.4795 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8205 (0.9121)  alignment_loss: 0.2015 (0.1785)  time: 1.4221 (1.4570)  data: 0.1284 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:11:17  iter: 160  loss: 1.6450 (1.8081)  loss_reg: 0.2286 (0.2396)  loss_centerness: 0.4774 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7277 (0.9114)  alignment_loss: 0.1990 (0.1786)  time: 1.4641 (1.4572)  data: 0.1334 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:48  iter: 180  loss: 1.7079 (1.8077)  loss_reg: 0.2628 (0.2397)  loss_centerness: 0.4790 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7620 (0.9108)  alignment_loss: 0.1964 (0.1787)  time: 1.4625 (1.4573)  data: 0.1316 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:10:19  iter: 200  loss: 1.7318 (1.8074)  loss_reg: 0.2565 (0.2398)  loss_centerness: 0.4800 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.8091 (0.9103)  alignment_loss: 0.1937 (0.1788)  time: 1.4760 (1.4574)  data: 0.1327 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:50  iter: 220  loss: 1.6766 (1.8067)  loss_reg: 0.2365 (0.2398)  loss_centerness: 0.4773 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7679 (0.9095)  alignment_loss: 0.1911 (0.1788)  time: 1.4397 (1.4574)  data: 0.1296 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:09:21  iter: 240  loss: 1.6768 (1.8062)  loss_reg: 0.2428 (0.2398)  loss_centerness: 0.4771 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7804 (0.9090)  alignment_loss: 0.1884 (0.1789)  time: 1.4131 (1.4573)  data: 0.1267 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:52  iter: 260  loss: 1.6957 (1.8056)  loss_reg: 0.2578 (0.2399)  loss_centerness: 0.4821 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7837 (0.9083)  alignment_loss: 0.1858 (0.1789)  time: 1.4818 (1.4577)  data: 0.1340 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:08:22  iter: 280  loss: 1.6689 (1.8049)  loss_reg: 0.2518 (0.2399)  loss_centerness: 0.4784 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7308 (0.9075)  alignment_loss: 0.1833 (0.1789)  time: 1.4298 (1.4579)  data: 0.1237 (0.1413)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:53  iter: 300  loss: 1.6280 (1.8043)  loss_reg: 0.2408 (0.2400)  loss_centerness: 0.4773 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7513 (0.9069)  alignment_loss: 0.1807 (0.1789)  time: 1.3854 (1.4579)  data: 0.0163 (0.1413)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:07:24  iter: 320  loss: 1.6341 (1.8037)  loss_reg: 0.2509 (0.2400)  loss_centerness: 0.4802 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7453 (0.9062)  alignment_loss: 0.1782 (0.1789)  time: 1.3685 (1.4578)  data: 0.0185 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:55  iter: 340  loss: 1.6139 (1.8029)  loss_reg: 0.2358 (0.2400)  loss_centerness: 0.4773 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7313 (0.9054)  alignment_loss: 0.1758 (0.1789)  time: 1.3821 (1.4580)  data: 0.0167 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:06:26  iter: 360  loss: 1.7130 (1.8024)  loss_reg: 0.2562 (0.2401)  loss_centerness: 0.4785 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7883 (0.9048)  alignment_loss: 0.1734 (0.1789)  time: 1.3687 (1.4580)  data: 0.0184 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:57  iter: 380  loss: 1.6852 (1.8019)  loss_reg: 0.2420 (0.2402)  loss_centerness: 0.4810 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7493 (0.9042)  alignment_loss: 0.1710 (0.1789)  time: 1.3827 (1.4580)  data: 0.0201 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:05:28  iter: 400  loss: 1.6319 (1.8012)  loss_reg: 0.2464 (0.2402)  loss_centerness: 0.4792 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7384 (0.9036)  alignment_loss: 0.1687 (0.1788)  time: 1.4226 (1.4581)  data: 0.0276 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:58  iter: 420  loss: 1.6149 (1.8005)  loss_reg: 0.2414 (0.2403)  loss_centerness: 0.4790 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7336 (0.9029)  alignment_loss: 0.1664 (0.1788)  time: 1.3662 (1.4580)  data: 0.0393 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:29  iter: 440  loss: 1.6440 (1.7998)  loss_reg: 0.2492 (0.2403)  loss_centerness: 0.4790 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7454 (0.9022)  alignment_loss: 0.1642 (0.1787)  time: 1.3598 (1.4581)  data: 0.0140 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:04:00  iter: 460  loss: 1.6141 (1.7991)  loss_reg: 0.2381 (0.2404)  loss_centerness: 0.4765 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7348 (0.9015)  alignment_loss: 0.1619 (0.1786)  time: 1.3690 (1.4581)  data: 0.0140 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:31  iter: 480  loss: 1.6233 (1.7984)  loss_reg: 0.2418 (0.2404)  loss_centerness: 0.4798 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7216 (0.9009)  alignment_loss: 0.1597 (0.1785)  time: 1.3131 (1.4579)  data: 0.0157 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:03:02  iter: 500  loss: 1.6217 (1.7977)  loss_reg: 0.2487 (0.2404)  loss_centerness: 0.4791 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7150 (0.9002)  alignment_loss: 0.1575 (0.1784)  time: 1.3579 (1.4578)  data: 0.0177 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:33  iter: 520  loss: 1.6123 (1.7970)  loss_reg: 0.2515 (0.2405)  loss_centerness: 0.4781 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7042 (0.8996)  alignment_loss: 0.1553 (0.1783)  time: 1.3560 (1.4577)  data: 0.0167 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:02:03  iter: 540  loss: 1.5875 (1.7962)  loss_reg: 0.2452 (0.2405)  loss_centerness: 0.4790 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7112 (0.8988)  alignment_loss: 0.1531 (0.1782)  time: 1.3770 (1.4579)  data: 0.0151 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:34  iter: 560  loss: 1.6078 (1.7953)  loss_reg: 0.2329 (0.2405)  loss_centerness: 0.4773 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7463 (0.8981)  alignment_loss: 0.1510 (0.1781)  time: 1.3819 (1.4579)  data: 0.0191 (0.1409)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:01:05  iter: 580  loss: 1.6350 (1.7948)  loss_reg: 0.2560 (0.2406)  loss_centerness: 0.4784 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7664 (0.8976)  alignment_loss: 0.1488 (0.1780)  time: 1.4111 (1.4580)  data: 0.0157 (0.1409)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:36  iter: 600  loss: 1.5907 (1.7939)  loss_reg: 0.2453 (0.2406)  loss_centerness: 0.4793 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7127 (0.8968)  alignment_loss: 0.1467 (0.1778)  time: 1.3731 (1.4580)  data: 0.0162 (0.1409)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:07  iter: 620  loss: 1.5988 (1.7931)  loss_reg: 0.2371 (0.2406)  loss_centerness: 0.4778 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6965 (0.8961)  alignment_loss: 0.1446 (0.1777)  time: 1.3996 (1.4579)  data: 0.0186 (0.1408)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:00:00  iter: 625  loss: 1.6057 (1.7929)  loss_reg: 0.2371 (0.2407)  loss_centerness: 0.4776 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7118 (0.8960)  alignment_loss: 0.1439 (0.1776)  time: 1.3875 (1.4579)  data: 0.0192 (0.1408)  lr: 0.000000  wd: 0.000500  max mem: 12750
Evaluating
2024-03-19 08:59:01,607 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 08:59:09,924 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:59:09,927 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:59:09,958 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.5068493150684932, 0.6712328767123288] 

2024-03-19 08:59:09,959 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:59:09,959 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:59:09,959 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8493150684931506
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.5068493150684932, 0.6712328767123288], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:59:09,977 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 08:59:14,361 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:59:14,365 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 08:59:14,381 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2222222222222222, 0.8888888888888888, 1.0] 

2024-03-19 08:59:14,381 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:59:14,382 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:59:14,382 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2222222222222222, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:59:14,399 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 08:59:21,116 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:59:21,120 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:59:21,138 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2727272727272727, 0.5227272727272727, 0.7727272727272727] 

2024-03-19 08:59:21,138 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:59:21,138 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:59:21,138 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.2727272727272727, 0.5227272727272727, 0.7727272727272727], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:59:21,155 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 08:59:45,275 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 08:59:45,280 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 08:59:45,397 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2980392156862745, 0.803921568627451, 0.9176470588235294] 

2024-03-19 08:59:45,398 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 08:59:45,398 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 08:59:45,398 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8549019607843137
evaluate on task refcoco, val, 3, res: {'refcoco': [0.2980392156862745, 0.803921568627451, 0.9176470588235294], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 08:59:45,415 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 09:00:05,856 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:00:05,861 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 09:00:05,956 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2761904761904762, 0.8047619047619048, 0.8904761904761904] 

2024-03-19 09:00:05,956 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:00:05,956 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:00:05,956 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8809523809523809
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2761904761904762, 0.8047619047619048, 0.8904761904761904], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:00:05,974 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 09:00:34,772 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:00:34,776 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:00:34,904 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.22875816993464052, 0.7450980392156863, 0.8823529411764706] 

2024-03-19 09:00:34,904 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:00:34,905 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:00:34,905 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8954248366013072
evaluate on task refcoco, val, 5, res: {'refcoco': [0.22875816993464052, 0.7450980392156863, 0.8823529411764706], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:00:34,923 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 09:01:18,559 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:01:18,563 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:01:18,735 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3333333333333333, 0.919831223628692, 0.9725738396624473] 

2024-03-19 09:01:18,736 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:01:18,736 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:01:18,736 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9261603375527426
evaluate on task refcoco, val, 6, res: {'refcoco': [0.3333333333333333, 0.919831223628692, 0.9725738396624473], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:01:18,754 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 7
2024-03-19 09:02:04,389 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:02:04,393 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:02:04,598 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.31, 0.774, 0.872] 

2024-03-19 09:02:04,599 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:02:04,599 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:02:04,599 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.616
evaluate on task refcoco, val, 7, res: {'refcoco': [0.31, 0.774, 0.872], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:02:04,615 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 8
2024-03-19 09:02:51,553 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:02:51,558 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 09:02:51,771 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.392, 0.93, 0.968] 

2024-03-19 09:02:51,771 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:02:51,772 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:02:51,772 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.91
evaluate on task refcoco, val, 8, res: {'refcoco': [0.392, 0.93, 0.968], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:02:51,825 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 09:02:53,012 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 09:02:54,194 maskrcnn_benchmark.trainer INFO: Total training time: 0:20:59.590060 (2.0153 s / it)
2024-03-19 09:02:54,219 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 09:02:54,219 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 09:02:54,219 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 09:02:54,219 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 09:02:54,219 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 09:02:54,219 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 09:02:54,219 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 09:02:54,220 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 09:02:54,220 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 09:02:54,220 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 09:02:54,220 maskrcnn_benchmark INFO: visual_prompt.9.dim_1 : Not Frozen, param number, 36
2024-03-19 09:02:54,221 maskrcnn_benchmark INFO: visual_prompt.9.dim_2 : Not Frozen, param number, 64
2024-03-19 09:02:54,221 maskrcnn_benchmark INFO: visual_prompt.9.dim_3 : Not Frozen, param number, 384
2024-03-19 09:02:54,221 maskrcnn_benchmark INFO: textual_prompt.9.dim_1 : Not Frozen, param number, 36
2024-03-19 09:02:54,221 maskrcnn_benchmark INFO: textual_prompt.9.dim_2 : Not Frozen, param number, 64
2024-03-19 09:02:54,221 maskrcnn_benchmark INFO: textual_prompt.9.dim_3 : Not Frozen, param number, 3072
2024-03-19 09:02:54,223 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 09:02:54,223 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.50s)
creating index...
index created!
2024-03-19 09:02:56,607 maskrcnn_benchmark INFO: Training on task 9: food, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.07s)
creating index...
index created!
2024-03-19 09:02:57,831 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 09:02:58,021 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:02:58,205 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:02:58,384 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 09:02:58,567 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:02:58,747 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:02:58,933 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 09:02:59,123 maskrcnn_benchmark INFO: Testing on task 7: furniture, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.42s)
creating index...
index created!
2024-03-19 09:03:00,668 maskrcnn_benchmark INFO: Testing on task 8: vehicle, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 09:03:00,859 maskrcnn_benchmark INFO: Testing on task 9: food, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
2024-03-19 09:03:01,199 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:42  iter: 20  loss: 2.2706 (1.7951)  loss_reg: 0.2293 (0.2406)  loss_centerness: 0.4738 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3263 (0.8980)  alignment_loss: 0.2452 (0.1779)  time: 1.3087 (1.4582)  data: 0.0116 (0.1412)  lr: 0.010000  wd: 0.000500  max mem: 12750
eta: 0:14:12  iter: 40  loss: 2.1918 (1.7970)  loss_reg: 0.2384 (0.2406)  loss_centerness: 0.4750 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2886 (0.8996)  alignment_loss: 0.2312 (0.1782)  time: 1.3369 (1.4581)  data: 0.0133 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12751
eta: 0:13:43  iter: 60  loss: 2.0863 (1.7983)  loss_reg: 0.2343 (0.2406)  loss_centerness: 0.4761 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1472 (0.9008)  alignment_loss: 0.2214 (0.1784)  time: 1.3522 (1.4580)  data: 0.0130 (0.1411)  lr: 0.010000  wd: 0.000500  max mem: 12751
eta: 0:13:14  iter: 80  loss: 2.0157 (1.7991)  loss_reg: 0.2327 (0.2405)  loss_centerness: 0.4742 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0880 (0.9016)  alignment_loss: 0.2149 (0.1785)  time: 1.3298 (1.4579)  data: 0.0127 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12751
eta: 0:12:45  iter: 100  loss: 1.9698 (1.8001)  loss_reg: 0.2306 (0.2405)  loss_centerness: 0.4740 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0592 (0.9024)  alignment_loss: 0.2102 (0.1786)  time: 1.3634 (1.4580)  data: 0.0131 (0.1410)  lr: 0.010000  wd: 0.000500  max mem: 12751
eta: 0:12:16  iter: 120  loss: 2.0418 (1.8009)  loss_reg: 0.2368 (0.2405)  loss_centerness: 0.4758 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1137 (0.9032)  alignment_loss: 0.2062 (0.1788)  time: 1.3230 (1.4579)  data: 0.0117 (0.1409)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:11:47  iter: 140  loss: 1.9437 (1.8016)  loss_reg: 0.2307 (0.2405)  loss_centerness: 0.4754 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0344 (0.9037)  alignment_loss: 0.2026 (0.1789)  time: 1.3085 (1.4578)  data: 0.0123 (0.1408)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:11:17  iter: 160  loss: 1.9400 (1.8021)  loss_reg: 0.2112 (0.2404)  loss_centerness: 0.4749 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9700 (0.9042)  alignment_loss: 0.1992 (0.1789)  time: 1.3083 (1.4578)  data: 0.0117 (0.1408)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:10:48  iter: 180  loss: 1.9262 (1.8028)  loss_reg: 0.2399 (0.2404)  loss_centerness: 0.4748 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0413 (0.9049)  alignment_loss: 0.1960 (0.1790)  time: 1.3069 (1.4577)  data: 0.0130 (0.1407)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:10:19  iter: 200  loss: 1.8755 (1.8032)  loss_reg: 0.2102 (0.2403)  loss_centerness: 0.4746 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9783 (0.9053)  alignment_loss: 0.1927 (0.1791)  time: 1.3518 (1.4576)  data: 0.0128 (0.1406)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:09:50  iter: 220  loss: 1.8571 (1.8035)  loss_reg: 0.2354 (0.2403)  loss_centerness: 0.4747 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9627 (0.9057)  alignment_loss: 0.1894 (0.1791)  time: 1.3526 (1.4575)  data: 0.0131 (0.1406)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:09:21  iter: 240  loss: 1.9392 (1.8041)  loss_reg: 0.2282 (0.2403)  loss_centerness: 0.4756 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0201 (0.9062)  alignment_loss: 0.1860 (0.1791)  time: 1.3442 (1.4575)  data: 0.0132 (0.1406)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:08:51  iter: 260  loss: 1.8591 (1.8044)  loss_reg: 0.2187 (0.2402)  loss_centerness: 0.4752 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9736 (0.9066)  alignment_loss: 0.1825 (0.1792)  time: 1.2972 (1.4574)  data: 0.0117 (0.1405)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:08:22  iter: 280  loss: 1.8742 (1.8046)  loss_reg: 0.2327 (0.2402)  loss_centerness: 0.4734 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9884 (0.9068)  alignment_loss: 0.1789 (0.1792)  time: 1.3310 (1.4574)  data: 0.0129 (0.1405)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:07:53  iter: 300  loss: 1.8691 (1.8048)  loss_reg: 0.2204 (0.2401)  loss_centerness: 0.4754 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9945 (0.9071)  alignment_loss: 0.1752 (0.1791)  time: 1.3502 (1.4573)  data: 0.0116 (0.1404)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:07:24  iter: 320  loss: 1.8996 (1.8051)  loss_reg: 0.2312 (0.2401)  loss_centerness: 0.4753 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0013 (0.9075)  alignment_loss: 0.1714 (0.1791)  time: 1.3067 (1.4572)  data: 0.0115 (0.1404)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:06:55  iter: 340  loss: 1.8677 (1.8055)  loss_reg: 0.2320 (0.2401)  loss_centerness: 0.4773 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0302 (0.9079)  alignment_loss: 0.1675 (0.1791)  time: 1.3006 (1.4570)  data: 0.0114 (0.1403)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:06:26  iter: 360  loss: 1.8629 (1.8056)  loss_reg: 0.2261 (0.2400)  loss_centerness: 0.4718 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0026 (0.9082)  alignment_loss: 0.1635 (0.1790)  time: 1.3087 (1.4571)  data: 0.0115 (0.1404)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:05:56  iter: 380  loss: 1.8415 (1.8058)  loss_reg: 0.2416 (0.2400)  loss_centerness: 0.4762 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9736 (0.9085)  alignment_loss: 0.1595 (0.1789)  time: 1.3549 (1.4571)  data: 0.0131 (0.1404)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:05:27  iter: 400  loss: 1.8129 (1.8061)  loss_reg: 0.2240 (0.2400)  loss_centerness: 0.4736 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9472 (0.9089)  alignment_loss: 0.1554 (0.1788)  time: 1.2950 (1.4569)  data: 0.0120 (0.1403)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:04:58  iter: 420  loss: 1.8552 (1.8061)  loss_reg: 0.2298 (0.2400)  loss_centerness: 0.4738 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9802 (0.9091)  alignment_loss: 0.1513 (0.1787)  time: 1.2991 (1.4568)  data: 0.0119 (0.1403)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:04:29  iter: 440  loss: 1.8593 (1.8063)  loss_reg: 0.2147 (0.2399)  loss_centerness: 0.4748 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9703 (0.9095)  alignment_loss: 0.1472 (0.1786)  time: 1.3038 (1.4567)  data: 0.0117 (0.1402)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:04:00  iter: 460  loss: 1.7795 (1.8063)  loss_reg: 0.2193 (0.2399)  loss_centerness: 0.4759 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9258 (0.9096)  alignment_loss: 0.1432 (0.1785)  time: 1.3395 (1.4567)  data: 0.0129 (0.1401)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:03:31  iter: 480  loss: 1.8393 (1.8064)  loss_reg: 0.2279 (0.2398)  loss_centerness: 0.4747 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9883 (0.9100)  alignment_loss: 0.1391 (0.1783)  time: 1.3569 (1.4566)  data: 0.0131 (0.1401)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:03:02  iter: 500  loss: 1.7800 (1.8064)  loss_reg: 0.2285 (0.2398)  loss_centerness: 0.4759 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9308 (0.9102)  alignment_loss: 0.1352 (0.1781)  time: 1.3510 (1.4566)  data: 0.0132 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:02:32  iter: 520  loss: 1.7761 (1.8064)  loss_reg: 0.2199 (0.2398)  loss_centerness: 0.4745 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9357 (0.9104)  alignment_loss: 0.1313 (0.1779)  time: 1.3091 (1.4564)  data: 0.0116 (0.1399)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:02:03  iter: 540  loss: 1.7451 (1.8061)  loss_reg: 0.2234 (0.2397)  loss_centerness: 0.4756 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9278 (0.9104)  alignment_loss: 0.1274 (0.1778)  time: 1.3586 (1.4565)  data: 0.0133 (0.1399)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:01:34  iter: 560  loss: 1.8362 (1.8064)  loss_reg: 0.2392 (0.2397)  loss_centerness: 0.4772 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9922 (0.9109)  alignment_loss: 0.1235 (0.1775)  time: 1.3665 (1.4567)  data: 0.0133 (0.1399)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:01:05  iter: 580  loss: 1.7992 (1.8064)  loss_reg: 0.2318 (0.2397)  loss_centerness: 0.4746 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9612 (0.9111)  alignment_loss: 0.1197 (0.1773)  time: 1.2986 (1.4565)  data: 0.0117 (0.1398)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:00:36  iter: 600  loss: 1.7731 (1.8065)  loss_reg: 0.2318 (0.2397)  loss_centerness: 0.4747 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9661 (0.9115)  alignment_loss: 0.1159 (0.1771)  time: 1.3521 (1.4565)  data: 0.0131 (0.1398)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:00:07  iter: 620  loss: 1.7136 (1.8063)  loss_reg: 0.2259 (0.2396)  loss_centerness: 0.4736 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9223 (0.9116)  alignment_loss: 0.1120 (0.1768)  time: 1.3172 (1.4564)  data: 0.0115 (0.1397)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:00:00  iter: 625  loss: 1.6851 (1.8062)  loss_reg: 0.2259 (0.2396)  loss_centerness: 0.4736 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9080 (0.9116)  alignment_loss: 0.1109 (0.1768)  time: 1.3227 (1.4564)  data: 0.0125 (0.1397)  lr: 0.000000  wd: 0.000500  max mem: 12753
Evaluating
2024-03-19 09:19:56,672 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 09:20:05,369 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:20:05,373 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:20:05,418 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.5068493150684932, 0.6712328767123288] 

2024-03-19 09:20:05,419 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:20:05,419 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:20:05,419 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8493150684931506
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.5068493150684932, 0.6712328767123288], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:20:05,437 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 09:20:10,102 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:20:10,106 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 09:20:10,119 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2222222222222222, 0.8888888888888888, 1.0] 

2024-03-19 09:20:10,120 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:20:10,120 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:20:10,120 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2222222222222222, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:20:10,136 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 09:20:16,855 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:20:16,860 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:20:16,879 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2727272727272727, 0.5227272727272727, 0.7727272727272727] 

2024-03-19 09:20:16,880 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:20:16,880 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:20:16,880 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.2727272727272727, 0.5227272727272727, 0.7727272727272727], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:20:16,906 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 09:20:42,566 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:20:42,570 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:20:42,683 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.29411764705882354, 0.803921568627451, 0.9176470588235294] 

2024-03-19 09:20:42,684 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:20:42,684 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:20:42,684 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8549019607843137
evaluate on task refcoco, val, 3, res: {'refcoco': [0.29411764705882354, 0.803921568627451, 0.9176470588235294], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:20:42,703 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 09:21:04,452 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:21:04,457 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 09:21:04,554 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2761904761904762, 0.8095238095238095, 0.8952380952380953] 

2024-03-19 09:21:04,554 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:21:04,554 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:21:04,554 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8809523809523809
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2761904761904762, 0.8095238095238095, 0.8952380952380953], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:21:04,573 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 09:21:35,713 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:21:35,717 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:21:35,856 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.22875816993464052, 0.7483660130718954, 0.8856209150326797] 

2024-03-19 09:21:35,856 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:21:35,856 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:21:35,856 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8790849673202614
evaluate on task refcoco, val, 5, res: {'refcoco': [0.22875816993464052, 0.7483660130718954, 0.8856209150326797], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:21:35,875 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 09:22:20,757 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:22:20,761 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:22:20,935 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3037974683544304, 0.879746835443038, 0.9451476793248945] 

2024-03-19 09:22:20,935 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:22:20,936 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:22:20,936 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8354430379746836
evaluate on task refcoco, val, 6, res: {'refcoco': [0.3037974683544304, 0.879746835443038, 0.9451476793248945], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:22:20,956 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 7
2024-03-19 09:23:08,802 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:23:08,806 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:23:09,051 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.296, 0.776, 0.866] 

2024-03-19 09:23:09,052 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:23:09,052 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:23:09,052 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.594
evaluate on task refcoco, val, 7, res: {'refcoco': [0.296, 0.776, 0.866], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:23:09,071 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 8
2024-03-19 09:23:56,527 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:23:56,531 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 09:23:56,747 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.396, 0.93, 0.97] 

2024-03-19 09:23:56,748 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:23:56,748 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:23:56,748 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.91
evaluate on task refcoco, val, 8, res: {'refcoco': [0.396, 0.93, 0.97], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:23:56,767 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 9
2024-03-19 09:24:44,624 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:24:44,628 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.30000001192092896), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.30000001192092896), ('AR@1000', 0.30000001192092896), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.30000001192092896)]))])
2024-03-19 09:24:44,789 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.226, 0.608, 0.774] 

2024-03-19 09:24:44,790 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:24:44,790 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:24:44,790 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.734
evaluate on task refcoco, val, 9, res: {'refcoco': [0.226, 0.608, 0.774], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:24:44,839 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 09:24:45,914 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 09:24:47,123 maskrcnn_benchmark.trainer INFO: Total training time: 0:21:45.908146 (2.0895 s / it)
2024-03-19 09:24:47,148 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 09:24:47,148 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 09:24:47,148 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 09:24:47,148 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 09:24:47,148 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 09:24:47,148 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 09:24:47,151 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 09:24:47,151 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 09:24:47,151 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 09:24:47,151 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 09:24:47,152 maskrcnn_benchmark INFO: visual_prompt.10.dim_1 : Not Frozen, param number, 36
2024-03-19 09:24:47,152 maskrcnn_benchmark INFO: visual_prompt.10.dim_2 : Not Frozen, param number, 64
2024-03-19 09:24:47,152 maskrcnn_benchmark INFO: visual_prompt.10.dim_3 : Not Frozen, param number, 384
2024-03-19 09:24:47,152 maskrcnn_benchmark INFO: textual_prompt.10.dim_1 : Not Frozen, param number, 36
2024-03-19 09:24:47,152 maskrcnn_benchmark INFO: textual_prompt.10.dim_2 : Not Frozen, param number, 64
2024-03-19 09:24:47,152 maskrcnn_benchmark INFO: textual_prompt.10.dim_3 : Not Frozen, param number, 3072
2024-03-19 09:24:47,155 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 09:24:47,155 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=2.45s)
creating index...
index created!
2024-03-19 09:24:50,471 maskrcnn_benchmark INFO: Training on task 10: animal, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 09:24:50,684 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:24:50,869 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:24:52,232 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:24:52,421 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:24:52,607 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 09:24:52,794 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 09:24:52,984 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 09:24:53,180 maskrcnn_benchmark INFO: Testing on task 7: furniture, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 09:24:53,370 maskrcnn_benchmark INFO: Testing on task 8: vehicle, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 09:24:53,558 maskrcnn_benchmark INFO: Testing on task 9: food, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 09:24:53,747 maskrcnn_benchmark INFO: Testing on task 10: animal, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
2024-03-19 09:24:54,141 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:41  iter: 20  loss: 2.0986 (1.8074)  loss_reg: 0.1999 (0.2395)  loss_centerness: 0.4746 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1644 (0.9127)  alignment_loss: 0.2355 (0.1770)  time: 1.3570 (1.4567)  data: 0.0133 (0.1401)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:14:12  iter: 40  loss: 1.7986 (1.8075)  loss_reg: 0.1816 (0.2393)  loss_centerness: 0.4755 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9020 (0.9128)  alignment_loss: 0.2293 (0.1772)  time: 1.3388 (1.4568)  data: 0.0132 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:13:43  iter: 60  loss: 1.6914 (1.8071)  loss_reg: 0.1819 (0.2391)  loss_centerness: 0.4752 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7753 (0.9124)  alignment_loss: 0.2248 (0.1774)  time: 1.3540 (1.4567)  data: 0.0156 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:13:13  iter: 80  loss: 1.6421 (1.8065)  loss_reg: 0.1931 (0.2389)  loss_centerness: 0.4742 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7414 (0.9119)  alignment_loss: 0.2216 (0.1775)  time: 1.3825 (1.4566)  data: 0.0156 (0.1399)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:12:44  iter: 100  loss: 1.5963 (1.8058)  loss_reg: 0.1877 (0.2388)  loss_centerness: 0.4738 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7215 (0.9111)  alignment_loss: 0.2193 (0.1777)  time: 1.3759 (1.4564)  data: 0.0162 (0.1399)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:12:15  iter: 120  loss: 1.5960 (1.8051)  loss_reg: 0.1814 (0.2386)  loss_centerness: 0.4732 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7172 (0.9105)  alignment_loss: 0.2173 (0.1778)  time: 1.3787 (1.4565)  data: 0.0220 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:11:46  iter: 140  loss: 1.5704 (1.8042)  loss_reg: 0.1863 (0.2384)  loss_centerness: 0.4736 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6904 (0.9097)  alignment_loss: 0.2155 (0.1780)  time: 1.3599 (1.4568)  data: 0.0132 (0.1402)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:11:17  iter: 160  loss: 1.6214 (1.8034)  loss_reg: 0.1974 (0.2383)  loss_centerness: 0.4743 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7005 (0.9089)  alignment_loss: 0.2139 (0.1781)  time: 1.3355 (1.4568)  data: 0.0123 (0.1401)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:10:48  iter: 180  loss: 1.5816 (1.8027)  loss_reg: 0.1992 (0.2382)  loss_centerness: 0.4727 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7047 (0.9081)  alignment_loss: 0.2124 (0.1782)  time: 1.3590 (1.4568)  data: 0.0139 (0.1401)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:10:19  iter: 200  loss: 1.5535 (1.8018)  loss_reg: 0.1895 (0.2380)  loss_centerness: 0.4736 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6658 (0.9073)  alignment_loss: 0.2109 (0.1784)  time: 1.3588 (1.4567)  data: 0.0134 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:09:49  iter: 220  loss: 1.5526 (1.8009)  loss_reg: 0.2010 (0.2379)  loss_centerness: 0.4745 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6763 (0.9065)  alignment_loss: 0.2095 (0.1785)  time: 1.3579 (1.4567)  data: 0.0129 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:09:20  iter: 240  loss: 1.5192 (1.8000)  loss_reg: 0.1982 (0.2377)  loss_centerness: 0.4756 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6408 (0.9056)  alignment_loss: 0.2080 (0.1786)  time: 1.3547 (1.4568)  data: 0.0132 (0.1401)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:08:51  iter: 260  loss: 1.5174 (1.7991)  loss_reg: 0.1909 (0.2376)  loss_centerness: 0.4726 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6241 (0.9047)  alignment_loss: 0.2065 (0.1787)  time: 1.3138 (1.4568)  data: 0.0122 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:08:22  iter: 280  loss: 1.5386 (1.7981)  loss_reg: 0.1849 (0.2374)  loss_centerness: 0.4726 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6654 (0.9038)  alignment_loss: 0.2050 (0.1788)  time: 1.3611 (1.4568)  data: 0.0130 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:07:53  iter: 300  loss: 1.5266 (1.7972)  loss_reg: 0.1892 (0.2372)  loss_centerness: 0.4748 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6696 (0.9031)  alignment_loss: 0.2035 (0.1789)  time: 1.3169 (1.4567)  data: 0.0119 (0.1399)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:07:24  iter: 320  loss: 1.5002 (1.7963)  loss_reg: 0.1972 (0.2371)  loss_centerness: 0.4732 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6539 (0.9022)  alignment_loss: 0.2019 (0.1790)  time: 1.3586 (1.4567)  data: 0.0132 (0.1399)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:06:55  iter: 340  loss: 1.5129 (1.7954)  loss_reg: 0.1883 (0.2370)  loss_centerness: 0.4719 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6588 (0.9014)  alignment_loss: 0.2003 (0.1790)  time: 1.3648 (1.4569)  data: 0.0133 (0.1399)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:06:26  iter: 360  loss: 1.5090 (1.7945)  loss_reg: 0.1925 (0.2368)  loss_centerness: 0.4767 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6210 (0.9006)  alignment_loss: 0.1986 (0.1791)  time: 1.3683 (1.4568)  data: 0.0135 (0.1398)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:05:56  iter: 380  loss: 1.5308 (1.7936)  loss_reg: 0.1869 (0.2367)  loss_centerness: 0.4734 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6634 (0.8998)  alignment_loss: 0.1967 (0.1792)  time: 1.3047 (1.4567)  data: 0.0118 (0.1398)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:05:27  iter: 400  loss: 1.4821 (1.7926)  loss_reg: 0.1789 (0.2365)  loss_centerness: 0.4716 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6496 (0.8989)  alignment_loss: 0.1948 (0.1792)  time: 1.3042 (1.4566)  data: 0.0117 (0.1397)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:04:58  iter: 420  loss: 1.5199 (1.7916)  loss_reg: 0.1997 (0.2364)  loss_centerness: 0.4726 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6319 (0.8980)  alignment_loss: 0.1928 (0.1793)  time: 1.3077 (1.4565)  data: 0.0117 (0.1397)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:04:29  iter: 440  loss: 1.5301 (1.7908)  loss_reg: 0.2037 (0.2363)  loss_centerness: 0.4744 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6622 (0.8972)  alignment_loss: 0.1907 (0.1793)  time: 1.3408 (1.4565)  data: 0.0130 (0.1396)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:04:00  iter: 460  loss: 1.4706 (1.7897)  loss_reg: 0.1812 (0.2361)  loss_centerness: 0.4719 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6241 (0.8964)  alignment_loss: 0.1884 (0.1793)  time: 1.3167 (1.4566)  data: 0.0127 (0.1398)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:03:31  iter: 480  loss: 1.4826 (1.7887)  loss_reg: 0.1914 (0.2359)  loss_centerness: 0.4745 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6290 (0.8955)  alignment_loss: 0.1860 (0.1794)  time: 1.3614 (1.4566)  data: 0.0137 (0.1397)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:03:02  iter: 500  loss: 1.5098 (1.7879)  loss_reg: 0.2024 (0.2359)  loss_centerness: 0.4776 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6485 (0.8947)  alignment_loss: 0.1836 (0.1794)  time: 1.3580 (1.4566)  data: 0.0132 (0.1397)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:02:32  iter: 520  loss: 1.4621 (1.7868)  loss_reg: 0.1809 (0.2357)  loss_centerness: 0.4721 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6242 (0.8938)  alignment_loss: 0.1809 (0.1794)  time: 1.3163 (1.4566)  data: 0.0128 (0.1397)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:02:03  iter: 540  loss: 1.5112 (1.7858)  loss_reg: 0.2056 (0.2356)  loss_centerness: 0.4737 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6473 (0.8930)  alignment_loss: 0.1781 (0.1794)  time: 1.3266 (1.4565)  data: 0.0134 (0.1396)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:01:34  iter: 560  loss: 1.5285 (1.7850)  loss_reg: 0.2069 (0.2354)  loss_centerness: 0.4742 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6669 (0.8923)  alignment_loss: 0.1753 (0.1794)  time: 1.3632 (1.4567)  data: 0.0134 (0.1398)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:01:05  iter: 580  loss: 1.4758 (1.7839)  loss_reg: 0.2042 (0.2353)  loss_centerness: 0.4756 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6264 (0.8914)  alignment_loss: 0.1723 (0.1793)  time: 1.3299 (1.4567)  data: 0.0123 (0.1397)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:00:36  iter: 600  loss: 1.5332 (1.7830)  loss_reg: 0.2069 (0.2352)  loss_centerness: 0.4748 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6599 (0.8906)  alignment_loss: 0.1693 (0.1793)  time: 1.3043 (1.4566)  data: 0.0119 (0.1397)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:00:07  iter: 620  loss: 1.4635 (1.7819)  loss_reg: 0.1891 (0.2351)  loss_centerness: 0.4724 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6344 (0.8898)  alignment_loss: 0.1663 (0.1793)  time: 1.3194 (1.4565)  data: 0.0123 (0.1397)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:00:00  iter: 625  loss: 1.4635 (1.7817)  loss_reg: 0.1891 (0.2350)  loss_centerness: 0.4725 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6344 (0.8896)  alignment_loss: 0.1653 (0.1793)  time: 1.3133 (1.4565)  data: 0.0123 (0.1396)  lr: 0.000000  wd: 0.000500  max mem: 12753
Evaluating
2024-03-19 09:41:50,832 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 09:42:00,389 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:42:00,392 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:42:00,426 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.5205479452054794, 0.6712328767123288] 

2024-03-19 09:42:00,426 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:42:00,426 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:42:00,426 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8493150684931506
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.5205479452054794, 0.6712328767123288], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:42:00,442 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 09:42:05,161 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:42:05,165 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 09:42:05,179 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2222222222222222, 0.8888888888888888, 1.0] 

2024-03-19 09:42:05,179 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:42:05,179 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:42:05,179 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2222222222222222, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:42:05,198 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 09:42:11,165 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:42:11,169 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:42:11,186 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2727272727272727, 0.5227272727272727, 0.75] 

2024-03-19 09:42:11,186 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:42:11,187 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:42:11,187 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.2727272727272727, 0.5227272727272727, 0.75], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:42:11,203 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 09:42:36,360 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:42:36,364 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:42:36,464 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2980392156862745, 0.807843137254902, 0.9176470588235294] 

2024-03-19 09:42:36,464 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:42:36,464 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:42:36,464 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8549019607843137
evaluate on task refcoco, val, 3, res: {'refcoco': [0.2980392156862745, 0.807843137254902, 0.9176470588235294], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:42:36,481 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 09:42:58,102 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:42:58,106 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 09:42:58,183 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2571428571428571, 0.8047619047619048, 0.8952380952380953] 

2024-03-19 09:42:58,184 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:42:58,184 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:42:58,184 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8523809523809524
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2571428571428571, 0.8047619047619048, 0.8952380952380953], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:42:58,201 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 09:43:28,844 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:43:28,848 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:43:28,960 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.22549019607843138, 0.761437908496732, 0.8823529411764706] 

2024-03-19 09:43:28,961 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:43:28,961 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:43:28,961 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8790849673202614
evaluate on task refcoco, val, 5, res: {'refcoco': [0.22549019607843138, 0.761437908496732, 0.8823529411764706], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:43:28,977 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 09:44:14,844 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:44:14,848 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:44:14,998 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3037974683544304, 0.879746835443038, 0.9451476793248945] 

2024-03-19 09:44:14,998 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:44:14,998 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:44:14,999 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8354430379746836
evaluate on task refcoco, val, 6, res: {'refcoco': [0.3037974683544304, 0.879746835443038, 0.9451476793248945], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:44:15,018 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 7
2024-03-19 09:45:03,654 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:45:03,658 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:45:03,910 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.278, 0.776, 0.864] 

2024-03-19 09:45:03,910 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:45:03,910 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:45:03,910 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.544
evaluate on task refcoco, val, 7, res: {'refcoco': [0.278, 0.776, 0.864], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:45:03,930 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 8
2024-03-19 09:45:51,871 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:45:51,875 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 09:45:52,090 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.388, 0.924, 0.97] 

2024-03-19 09:45:52,091 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:45:52,091 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:45:52,091 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9
evaluate on task refcoco, val, 8, res: {'refcoco': [0.388, 0.924, 0.97], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:45:52,111 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 9
2024-03-19 09:46:39,930 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:46:39,933 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.30000001192092896), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.30000001192092896), ('AR@1000', 0.30000001192092896), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.30000001192092896)]))])
2024-03-19 09:46:40,094 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.226, 0.608, 0.778] 

2024-03-19 09:46:40,094 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:46:40,095 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:46:40,095 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.734
evaluate on task refcoco, val, 9, res: {'refcoco': [0.226, 0.608, 0.778], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:46:40,112 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 10
2024-03-19 09:47:27,983 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 09:47:27,986 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 09:47:28,129 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.382, 0.946, 0.98] 

2024-03-19 09:47:28,129 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 09:47:28,129 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 09:47:28,129 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.872
evaluate on task refcoco, val, 10, res: {'refcoco': [0.382, 0.946, 0.98], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 09:47:28,176 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 09:47:29,229 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 09:47:30,459 maskrcnn_benchmark.trainer INFO: Total training time: 0:22:36.302664 (2.1701 s / it)
2024-03-19 09:47:30,484 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 09:47:30,484 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 09:47:30,484 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 09:47:30,484 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 09:47:30,484 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 09:47:30,484 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 09:47:30,484 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 09:47:30,484 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 09:47:30,484 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 09:47:30,484 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 09:47:30,485 maskrcnn_benchmark INFO: visual_prompt.11.dim_1 : Not Frozen, param number, 36
2024-03-19 09:47:30,485 maskrcnn_benchmark INFO: visual_prompt.11.dim_2 : Not Frozen, param number, 64
2024-03-19 09:47:30,485 maskrcnn_benchmark INFO: visual_prompt.11.dim_3 : Not Frozen, param number, 384
2024-03-19 09:47:30,485 maskrcnn_benchmark INFO: textual_prompt.11.dim_1 : Not Frozen, param number, 36
2024-03-19 09:47:30,485 maskrcnn_benchmark INFO: textual_prompt.11.dim_2 : Not Frozen, param number, 64
2024-03-19 09:47:30,485 maskrcnn_benchmark INFO: textual_prompt.11.dim_3 : Not Frozen, param number, 3072
2024-03-19 09:47:30,488 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 09:47:30,488 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=2.42s)
creating index...
index created!
2024-03-19 09:47:33,785 maskrcnn_benchmark INFO: Training on task 11: person, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 09:47:33,999 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:47:34,185 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:47:34,369 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.40s)
creating index...
index created!
2024-03-19 09:47:35,896 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:47:36,080 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:47:36,261 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:47:36,445 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:47:36,628 maskrcnn_benchmark INFO: Testing on task 7: furniture, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:47:36,810 maskrcnn_benchmark INFO: Testing on task 8: vehicle, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:47:36,994 maskrcnn_benchmark INFO: Testing on task 9: food, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:47:37,178 maskrcnn_benchmark INFO: Testing on task 10: animal, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 09:47:37,359 maskrcnn_benchmark INFO: Testing on task 11: person, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
2024-03-19 09:47:37,693 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:14:41  iter: 20  loss: 1.8627 (1.7821)  loss_reg: 0.1941 (0.2349)  loss_centerness: 0.4746 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9735 (0.8900)  alignment_loss: 0.2180 (0.1794)  time: 1.4279 (1.4569)  data: 0.1324 (0.1399)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:14:12  iter: 40  loss: 1.6418 (1.7817)  loss_reg: 0.1853 (0.2347)  loss_centerness: 0.4742 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.7816 (0.8897)  alignment_loss: 0.1878 (0.1794)  time: 1.4165 (1.4570)  data: 0.1277 (0.1401)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:13:43  iter: 60  loss: 1.5303 (1.7809)  loss_reg: 0.1825 (0.2346)  loss_centerness: 0.4756 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6935 (0.8891)  alignment_loss: 0.1756 (0.1794)  time: 1.4462 (1.4570)  data: 0.1233 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:13:14  iter: 80  loss: 1.4989 (1.7800)  loss_reg: 0.1685 (0.2343)  loss_centerness: 0.4736 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6868 (0.8885)  alignment_loss: 0.1692 (0.1794)  time: 1.4783 (1.4570)  data: 0.1382 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:12:44  iter: 100  loss: 1.5069 (1.7791)  loss_reg: 0.1978 (0.2342)  loss_centerness: 0.4748 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6603 (0.8878)  alignment_loss: 0.1640 (0.1793)  time: 1.4272 (1.4570)  data: 0.1217 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:12:15  iter: 120  loss: 1.4736 (1.7781)  loss_reg: 0.1919 (0.2341)  loss_centerness: 0.4745 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6406 (0.8870)  alignment_loss: 0.1592 (0.1792)  time: 1.4507 (1.4570)  data: 0.1275 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:11:46  iter: 140  loss: 1.4429 (1.7771)  loss_reg: 0.1797 (0.2339)  loss_centerness: 0.4731 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6332 (0.8862)  alignment_loss: 0.1544 (0.1792)  time: 1.4249 (1.4569)  data: 0.1233 (0.1399)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:11:17  iter: 160  loss: 1.4799 (1.7761)  loss_reg: 0.1843 (0.2338)  loss_centerness: 0.4776 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6571 (0.8855)  alignment_loss: 0.1498 (0.1791)  time: 1.4161 (1.4572)  data: 0.1222 (0.1401)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:10:48  iter: 180  loss: 1.4055 (1.7750)  loss_reg: 0.1838 (0.2336)  loss_centerness: 0.4766 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6032 (0.8846)  alignment_loss: 0.1453 (0.1790)  time: 1.4170 (1.4571)  data: 0.1212 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:10:19  iter: 200  loss: 1.4138 (1.7738)  loss_reg: 0.1787 (0.2335)  loss_centerness: 0.4742 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6106 (0.8838)  alignment_loss: 0.1408 (0.1788)  time: 1.4238 (1.4571)  data: 0.1232 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:09:50  iter: 220  loss: 1.4541 (1.7727)  loss_reg: 0.1883 (0.2333)  loss_centerness: 0.4775 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6230 (0.8829)  alignment_loss: 0.1363 (0.1787)  time: 1.4493 (1.4571)  data: 0.1283 (0.1399)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:09:20  iter: 240  loss: 1.4640 (1.7716)  loss_reg: 0.1840 (0.2332)  loss_centerness: 0.4733 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6594 (0.8822)  alignment_loss: 0.1318 (0.1785)  time: 1.4235 (1.4571)  data: 0.1286 (0.1399)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:08:51  iter: 260  loss: 1.4281 (1.7706)  loss_reg: 0.1938 (0.2331)  loss_centerness: 0.4759 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6199 (0.8814)  alignment_loss: 0.1274 (0.1784)  time: 1.4104 (1.4571)  data: 0.1178 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:08:22  iter: 280  loss: 1.3747 (1.7693)  loss_reg: 0.1811 (0.2329)  loss_centerness: 0.4758 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6026 (0.8805)  alignment_loss: 0.1230 (0.1782)  time: 1.4476 (1.4571)  data: 0.1291 (0.1400)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:07:53  iter: 300  loss: 1.3945 (1.7681)  loss_reg: 0.1831 (0.2328)  loss_centerness: 0.4733 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5898 (0.8796)  alignment_loss: 0.1187 (0.1780)  time: 1.4244 (1.4570)  data: 0.1286 (0.1399)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:07:24  iter: 320  loss: 1.3600 (1.7668)  loss_reg: 0.1801 (0.2326)  loss_centerness: 0.4757 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5819 (0.8787)  alignment_loss: 0.1145 (0.1778)  time: 1.4259 (1.4570)  data: 0.1319 (0.1399)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:06:55  iter: 340  loss: 1.3887 (1.7656)  loss_reg: 0.1972 (0.2325)  loss_centerness: 0.4743 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6473 (0.8779)  alignment_loss: 0.1105 (0.1776)  time: 1.4754 (1.4570)  data: 0.1314 (0.1399)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:06:26  iter: 360  loss: 1.3449 (1.7643)  loss_reg: 0.1806 (0.2323)  loss_centerness: 0.4761 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5945 (0.8769)  alignment_loss: 0.1067 (0.1773)  time: 1.4214 (1.4569)  data: 0.1232 (0.1398)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:05:56  iter: 380  loss: 1.3796 (1.7631)  loss_reg: 0.1910 (0.2322)  loss_centerness: 0.4744 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6181 (0.8762)  alignment_loss: 0.1032 (0.1771)  time: 1.4836 (1.4571)  data: 0.1289 (0.1398)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:05:27  iter: 400  loss: 1.3513 (1.7619)  loss_reg: 0.1766 (0.2320)  loss_centerness: 0.4741 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6132 (0.8753)  alignment_loss: 0.1000 (0.1769)  time: 1.4271 (1.4571)  data: 0.1280 (0.1398)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:04:58  iter: 420  loss: 1.3518 (1.7606)  loss_reg: 0.1850 (0.2319)  loss_centerness: 0.4745 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5791 (0.8744)  alignment_loss: 0.0970 (0.1766)  time: 1.4698 (1.4571)  data: 0.1326 (0.1398)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:04:29  iter: 440  loss: 1.3566 (1.7593)  loss_reg: 0.1883 (0.2317)  loss_centerness: 0.4769 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6020 (0.8736)  alignment_loss: 0.0943 (0.1763)  time: 1.4303 (1.4571)  data: 0.1309 (0.1398)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:04:00  iter: 460  loss: 1.3415 (1.7580)  loss_reg: 0.1849 (0.2316)  loss_centerness: 0.4752 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5821 (0.8727)  alignment_loss: 0.0918 (0.1761)  time: 1.4684 (1.4571)  data: 0.1235 (0.1397)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:03:31  iter: 480  loss: 1.3640 (1.7568)  loss_reg: 0.1777 (0.2315)  loss_centerness: 0.4745 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6096 (0.8719)  alignment_loss: 0.0893 (0.1758)  time: 1.4773 (1.4573)  data: 0.1331 (0.1397)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:03:02  iter: 500  loss: 1.3376 (1.7555)  loss_reg: 0.1759 (0.2313)  loss_centerness: 0.4745 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5947 (0.8710)  alignment_loss: 0.0870 (0.1755)  time: 1.4121 (1.4572)  data: 0.1194 (0.1397)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:02:32  iter: 520  loss: 1.3844 (1.7543)  loss_reg: 0.1952 (0.2312)  loss_centerness: 0.4756 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.6251 (0.8702)  alignment_loss: 0.0847 (0.1752)  time: 1.4295 (1.4571)  data: 0.1315 (0.1397)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:02:03  iter: 540  loss: 1.3386 (1.7531)  loss_reg: 0.1861 (0.2311)  loss_centerness: 0.4763 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5864 (0.8694)  alignment_loss: 0.0824 (0.1749)  time: 1.4197 (1.4571)  data: 0.1291 (0.1397)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:01:34  iter: 560  loss: 1.3026 (1.7516)  loss_reg: 0.1827 (0.2309)  loss_centerness: 0.4755 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5561 (0.8684)  alignment_loss: 0.0800 (0.1746)  time: 1.4252 (1.4570)  data: 0.1280 (0.1396)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:01:05  iter: 580  loss: 1.3089 (1.7503)  loss_reg: 0.1769 (0.2308)  loss_centerness: 0.4740 (0.4776)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5756 (0.8676)  alignment_loss: 0.0775 (0.1743)  time: 1.4325 (1.4570)  data: 0.1289 (0.1396)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:00:36  iter: 600  loss: 1.3207 (1.7491)  loss_reg: 0.1922 (0.2307)  loss_centerness: 0.4750 (0.4776)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5800 (0.8667)  alignment_loss: 0.0750 (0.1740)  time: 1.4300 (1.4571)  data: 0.1224 (0.1396)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:00:07  iter: 620  loss: 1.3111 (1.7478)  loss_reg: 0.1900 (0.2305)  loss_centerness: 0.4738 (0.4776)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5912 (0.8659)  alignment_loss: 0.0723 (0.1737)  time: 1.4302 (1.4571)  data: 0.1280 (0.1395)  lr: 0.010000  wd: 0.000500  max mem: 12753
eta: 0:00:00  iter: 625  loss: 1.3262 (1.7475)  loss_reg: 0.1949 (0.2305)  loss_centerness: 0.4740 (0.4776)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.5878 (0.8658)  alignment_loss: 0.0715 (0.1736)  time: 1.4227 (1.4570)  data: 0.1207 (0.1395)  lr: 0.000000  wd: 0.000500  max mem: 12753
Evaluating
2024-03-19 10:04:38,506 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 10:04:47,057 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:04:47,061 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 10:04:47,093 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1095890410958904, 0.5205479452054794, 0.6712328767123288] 

2024-03-19 10:04:47,093 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:04:47,094 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:04:47,094 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8493150684931506
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1095890410958904, 0.5205479452054794, 0.6712328767123288], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:04:47,114 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 10:04:51,915 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:04:51,919 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 10:04:51,932 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.14814814814814814, 0.8888888888888888, 1.0] 

2024-03-19 10:04:51,932 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:04:51,932 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:04:51,932 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8148148148148148
evaluate on task refcoco, val, 1, res: {'refcoco': [0.14814814814814814, 0.8888888888888888, 1.0], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:04:51,948 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 10:04:57,920 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:04:57,924 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 10:04:57,941 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.29545454545454547, 0.5227272727272727, 0.75] 

2024-03-19 10:04:57,942 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:04:57,942 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:04:57,942 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.29545454545454547, 0.5227272727272727, 0.75], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:04:57,958 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 10:05:24,270 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:05:24,274 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 10:05:24,393 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2784313725490196, 0.7764705882352941, 0.8823529411764706] 

2024-03-19 10:05:24,393 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:05:24,393 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:05:24,394 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8352941176470589
evaluate on task refcoco, val, 3, res: {'refcoco': [0.2784313725490196, 0.7764705882352941, 0.8823529411764706], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:05:24,413 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 10:05:46,057 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:05:46,061 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.20000000298023224), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.20000000298023224), ('AR@1000', 0.20000000298023224), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.20000000298023224)]))])
2024-03-19 10:05:46,141 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2571428571428571, 0.7952380952380952, 0.8952380952380953] 

2024-03-19 10:05:46,141 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:05:46,141 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:05:46,141 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8523809523809524
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2571428571428571, 0.7952380952380952, 0.8952380952380953], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:05:46,159 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 10:06:16,526 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:06:16,530 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 10:06:16,666 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.22549019607843138, 0.7581699346405228, 0.8856209150326797] 

2024-03-19 10:06:16,666 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:06:16,666 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:06:16,666 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8790849673202614
evaluate on task refcoco, val, 5, res: {'refcoco': [0.22549019607843138, 0.7581699346405228, 0.8856209150326797], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:06:16,686 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 10:07:03,558 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:07:03,562 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 10:07:03,715 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.29535864978902954, 0.879746835443038, 0.9388185654008439] 

2024-03-19 10:07:03,716 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:07:03,716 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:07:03,716 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8227848101265823
evaluate on task refcoco, val, 6, res: {'refcoco': [0.29535864978902954, 0.879746835443038, 0.9388185654008439], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:07:03,734 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 7
2024-03-19 10:07:53,021 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:07:53,025 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 10:07:53,227 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.236, 0.726, 0.822] 

2024-03-19 10:07:53,228 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:07:53,228 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:07:53,228 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.458
evaluate on task refcoco, val, 7, res: {'refcoco': [0.236, 0.726, 0.822], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:07:53,245 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 8
2024-03-19 10:08:40,900 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:08:40,905 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 10:08:41,139 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.38, 0.912, 0.956] 

2024-03-19 10:08:41,139 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:08:41,140 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:08:41,140 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.888
evaluate on task refcoco, val, 8, res: {'refcoco': [0.38, 0.912, 0.956], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:08:41,160 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 9
2024-03-19 10:09:30,443 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:09:30,447 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.30000001192092896), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.30000001192092896), ('AR@1000', 0.30000001192092896), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.30000001192092896)]))])
2024-03-19 10:09:30,602 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.218, 0.612, 0.79] 

2024-03-19 10:09:30,603 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:09:30,603 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:09:30,603 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.722
evaluate on task refcoco, val, 9, res: {'refcoco': [0.218, 0.612, 0.79], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:09:30,621 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 10
2024-03-19 10:10:18,255 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:10:18,259 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 10:10:18,404 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.376, 0.942, 0.98] 

2024-03-19 10:10:18,404 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:10:18,404 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:10:18,404 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.86
evaluate on task refcoco, val, 10, res: {'refcoco': [0.376, 0.942, 0.98], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:10:18,422 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 11
2024-03-19 10:11:06,552 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:11:06,556 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 10:11:06,742 maskrcnn_benchmark INFO: Task[[tensor([11], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.304, 0.838, 0.934] 

2024-03-19 10:11:06,742 maskrcnn_benchmark INFO: Task[[tensor([11], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:11:06,742 maskrcnn_benchmark INFO: Task[[tensor([11], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:11:06,742 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.602
evaluate on task refcoco, val, 11, res: {'refcoco': [0.304, 0.838, 0.934], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:11:06,789 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 10:11:07,879 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 10:11:09,255 maskrcnn_benchmark.trainer INFO: Total training time: 0:23:31.546100 (2.2585 s / it)
{0: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.5205479452054794, 0.6575342465753424]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 1: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.5205479452054794, 0.6575342465753424], 1: [0.2222222222222222, 0.8518518518518519, 1.0]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 2: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.5205479452054794, 0.6575342465753424], 1: [0.2222222222222222, 0.8518518518518519, 1.0], 2: [0.3409090909090909, 0.5681818181818182, 0.7954545454545454]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 3: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.5205479452054794, 0.6438356164383562], 1: [0.2962962962962963, 0.8888888888888888, 1.0], 2: [0.36363636363636365, 0.5454545454545454, 0.75], 3: [0.29411764705882354, 0.807843137254902, 0.9215686274509803]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 4: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1506849315068493, 0.5205479452054794, 0.6575342465753424], 1: [0.2222222222222222, 0.8888888888888888, 1.0], 2: [0.3181818181818182, 0.5227272727272727, 0.7272727272727273], 3: [0.2901960784313726, 0.8117647058823529, 0.9215686274509803], 4: [0.2761904761904762, 0.8047619047619048, 0.8952380952380953]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 5: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.4794520547945205, 0.6438356164383562], 1: [0.2222222222222222, 0.8888888888888888, 1.0], 2: [0.3181818181818182, 0.5227272727272727, 0.7272727272727273], 3: [0.30196078431372547, 0.8196078431372549, 0.9215686274509803], 4: [0.2761904761904762, 0.8095238095238095, 0.8952380952380953], 5: [0.238562091503268, 0.7483660130718954, 0.8921568627450981]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 6: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.4931506849315068, 0.6438356164383562], 1: [0.2222222222222222, 0.8888888888888888, 1.0], 2: [0.3181818181818182, 0.5227272727272727, 0.7272727272727273], 3: [0.3137254901960784, 0.8235294117647058, 0.9215686274509803], 4: [0.2714285714285714, 0.8, 0.8857142857142857], 5: [0.22875816993464052, 0.7483660130718954, 0.8823529411764706], 6: [0.339662447257384, 0.9219409282700421, 0.9704641350210971]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 7: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.4931506849315068, 0.6712328767123288], 1: [0.2222222222222222, 0.8888888888888888, 1.0], 2: [0.2727272727272727, 0.5227272727272727, 0.75], 3: [0.2980392156862745, 0.803921568627451, 0.9098039215686274], 4: [0.2714285714285714, 0.8047619047619048, 0.8857142857142857], 5: [0.23202614379084968, 0.7450980392156863, 0.8823529411764706], 6: [0.3333333333333333, 0.919831223628692, 0.9725738396624473], 7: [0.31, 0.774, 0.876]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 8: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.5068493150684932, 0.6712328767123288], 1: [0.2222222222222222, 0.8888888888888888, 1.0], 2: [0.2727272727272727, 0.5227272727272727, 0.7727272727272727], 3: [0.2980392156862745, 0.803921568627451, 0.9176470588235294], 4: [0.2761904761904762, 0.8047619047619048, 0.8904761904761904], 5: [0.22875816993464052, 0.7450980392156863, 0.8823529411764706], 6: [0.3333333333333333, 0.919831223628692, 0.9725738396624473], 7: [0.31, 0.774, 0.872], 8: [0.392, 0.93, 0.968]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 9: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.5068493150684932, 0.6712328767123288], 1: [0.2222222222222222, 0.8888888888888888, 1.0], 2: [0.2727272727272727, 0.5227272727272727, 0.7727272727272727], 3: [0.29411764705882354, 0.803921568627451, 0.9176470588235294], 4: [0.2761904761904762, 0.8095238095238095, 0.8952380952380953], 5: [0.22875816993464052, 0.7483660130718954, 0.8856209150326797], 6: [0.3037974683544304, 0.879746835443038, 0.9451476793248945], 7: [0.296, 0.776, 0.866], 8: [0.396, 0.93, 0.97], 9: [0.226, 0.608, 0.774]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 10: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.5205479452054794, 0.6712328767123288], 1: [0.2222222222222222, 0.8888888888888888, 1.0], 2: [0.2727272727272727, 0.5227272727272727, 0.75], 3: [0.2980392156862745, 0.807843137254902, 0.9176470588235294], 4: [0.2571428571428571, 0.8047619047619048, 0.8952380952380953], 5: [0.22549019607843138, 0.761437908496732, 0.8823529411764706], 6: [0.3037974683544304, 0.879746835443038, 0.9451476793248945], 7: [0.278, 0.776, 0.864], 8: [0.388, 0.924, 0.97], 9: [0.226, 0.608, 0.778], 10: [0.382, 0.946, 0.98]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 11: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1095890410958904, 0.5205479452054794, 0.6712328767123288], 1: [0.14814814814814814, 0.8888888888888888, 1.0], 2: [0.29545454545454547, 0.5227272727272727, 0.75], 3: [0.2784313725490196, 0.7764705882352941, 0.8823529411764706], 4: [0.2571428571428571, 0.7952380952380952, 0.8952380952380953], 5: [0.22549019607843138, 0.7581699346405228, 0.8856209150326797], 6: [0.29535864978902954, 0.879746835443038, 0.9388185654008439], 7: [0.236, 0.726, 0.822], 8: [0.38, 0.912, 0.956], 9: [0.218, 0.612, 0.79], 10: [0.376, 0.942, 0.98], 11: [0.304, 0.838, 0.934]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}}
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: False
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 3
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('refexp_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('refexp_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: True
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
LPAI:
  INTERACT: False
  INTERACT_LORA_D: 4
  LAYER_ALIGNMENT: True
  PROMPT_DEPTH: 9
  PROMPT_LORA: True
  PROMPT_LORA_D: 4
  TASK_ALIGNMENT: True
  TEXTUAL_PROMPT: True
  VISUAL_PROMPT: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: False
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: False
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: MODEL/glip_a_tiny_o365.pth
OUTPUT_DIR: OUTPUT
PATHS_CATALOG: /root/workspace/grounding/prompt_grounding/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: 4
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 0.0001
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: True
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 32
  LANG_LR: 0.0001
  MAX_EPOCH: 30
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.0
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 10
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 2
  TEST_WITH_INFERENCE: True
  TUNING_HIGHLEVEL_OVERRIDE: language_prompt_v4
  USE_AMP: True
  USE_AUTOSTEP: True
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: True
  EVAL_TASK: grounding
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 1
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
args.opts []
2024-03-19 10:11:14,018 maskrcnn_benchmark INFO: Using 1 GPUs
2024-03-19 10:11:14,018 maskrcnn_benchmark INFO: Namespace(config_file='configs/refcoco/finetune_A_decompose_layer_task.yaml', custom_shot_and_epoch_and_general_copy='0_10_1', distributed=False, evaluate_only_best_on_test=False, ft_tasks='', keep_testing=False, local_rank=0, opts=[], push_both_val_and_test=False, shuffle_seeds=None, skip_optimizer_resume=False, skip_test=True, skip_train=False, use_prepared_data=False)
2024-03-19 10:11:14,018 maskrcnn_benchmark INFO: Loaded configuration file configs/refcoco/finetune_A_decompose_layer_task.yaml
2024-03-19 10:11:14,019 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "MODEL/glip_a_tiny_o365.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: False
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True

    USE_CHECKPOINT: False

TEST:
  DURING_TRAINING: True
  IMS_PER_BATCH: 1
  EVAL_TASK: grounding
# use for grounding model
DATASETS:
  TRAIN: ("refexp_train", )
  TEST: ("refexp_val",)
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

  USE_OVERRIDE_CATEGORY: True
  SHUFFLE_SEED: 3

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.0001
  WEIGHT_DECAY: 0.05
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 32
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.0
  FIND_UNUSED_PARAMETERS: True

  TEST_WITH_INFERENCE: True
  USE_AUTOSTEP: True
#  USE_COSINE: True

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0

  SEED: 10
  STEP_PATIENCE: 2
  AUTO_TERMINATE_PATIENCE: 4
  TUNING_HIGHLEVEL_OVERRIDE: language_prompt_v4

LPAI:
  VISUAL_PROMPT: True
  TEXTUAL_PROMPT: True
  TASK_ALIGNMENT: True
  LAYER_ALIGNMENT: True
  INTERACT: False
  PROMPT_DEPTH: 9

  PROMPT_LORA_D: 4
  INTERACT_LORA_D: 4
  PROMPT_LORA: True

2024-03-19 10:11:14,020 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: False
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 3
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('refexp_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('refexp_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: True
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
LPAI:
  INTERACT: False
  INTERACT_LORA_D: 4
  LAYER_ALIGNMENT: True
  PROMPT_DEPTH: 9
  PROMPT_LORA: True
  PROMPT_LORA_D: 4
  TASK_ALIGNMENT: True
  TEXTUAL_PROMPT: True
  VISUAL_PROMPT: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: False
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: False
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: MODEL/glip_a_tiny_o365.pth
OUTPUT_DIR: OUTPUT
PATHS_CATALOG: /root/workspace/grounding/prompt_grounding/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: 4
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 0.0001
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: True
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 32
  LANG_LR: 0.0001
  MAX_EPOCH: 30
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.0
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 10
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 2
  TEST_WITH_INFERENCE: True
  TUNING_HIGHLEVEL_OVERRIDE: language_prompt_v4
  USE_AMP: True
  USE_AUTOSTEP: True
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: True
  EVAL_TASK: grounding
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 1
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 1
2024-03-19 10:11:14,020 maskrcnn_benchmark INFO: Saving config into: OUTPUT/config.yml
2024-03-19 10:11:14,076 maskrcnn_benchmark INFO: Loaded fine-tune configuration file configs/refcoco/finetune_A_decompose_layer_task.yaml
2024-03-19 10:11:14,076 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "MODEL/glip_a_tiny_o365.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: False
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True

    USE_CHECKPOINT: False

TEST:
  DURING_TRAINING: True
  IMS_PER_BATCH: 1
  EVAL_TASK: grounding
# use for grounding model
DATASETS:
  TRAIN: ("refexp_train", )
  TEST: ("refexp_val",)
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

  USE_OVERRIDE_CATEGORY: True
  SHUFFLE_SEED: 3

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.0001
  WEIGHT_DECAY: 0.05
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 32
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.0
  FIND_UNUSED_PARAMETERS: True

  TEST_WITH_INFERENCE: True
  USE_AUTOSTEP: True
#  USE_COSINE: True

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0

  SEED: 10
  STEP_PATIENCE: 2
  AUTO_TERMINATE_PATIENCE: 4
  TUNING_HIGHLEVEL_OVERRIDE: language_prompt_v4

LPAI:
  VISUAL_PROMPT: True
  TEXTUAL_PROMPT: True
  TASK_ALIGNMENT: True
  LAYER_ALIGNMENT: True
  INTERACT: False
  PROMPT_DEPTH: 9

  PROMPT_LORA_D: 4
  INTERACT_LORA_D: 4
  PROMPT_LORA: True

Saving config into: OUTPUT/ft_task_1/config.yml
2024-03-19 10:11:14,112 maskrcnn_benchmark INFO: Training configs/refcoco/finetune_A_decompose_layer_task.yaml
VISION BACKBONE USE GRADIENT CHECKPOINTING:  False
LANGUAGE BACKBONE USE GRADIENT CHECKPOINTING:  False
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.proj.bias                                          loaded from backbone.body.layers.0.blocks.0.attn.proj.bias                                  of shape (96,)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.proj.weight                                        loaded from backbone.body.layers.0.blocks.0.attn.proj.weight                                of shape (96, 96)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.qkv.bias                                           loaded from backbone.body.layers.0.blocks.0.attn.qkv.bias                                   of shape (288,)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.qkv.weight                                         loaded from backbone.body.layers.0.blocks.0.attn.qkv.weight                                 of shape (288, 96)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.relative_position_bias_table                       loaded from backbone.body.layers.0.blocks.0.attn.relative_position_bias_table               of shape (169, 3)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.attn.relative_position_index                            loaded from backbone.body.layers.0.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.mlp.fc1.bias                                            loaded from backbone.body.layers.0.blocks.0.mlp.fc1.bias                                    of shape (384,)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.mlp.fc1.weight                                          loaded from backbone.body.layers.0.blocks.0.mlp.fc1.weight                                  of shape (384, 96)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.mlp.fc2.bias                                            loaded from backbone.body.layers.0.blocks.0.mlp.fc2.bias                                    of shape (96,)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.mlp.fc2.weight                                          loaded from backbone.body.layers.0.blocks.0.mlp.fc2.weight                                  of shape (96, 384)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.norm1.bias                                              loaded from backbone.body.layers.0.blocks.0.norm1.bias                                      of shape (96,)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.norm1.weight                                            loaded from backbone.body.layers.0.blocks.0.norm1.weight                                    of shape (96,)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.norm2.bias                                              loaded from backbone.body.layers.0.blocks.0.norm2.bias                                      of shape (96,)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.0.norm2.weight                                            loaded from backbone.body.layers.0.blocks.0.norm2.weight                                    of shape (96,)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.proj.bias                                          loaded from backbone.body.layers.0.blocks.1.attn.proj.bias                                  of shape (96,)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.proj.weight                                        loaded from backbone.body.layers.0.blocks.1.attn.proj.weight                                of shape (96, 96)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.qkv.bias                                           loaded from backbone.body.layers.0.blocks.1.attn.qkv.bias                                   of shape (288,)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.qkv.weight                                         loaded from backbone.body.layers.0.blocks.1.attn.qkv.weight                                 of shape (288, 96)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.relative_position_bias_table                       loaded from backbone.body.layers.0.blocks.1.attn.relative_position_bias_table               of shape (169, 3)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.attn.relative_position_index                            loaded from backbone.body.layers.0.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.mlp.fc1.bias                                            loaded from backbone.body.layers.0.blocks.1.mlp.fc1.bias                                    of shape (384,)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.mlp.fc1.weight                                          loaded from backbone.body.layers.0.blocks.1.mlp.fc1.weight                                  of shape (384, 96)
2024-03-19 10:11:22,257 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.mlp.fc2.bias                                            loaded from backbone.body.layers.0.blocks.1.mlp.fc2.bias                                    of shape (96,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.mlp.fc2.weight                                          loaded from backbone.body.layers.0.blocks.1.mlp.fc2.weight                                  of shape (96, 384)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.norm1.bias                                              loaded from backbone.body.layers.0.blocks.1.norm1.bias                                      of shape (96,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.norm1.weight                                            loaded from backbone.body.layers.0.blocks.1.norm1.weight                                    of shape (96,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.norm2.bias                                              loaded from backbone.body.layers.0.blocks.1.norm2.bias                                      of shape (96,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.blocks.1.norm2.weight                                            loaded from backbone.body.layers.0.blocks.1.norm2.weight                                    of shape (96,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.downsample.norm.bias                                             loaded from backbone.body.layers.0.downsample.norm.bias                                     of shape (384,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.downsample.norm.weight                                           loaded from backbone.body.layers.0.downsample.norm.weight                                   of shape (384,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.0.downsample.reduction.weight                                      loaded from backbone.body.layers.0.downsample.reduction.weight                              of shape (192, 384)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.proj.bias                                          loaded from backbone.body.layers.1.blocks.0.attn.proj.bias                                  of shape (192,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.proj.weight                                        loaded from backbone.body.layers.1.blocks.0.attn.proj.weight                                of shape (192, 192)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.qkv.bias                                           loaded from backbone.body.layers.1.blocks.0.attn.qkv.bias                                   of shape (576,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.qkv.weight                                         loaded from backbone.body.layers.1.blocks.0.attn.qkv.weight                                 of shape (576, 192)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.relative_position_bias_table                       loaded from backbone.body.layers.1.blocks.0.attn.relative_position_bias_table               of shape (169, 6)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.attn.relative_position_index                            loaded from backbone.body.layers.1.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.mlp.fc1.bias                                            loaded from backbone.body.layers.1.blocks.0.mlp.fc1.bias                                    of shape (768,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.mlp.fc1.weight                                          loaded from backbone.body.layers.1.blocks.0.mlp.fc1.weight                                  of shape (768, 192)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.mlp.fc2.bias                                            loaded from backbone.body.layers.1.blocks.0.mlp.fc2.bias                                    of shape (192,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.mlp.fc2.weight                                          loaded from backbone.body.layers.1.blocks.0.mlp.fc2.weight                                  of shape (192, 768)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.norm1.bias                                              loaded from backbone.body.layers.1.blocks.0.norm1.bias                                      of shape (192,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.norm1.weight                                            loaded from backbone.body.layers.1.blocks.0.norm1.weight                                    of shape (192,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.norm2.bias                                              loaded from backbone.body.layers.1.blocks.0.norm2.bias                                      of shape (192,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.0.norm2.weight                                            loaded from backbone.body.layers.1.blocks.0.norm2.weight                                    of shape (192,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.proj.bias                                          loaded from backbone.body.layers.1.blocks.1.attn.proj.bias                                  of shape (192,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.proj.weight                                        loaded from backbone.body.layers.1.blocks.1.attn.proj.weight                                of shape (192, 192)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.qkv.bias                                           loaded from backbone.body.layers.1.blocks.1.attn.qkv.bias                                   of shape (576,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.qkv.weight                                         loaded from backbone.body.layers.1.blocks.1.attn.qkv.weight                                 of shape (576, 192)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.relative_position_bias_table                       loaded from backbone.body.layers.1.blocks.1.attn.relative_position_bias_table               of shape (169, 6)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.attn.relative_position_index                            loaded from backbone.body.layers.1.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.mlp.fc1.bias                                            loaded from backbone.body.layers.1.blocks.1.mlp.fc1.bias                                    of shape (768,)
2024-03-19 10:11:22,258 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.mlp.fc1.weight                                          loaded from backbone.body.layers.1.blocks.1.mlp.fc1.weight                                  of shape (768, 192)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.mlp.fc2.bias                                            loaded from backbone.body.layers.1.blocks.1.mlp.fc2.bias                                    of shape (192,)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.mlp.fc2.weight                                          loaded from backbone.body.layers.1.blocks.1.mlp.fc2.weight                                  of shape (192, 768)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.norm1.bias                                              loaded from backbone.body.layers.1.blocks.1.norm1.bias                                      of shape (192,)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.norm1.weight                                            loaded from backbone.body.layers.1.blocks.1.norm1.weight                                    of shape (192,)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.norm2.bias                                              loaded from backbone.body.layers.1.blocks.1.norm2.bias                                      of shape (192,)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.blocks.1.norm2.weight                                            loaded from backbone.body.layers.1.blocks.1.norm2.weight                                    of shape (192,)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.downsample.norm.bias                                             loaded from backbone.body.layers.1.downsample.norm.bias                                     of shape (768,)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.downsample.norm.weight                                           loaded from backbone.body.layers.1.downsample.norm.weight                                   of shape (768,)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.1.downsample.reduction.weight                                      loaded from backbone.body.layers.1.downsample.reduction.weight                              of shape (384, 768)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.0.attn.proj.bias                                  of shape (384,)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.0.attn.proj.weight                                of shape (384, 384)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.0.attn.qkv.bias                                   of shape (1152,)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.0.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.0.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.0.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.0.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.0.mlp.fc2.bias                                    of shape (384,)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.0.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 10:11:22,259 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.norm1.bias                                              loaded from backbone.body.layers.2.blocks.0.norm1.bias                                      of shape (384,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.norm1.weight                                            loaded from backbone.body.layers.2.blocks.0.norm1.weight                                    of shape (384,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.norm2.bias                                              loaded from backbone.body.layers.2.blocks.0.norm2.bias                                      of shape (384,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.0.norm2.weight                                            loaded from backbone.body.layers.2.blocks.0.norm2.weight                                    of shape (384,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.1.attn.proj.bias                                  of shape (384,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.1.attn.proj.weight                                of shape (384, 384)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.1.attn.qkv.bias                                   of shape (1152,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.1.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.1.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.1.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.1.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.1.mlp.fc2.bias                                    of shape (384,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.1.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.norm1.bias                                              loaded from backbone.body.layers.2.blocks.1.norm1.bias                                      of shape (384,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.norm1.weight                                            loaded from backbone.body.layers.2.blocks.1.norm1.weight                                    of shape (384,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.norm2.bias                                              loaded from backbone.body.layers.2.blocks.1.norm2.bias                                      of shape (384,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.1.norm2.weight                                            loaded from backbone.body.layers.2.blocks.1.norm2.weight                                    of shape (384,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.2.attn.proj.bias                                  of shape (384,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.2.attn.proj.weight                                of shape (384, 384)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.2.attn.qkv.bias                                   of shape (1152,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.2.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.2.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.2.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.2.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.2.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.2.mlp.fc2.bias                                    of shape (384,)
2024-03-19 10:11:22,260 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.2.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.norm1.bias                                              loaded from backbone.body.layers.2.blocks.2.norm1.bias                                      of shape (384,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.norm1.weight                                            loaded from backbone.body.layers.2.blocks.2.norm1.weight                                    of shape (384,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.norm2.bias                                              loaded from backbone.body.layers.2.blocks.2.norm2.bias                                      of shape (384,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.2.norm2.weight                                            loaded from backbone.body.layers.2.blocks.2.norm2.weight                                    of shape (384,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.3.attn.proj.bias                                  of shape (384,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.3.attn.proj.weight                                of shape (384, 384)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.3.attn.qkv.bias                                   of shape (1152,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.3.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.3.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.3.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.3.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.3.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.3.mlp.fc2.bias                                    of shape (384,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.3.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.norm1.bias                                              loaded from backbone.body.layers.2.blocks.3.norm1.bias                                      of shape (384,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.norm1.weight                                            loaded from backbone.body.layers.2.blocks.3.norm1.weight                                    of shape (384,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.norm2.bias                                              loaded from backbone.body.layers.2.blocks.3.norm2.bias                                      of shape (384,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.3.norm2.weight                                            loaded from backbone.body.layers.2.blocks.3.norm2.weight                                    of shape (384,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.4.attn.proj.bias                                  of shape (384,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.4.attn.proj.weight                                of shape (384, 384)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.4.attn.qkv.bias                                   of shape (1152,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.4.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.4.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.4.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.4.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.4.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.4.mlp.fc2.bias                                    of shape (384,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.4.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.norm1.bias                                              loaded from backbone.body.layers.2.blocks.4.norm1.bias                                      of shape (384,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.norm1.weight                                            loaded from backbone.body.layers.2.blocks.4.norm1.weight                                    of shape (384,)
2024-03-19 10:11:22,261 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.norm2.bias                                              loaded from backbone.body.layers.2.blocks.4.norm2.bias                                      of shape (384,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.4.norm2.weight                                            loaded from backbone.body.layers.2.blocks.4.norm2.weight                                    of shape (384,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.proj.bias                                          loaded from backbone.body.layers.2.blocks.5.attn.proj.bias                                  of shape (384,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.proj.weight                                        loaded from backbone.body.layers.2.blocks.5.attn.proj.weight                                of shape (384, 384)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.qkv.bias                                           loaded from backbone.body.layers.2.blocks.5.attn.qkv.bias                                   of shape (1152,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.qkv.weight                                         loaded from backbone.body.layers.2.blocks.5.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.relative_position_bias_table                       loaded from backbone.body.layers.2.blocks.5.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.attn.relative_position_index                            loaded from backbone.body.layers.2.blocks.5.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.mlp.fc1.bias                                            loaded from backbone.body.layers.2.blocks.5.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.mlp.fc1.weight                                          loaded from backbone.body.layers.2.blocks.5.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.mlp.fc2.bias                                            loaded from backbone.body.layers.2.blocks.5.mlp.fc2.bias                                    of shape (384,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.mlp.fc2.weight                                          loaded from backbone.body.layers.2.blocks.5.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.norm1.bias                                              loaded from backbone.body.layers.2.blocks.5.norm1.bias                                      of shape (384,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.norm1.weight                                            loaded from backbone.body.layers.2.blocks.5.norm1.weight                                    of shape (384,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.norm2.bias                                              loaded from backbone.body.layers.2.blocks.5.norm2.bias                                      of shape (384,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.blocks.5.norm2.weight                                            loaded from backbone.body.layers.2.blocks.5.norm2.weight                                    of shape (384,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.downsample.norm.bias                                             loaded from backbone.body.layers.2.downsample.norm.bias                                     of shape (1536,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.downsample.norm.weight                                           loaded from backbone.body.layers.2.downsample.norm.weight                                   of shape (1536,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.2.downsample.reduction.weight                                      loaded from backbone.body.layers.2.downsample.reduction.weight                              of shape (768, 1536)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.proj.bias                                          loaded from backbone.body.layers.3.blocks.0.attn.proj.bias                                  of shape (768,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.proj.weight                                        loaded from backbone.body.layers.3.blocks.0.attn.proj.weight                                of shape (768, 768)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.qkv.bias                                           loaded from backbone.body.layers.3.blocks.0.attn.qkv.bias                                   of shape (2304,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.qkv.weight                                         loaded from backbone.body.layers.3.blocks.0.attn.qkv.weight                                 of shape (2304, 768)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.relative_position_bias_table                       loaded from backbone.body.layers.3.blocks.0.attn.relative_position_bias_table               of shape (169, 24)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.attn.relative_position_index                            loaded from backbone.body.layers.3.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.mlp.fc1.bias                                            loaded from backbone.body.layers.3.blocks.0.mlp.fc1.bias                                    of shape (3072,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.mlp.fc1.weight                                          loaded from backbone.body.layers.3.blocks.0.mlp.fc1.weight                                  of shape (3072, 768)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.mlp.fc2.bias                                            loaded from backbone.body.layers.3.blocks.0.mlp.fc2.bias                                    of shape (768,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.mlp.fc2.weight                                          loaded from backbone.body.layers.3.blocks.0.mlp.fc2.weight                                  of shape (768, 3072)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.norm1.bias                                              loaded from backbone.body.layers.3.blocks.0.norm1.bias                                      of shape (768,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.norm1.weight                                            loaded from backbone.body.layers.3.blocks.0.norm1.weight                                    of shape (768,)
2024-03-19 10:11:22,262 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.norm2.bias                                              loaded from backbone.body.layers.3.blocks.0.norm2.bias                                      of shape (768,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.0.norm2.weight                                            loaded from backbone.body.layers.3.blocks.0.norm2.weight                                    of shape (768,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.proj.bias                                          loaded from backbone.body.layers.3.blocks.1.attn.proj.bias                                  of shape (768,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.proj.weight                                        loaded from backbone.body.layers.3.blocks.1.attn.proj.weight                                of shape (768, 768)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.qkv.bias                                           loaded from backbone.body.layers.3.blocks.1.attn.qkv.bias                                   of shape (2304,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.qkv.weight                                         loaded from backbone.body.layers.3.blocks.1.attn.qkv.weight                                 of shape (2304, 768)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.relative_position_bias_table                       loaded from backbone.body.layers.3.blocks.1.attn.relative_position_bias_table               of shape (169, 24)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.attn.relative_position_index                            loaded from backbone.body.layers.3.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.mlp.fc1.bias                                            loaded from backbone.body.layers.3.blocks.1.mlp.fc1.bias                                    of shape (3072,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.mlp.fc1.weight                                          loaded from backbone.body.layers.3.blocks.1.mlp.fc1.weight                                  of shape (3072, 768)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.mlp.fc2.bias                                            loaded from backbone.body.layers.3.blocks.1.mlp.fc2.bias                                    of shape (768,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.mlp.fc2.weight                                          loaded from backbone.body.layers.3.blocks.1.mlp.fc2.weight                                  of shape (768, 3072)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.norm1.bias                                              loaded from backbone.body.layers.3.blocks.1.norm1.bias                                      of shape (768,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.norm1.weight                                            loaded from backbone.body.layers.3.blocks.1.norm1.weight                                    of shape (768,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.norm2.bias                                              loaded from backbone.body.layers.3.blocks.1.norm2.bias                                      of shape (768,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layers.3.blocks.1.norm2.weight                                            loaded from backbone.body.layers.3.blocks.1.norm2.weight                                    of shape (768,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm1.bias                                                                loaded from backbone.body.norm1.bias                                                        of shape (192,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm1.weight                                                              loaded from backbone.body.norm1.weight                                                      of shape (192,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm2.bias                                                                loaded from backbone.body.norm2.bias                                                        of shape (384,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm2.weight                                                              loaded from backbone.body.norm2.weight                                                      of shape (384,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm3.bias                                                                loaded from backbone.body.norm3.bias                                                        of shape (768,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.norm3.weight                                                              loaded from backbone.body.norm3.weight                                                      of shape (768,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.patch_embed.norm.bias                                                     loaded from backbone.body.patch_embed.norm.bias                                             of shape (96,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.patch_embed.norm.weight                                                   loaded from backbone.body.patch_embed.norm.weight                                           of shape (96,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.patch_embed.proj.bias                                                     loaded from backbone.body.patch_embed.proj.bias                                             of shape (96,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.patch_embed.proj.weight                                                   loaded from backbone.body.patch_embed.proj.weight                                           of shape (96, 3, 4, 4)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                                                            loaded from backbone.fpn.fpn_inner2.bias                                                    of shape (256,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                                                          loaded from backbone.fpn.fpn_inner2.weight                                                  of shape (256, 192, 1, 1)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                                                            loaded from backbone.fpn.fpn_inner3.bias                                                    of shape (256,)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                                                          loaded from backbone.fpn.fpn_inner3.weight                                                  of shape (256, 384, 1, 1)
2024-03-19 10:11:22,263 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                                                            loaded from backbone.fpn.fpn_inner4.bias                                                    of shape (256,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                                                          loaded from backbone.fpn.fpn_inner4.weight                                                  of shape (256, 768, 1, 1)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                                                            loaded from backbone.fpn.fpn_layer2.bias                                                    of shape (256,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                                                          loaded from backbone.fpn.fpn_layer2.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                                                            loaded from backbone.fpn.fpn_layer3.bias                                                    of shape (256,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                                                          loaded from backbone.fpn.fpn_layer3.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                                                            loaded from backbone.fpn.fpn_layer4.bias                                                    of shape (256,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                                                          loaded from backbone.fpn.fpn_layer4.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.top_blocks.p6.bias                                                         loaded from backbone.fpn.top_blocks.p6.bias                                                 of shape (256,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.top_blocks.p6.weight                                                       loaded from backbone.fpn.top_blocks.p6.weight                                               of shape (256, 256, 3, 3)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.top_blocks.p7.bias                                                         loaded from backbone.fpn.top_blocks.p7.bias                                                 of shape (256,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.top_blocks.p7.weight                                                       loaded from backbone.fpn.top_blocks.p7.weight                                               of shape (256, 256, 3, 3)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.proj.bias                                  loaded from backbone.body.layers.0.blocks.0.attn.proj.bias                                  of shape (96,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.proj.weight                                loaded from backbone.body.layers.0.blocks.0.attn.proj.weight                                of shape (96, 96)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.qkv.bias                                   loaded from backbone.body.layers.0.blocks.0.attn.qkv.bias                                   of shape (288,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.qkv.weight                                 loaded from backbone.body.layers.0.blocks.0.attn.qkv.weight                                 of shape (288, 96)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.relative_position_bias_table               loaded from backbone.body.layers.0.blocks.0.attn.relative_position_bias_table               of shape (169, 3)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.attn.relative_position_index                    loaded from backbone.body.layers.0.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.mlp.fc1.bias                                    loaded from backbone.body.layers.0.blocks.0.mlp.fc1.bias                                    of shape (384,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.mlp.fc1.weight                                  loaded from backbone.body.layers.0.blocks.0.mlp.fc1.weight                                  of shape (384, 96)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.mlp.fc2.bias                                    loaded from backbone.body.layers.0.blocks.0.mlp.fc2.bias                                    of shape (96,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.mlp.fc2.weight                                  loaded from backbone.body.layers.0.blocks.0.mlp.fc2.weight                                  of shape (96, 384)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.norm1.bias                                      loaded from backbone.body.layers.0.blocks.0.norm1.bias                                      of shape (96,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.norm1.weight                                    loaded from backbone.body.layers.0.blocks.0.norm1.weight                                    of shape (96,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.norm2.bias                                      loaded from backbone.body.layers.0.blocks.0.norm2.bias                                      of shape (96,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.0.norm2.weight                                    loaded from backbone.body.layers.0.blocks.0.norm2.weight                                    of shape (96,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.proj.bias                                  loaded from backbone.body.layers.0.blocks.1.attn.proj.bias                                  of shape (96,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.proj.weight                                loaded from backbone.body.layers.0.blocks.1.attn.proj.weight                                of shape (96, 96)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.qkv.bias                                   loaded from backbone.body.layers.0.blocks.1.attn.qkv.bias                                   of shape (288,)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.qkv.weight                                 loaded from backbone.body.layers.0.blocks.1.attn.qkv.weight                                 of shape (288, 96)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.relative_position_bias_table               loaded from backbone.body.layers.0.blocks.1.attn.relative_position_bias_table               of shape (169, 3)
2024-03-19 10:11:22,264 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.attn.relative_position_index                    loaded from backbone.body.layers.0.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.mlp.fc1.bias                                    loaded from backbone.body.layers.0.blocks.1.mlp.fc1.bias                                    of shape (384,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.mlp.fc1.weight                                  loaded from backbone.body.layers.0.blocks.1.mlp.fc1.weight                                  of shape (384, 96)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.mlp.fc2.bias                                    loaded from backbone.body.layers.0.blocks.1.mlp.fc2.bias                                    of shape (96,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.mlp.fc2.weight                                  loaded from backbone.body.layers.0.blocks.1.mlp.fc2.weight                                  of shape (96, 384)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.norm1.bias                                      loaded from backbone.body.layers.0.blocks.1.norm1.bias                                      of shape (96,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.norm1.weight                                    loaded from backbone.body.layers.0.blocks.1.norm1.weight                                    of shape (96,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.norm2.bias                                      loaded from backbone.body.layers.0.blocks.1.norm2.bias                                      of shape (96,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.blocks.1.norm2.weight                                    loaded from backbone.body.layers.0.blocks.1.norm2.weight                                    of shape (96,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.downsample.norm.bias                                     loaded from backbone.body.layers.0.downsample.norm.bias                                     of shape (384,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.downsample.norm.weight                                   loaded from backbone.body.layers.0.downsample.norm.weight                                   of shape (384,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.0.downsample.reduction.weight                              loaded from backbone.body.layers.0.downsample.reduction.weight                              of shape (192, 384)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.proj.bias                                  loaded from backbone.body.layers.1.blocks.0.attn.proj.bias                                  of shape (192,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.proj.weight                                loaded from backbone.body.layers.1.blocks.0.attn.proj.weight                                of shape (192, 192)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.qkv.bias                                   loaded from backbone.body.layers.1.blocks.0.attn.qkv.bias                                   of shape (576,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.qkv.weight                                 loaded from backbone.body.layers.1.blocks.0.attn.qkv.weight                                 of shape (576, 192)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.relative_position_bias_table               loaded from backbone.body.layers.1.blocks.0.attn.relative_position_bias_table               of shape (169, 6)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.attn.relative_position_index                    loaded from backbone.body.layers.1.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.mlp.fc1.bias                                    loaded from backbone.body.layers.1.blocks.0.mlp.fc1.bias                                    of shape (768,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.mlp.fc1.weight                                  loaded from backbone.body.layers.1.blocks.0.mlp.fc1.weight                                  of shape (768, 192)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.mlp.fc2.bias                                    loaded from backbone.body.layers.1.blocks.0.mlp.fc2.bias                                    of shape (192,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.mlp.fc2.weight                                  loaded from backbone.body.layers.1.blocks.0.mlp.fc2.weight                                  of shape (192, 768)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.norm1.bias                                      loaded from backbone.body.layers.1.blocks.0.norm1.bias                                      of shape (192,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.norm1.weight                                    loaded from backbone.body.layers.1.blocks.0.norm1.weight                                    of shape (192,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.norm2.bias                                      loaded from backbone.body.layers.1.blocks.0.norm2.bias                                      of shape (192,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.0.norm2.weight                                    loaded from backbone.body.layers.1.blocks.0.norm2.weight                                    of shape (192,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.proj.bias                                  loaded from backbone.body.layers.1.blocks.1.attn.proj.bias                                  of shape (192,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.proj.weight                                loaded from backbone.body.layers.1.blocks.1.attn.proj.weight                                of shape (192, 192)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.qkv.bias                                   loaded from backbone.body.layers.1.blocks.1.attn.qkv.bias                                   of shape (576,)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.qkv.weight                                 loaded from backbone.body.layers.1.blocks.1.attn.qkv.weight                                 of shape (576, 192)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.relative_position_bias_table               loaded from backbone.body.layers.1.blocks.1.attn.relative_position_bias_table               of shape (169, 6)
2024-03-19 10:11:22,265 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.attn.relative_position_index                    loaded from backbone.body.layers.1.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.mlp.fc1.bias                                    loaded from backbone.body.layers.1.blocks.1.mlp.fc1.bias                                    of shape (768,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.mlp.fc1.weight                                  loaded from backbone.body.layers.1.blocks.1.mlp.fc1.weight                                  of shape (768, 192)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.mlp.fc2.bias                                    loaded from backbone.body.layers.1.blocks.1.mlp.fc2.bias                                    of shape (192,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.mlp.fc2.weight                                  loaded from backbone.body.layers.1.blocks.1.mlp.fc2.weight                                  of shape (192, 768)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.norm1.bias                                      loaded from backbone.body.layers.1.blocks.1.norm1.bias                                      of shape (192,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.norm1.weight                                    loaded from backbone.body.layers.1.blocks.1.norm1.weight                                    of shape (192,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.norm2.bias                                      loaded from backbone.body.layers.1.blocks.1.norm2.bias                                      of shape (192,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.blocks.1.norm2.weight                                    loaded from backbone.body.layers.1.blocks.1.norm2.weight                                    of shape (192,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.downsample.norm.bias                                     loaded from backbone.body.layers.1.downsample.norm.bias                                     of shape (768,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.downsample.norm.weight                                   loaded from backbone.body.layers.1.downsample.norm.weight                                   of shape (768,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.1.downsample.reduction.weight                              loaded from backbone.body.layers.1.downsample.reduction.weight                              of shape (384, 768)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.0.attn.proj.bias                                  of shape (384,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.0.attn.proj.weight                                of shape (384, 384)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.0.attn.qkv.bias                                   of shape (1152,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.0.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.0.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.0.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.0.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.0.mlp.fc2.bias                                    of shape (384,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.0.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.norm1.bias                                      loaded from backbone.body.layers.2.blocks.0.norm1.bias                                      of shape (384,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.norm1.weight                                    loaded from backbone.body.layers.2.blocks.0.norm1.weight                                    of shape (384,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.norm2.bias                                      loaded from backbone.body.layers.2.blocks.0.norm2.bias                                      of shape (384,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.0.norm2.weight                                    loaded from backbone.body.layers.2.blocks.0.norm2.weight                                    of shape (384,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.1.attn.proj.bias                                  of shape (384,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.1.attn.proj.weight                                of shape (384, 384)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.1.attn.qkv.bias                                   of shape (1152,)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.1.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.1.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 10:11:22,266 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.1.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.1.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.1.mlp.fc2.bias                                    of shape (384,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.1.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.norm1.bias                                      loaded from backbone.body.layers.2.blocks.1.norm1.bias                                      of shape (384,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.norm1.weight                                    loaded from backbone.body.layers.2.blocks.1.norm1.weight                                    of shape (384,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.norm2.bias                                      loaded from backbone.body.layers.2.blocks.1.norm2.bias                                      of shape (384,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.1.norm2.weight                                    loaded from backbone.body.layers.2.blocks.1.norm2.weight                                    of shape (384,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.2.attn.proj.bias                                  of shape (384,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.2.attn.proj.weight                                of shape (384, 384)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.2.attn.qkv.bias                                   of shape (1152,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.2.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.2.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.2.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.2.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.2.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.2.mlp.fc2.bias                                    of shape (384,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.2.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.norm1.bias                                      loaded from backbone.body.layers.2.blocks.2.norm1.bias                                      of shape (384,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.norm1.weight                                    loaded from backbone.body.layers.2.blocks.2.norm1.weight                                    of shape (384,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.norm2.bias                                      loaded from backbone.body.layers.2.blocks.2.norm2.bias                                      of shape (384,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.2.norm2.weight                                    loaded from backbone.body.layers.2.blocks.2.norm2.weight                                    of shape (384,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.3.attn.proj.bias                                  of shape (384,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.3.attn.proj.weight                                of shape (384, 384)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.3.attn.qkv.bias                                   of shape (1152,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.3.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.3.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.3.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.3.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.3.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 10:11:22,267 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.3.mlp.fc2.bias                                    of shape (384,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.3.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.norm1.bias                                      loaded from backbone.body.layers.2.blocks.3.norm1.bias                                      of shape (384,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.norm1.weight                                    loaded from backbone.body.layers.2.blocks.3.norm1.weight                                    of shape (384,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.norm2.bias                                      loaded from backbone.body.layers.2.blocks.3.norm2.bias                                      of shape (384,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.3.norm2.weight                                    loaded from backbone.body.layers.2.blocks.3.norm2.weight                                    of shape (384,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.4.attn.proj.bias                                  of shape (384,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.4.attn.proj.weight                                of shape (384, 384)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.4.attn.qkv.bias                                   of shape (1152,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.4.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.4.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.4.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.4.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.4.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.4.mlp.fc2.bias                                    of shape (384,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.4.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.norm1.bias                                      loaded from backbone.body.layers.2.blocks.4.norm1.bias                                      of shape (384,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.norm1.weight                                    loaded from backbone.body.layers.2.blocks.4.norm1.weight                                    of shape (384,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.norm2.bias                                      loaded from backbone.body.layers.2.blocks.4.norm2.bias                                      of shape (384,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.4.norm2.weight                                    loaded from backbone.body.layers.2.blocks.4.norm2.weight                                    of shape (384,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.proj.bias                                  loaded from backbone.body.layers.2.blocks.5.attn.proj.bias                                  of shape (384,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.proj.weight                                loaded from backbone.body.layers.2.blocks.5.attn.proj.weight                                of shape (384, 384)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.qkv.bias                                   loaded from backbone.body.layers.2.blocks.5.attn.qkv.bias                                   of shape (1152,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.qkv.weight                                 loaded from backbone.body.layers.2.blocks.5.attn.qkv.weight                                 of shape (1152, 384)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.relative_position_bias_table               loaded from backbone.body.layers.2.blocks.5.attn.relative_position_bias_table               of shape (169, 12)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.attn.relative_position_index                    loaded from backbone.body.layers.2.blocks.5.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.mlp.fc1.bias                                    loaded from backbone.body.layers.2.blocks.5.mlp.fc1.bias                                    of shape (1536,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.mlp.fc1.weight                                  loaded from backbone.body.layers.2.blocks.5.mlp.fc1.weight                                  of shape (1536, 384)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.mlp.fc2.bias                                    loaded from backbone.body.layers.2.blocks.5.mlp.fc2.bias                                    of shape (384,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.mlp.fc2.weight                                  loaded from backbone.body.layers.2.blocks.5.mlp.fc2.weight                                  of shape (384, 1536)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.norm1.bias                                      loaded from backbone.body.layers.2.blocks.5.norm1.bias                                      of shape (384,)
2024-03-19 10:11:22,268 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.norm1.weight                                    loaded from backbone.body.layers.2.blocks.5.norm1.weight                                    of shape (384,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.norm2.bias                                      loaded from backbone.body.layers.2.blocks.5.norm2.bias                                      of shape (384,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.blocks.5.norm2.weight                                    loaded from backbone.body.layers.2.blocks.5.norm2.weight                                    of shape (384,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.downsample.norm.bias                                     loaded from backbone.body.layers.2.downsample.norm.bias                                     of shape (1536,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.downsample.norm.weight                                   loaded from backbone.body.layers.2.downsample.norm.weight                                   of shape (1536,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.2.downsample.reduction.weight                              loaded from backbone.body.layers.2.downsample.reduction.weight                              of shape (768, 1536)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.proj.bias                                  loaded from backbone.body.layers.3.blocks.0.attn.proj.bias                                  of shape (768,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.proj.weight                                loaded from backbone.body.layers.3.blocks.0.attn.proj.weight                                of shape (768, 768)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.qkv.bias                                   loaded from backbone.body.layers.3.blocks.0.attn.qkv.bias                                   of shape (2304,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.qkv.weight                                 loaded from backbone.body.layers.3.blocks.0.attn.qkv.weight                                 of shape (2304, 768)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.relative_position_bias_table               loaded from backbone.body.layers.3.blocks.0.attn.relative_position_bias_table               of shape (169, 24)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.attn.relative_position_index                    loaded from backbone.body.layers.3.blocks.0.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.mlp.fc1.bias                                    loaded from backbone.body.layers.3.blocks.0.mlp.fc1.bias                                    of shape (3072,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.mlp.fc1.weight                                  loaded from backbone.body.layers.3.blocks.0.mlp.fc1.weight                                  of shape (3072, 768)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.mlp.fc2.bias                                    loaded from backbone.body.layers.3.blocks.0.mlp.fc2.bias                                    of shape (768,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.mlp.fc2.weight                                  loaded from backbone.body.layers.3.blocks.0.mlp.fc2.weight                                  of shape (768, 3072)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.norm1.bias                                      loaded from backbone.body.layers.3.blocks.0.norm1.bias                                      of shape (768,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.norm1.weight                                    loaded from backbone.body.layers.3.blocks.0.norm1.weight                                    of shape (768,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.norm2.bias                                      loaded from backbone.body.layers.3.blocks.0.norm2.bias                                      of shape (768,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.0.norm2.weight                                    loaded from backbone.body.layers.3.blocks.0.norm2.weight                                    of shape (768,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.proj.bias                                  loaded from backbone.body.layers.3.blocks.1.attn.proj.bias                                  of shape (768,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.proj.weight                                loaded from backbone.body.layers.3.blocks.1.attn.proj.weight                                of shape (768, 768)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.qkv.bias                                   loaded from backbone.body.layers.3.blocks.1.attn.qkv.bias                                   of shape (2304,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.qkv.weight                                 loaded from backbone.body.layers.3.blocks.1.attn.qkv.weight                                 of shape (2304, 768)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.relative_position_bias_table               loaded from backbone.body.layers.3.blocks.1.attn.relative_position_bias_table               of shape (169, 24)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.attn.relative_position_index                    loaded from backbone.body.layers.3.blocks.1.attn.relative_position_index                    of shape (49, 49)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.mlp.fc1.bias                                    loaded from backbone.body.layers.3.blocks.1.mlp.fc1.bias                                    of shape (3072,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.mlp.fc1.weight                                  loaded from backbone.body.layers.3.blocks.1.mlp.fc1.weight                                  of shape (3072, 768)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.mlp.fc2.bias                                    loaded from backbone.body.layers.3.blocks.1.mlp.fc2.bias                                    of shape (768,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.mlp.fc2.weight                                  loaded from backbone.body.layers.3.blocks.1.mlp.fc2.weight                                  of shape (768, 3072)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.norm1.bias                                      loaded from backbone.body.layers.3.blocks.1.norm1.bias                                      of shape (768,)
2024-03-19 10:11:22,269 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.norm1.weight                                    loaded from backbone.body.layers.3.blocks.1.norm1.weight                                    of shape (768,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.norm2.bias                                      loaded from backbone.body.layers.3.blocks.1.norm2.bias                                      of shape (768,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.layers.3.blocks.1.norm2.weight                                    loaded from backbone.body.layers.3.blocks.1.norm2.weight                                    of shape (768,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm1.bias                                                        loaded from backbone.body.norm1.bias                                                        of shape (192,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm1.weight                                                      loaded from backbone.body.norm1.weight                                                      of shape (192,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm2.bias                                                        loaded from backbone.body.norm2.bias                                                        of shape (384,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm2.weight                                                      loaded from backbone.body.norm2.weight                                                      of shape (384,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm3.bias                                                        loaded from backbone.body.norm3.bias                                                        of shape (768,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.norm3.weight                                                      loaded from backbone.body.norm3.weight                                                      of shape (768,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.patch_embed.norm.bias                                             loaded from backbone.body.patch_embed.norm.bias                                             of shape (96,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.patch_embed.norm.weight                                           loaded from backbone.body.patch_embed.norm.weight                                           of shape (96,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.patch_embed.proj.bias                                             loaded from backbone.body.patch_embed.proj.bias                                             of shape (96,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.body.patch_embed.proj.weight                                           loaded from backbone.body.patch_embed.proj.weight                                           of shape (96, 3, 4, 4)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner2.bias                                                    loaded from backbone.fpn.fpn_inner2.bias                                                    of shape (256,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner2.weight                                                  loaded from backbone.fpn.fpn_inner2.weight                                                  of shape (256, 192, 1, 1)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner3.bias                                                    loaded from backbone.fpn.fpn_inner3.bias                                                    of shape (256,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner3.weight                                                  loaded from backbone.fpn.fpn_inner3.weight                                                  of shape (256, 384, 1, 1)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner4.bias                                                    loaded from backbone.fpn.fpn_inner4.bias                                                    of shape (256,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_inner4.weight                                                  loaded from backbone.fpn.fpn_inner4.weight                                                  of shape (256, 768, 1, 1)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer2.bias                                                    loaded from backbone.fpn.fpn_layer2.bias                                                    of shape (256,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer2.weight                                                  loaded from backbone.fpn.fpn_layer2.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer3.bias                                                    loaded from backbone.fpn.fpn_layer3.bias                                                    of shape (256,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer3.weight                                                  loaded from backbone.fpn.fpn_layer3.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer4.bias                                                    loaded from backbone.fpn.fpn_layer4.bias                                                    of shape (256,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.fpn_layer4.weight                                                  loaded from backbone.fpn.fpn_layer4.weight                                                  of shape (256, 256, 3, 3)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.top_blocks.p6.bias                                                 loaded from backbone.fpn.top_blocks.p6.bias                                                 of shape (256,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.top_blocks.p6.weight                                               loaded from backbone.fpn.top_blocks.p6.weight                                               of shape (256, 256, 3, 3)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.top_blocks.p7.bias                                                 loaded from backbone.fpn.top_blocks.p7.bias                                                 of shape (256,)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.backbone.fpn.top_blocks.p7.weight                                               loaded from backbone.fpn.top_blocks.p7.weight                                               of shape (256, 256, 3, 3)
2024-03-19 10:11:22,270 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.embeddings.LayerNorm.bias                          loaded from language_backbone.body.model.embeddings.LayerNorm.bias                          of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.embeddings.LayerNorm.weight                        loaded from language_backbone.body.model.embeddings.LayerNorm.weight                        of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.embeddings.position_embeddings.weight              loaded from language_backbone.body.model.embeddings.position_embeddings.weight              of shape (512, 768)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.embeddings.token_type_embeddings.weight            loaded from language_backbone.body.model.embeddings.token_type_embeddings.weight            of shape (2, 768)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.embeddings.word_embeddings.weight                  loaded from language_backbone.body.model.embeddings.word_embeddings.weight                  of shape (30522, 768)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.0.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.0.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.0.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.0.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.0.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.0.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.0.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.0.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.0.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.0.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.0.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.0.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.0.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.0.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.0.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.1.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.1.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.1.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.1.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.1.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.1.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.1.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.1.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,271 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.1.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.1.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.1.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.1.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.1.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.1.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.1.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.bias   loaded from language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.bias   of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.weight loaded from language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.weight of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.output.dense.bias       loaded from language_backbone.body.model.encoder.layer.10.attention.output.dense.bias       of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.output.dense.weight     loaded from language_backbone.body.model.encoder.layer.10.attention.output.dense.weight     of shape (768, 768)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.key.bias           loaded from language_backbone.body.model.encoder.layer.10.attention.self.key.bias           of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.key.weight         loaded from language_backbone.body.model.encoder.layer.10.attention.self.key.weight         of shape (768, 768)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.query.bias         loaded from language_backbone.body.model.encoder.layer.10.attention.self.query.bias         of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.query.weight       loaded from language_backbone.body.model.encoder.layer.10.attention.self.query.weight       of shape (768, 768)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.value.bias         loaded from language_backbone.body.model.encoder.layer.10.attention.self.value.bias         of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.attention.self.value.weight       loaded from language_backbone.body.model.encoder.layer.10.attention.self.value.weight       of shape (768, 768)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.intermediate.dense.bias           loaded from language_backbone.body.model.encoder.layer.10.intermediate.dense.bias           of shape (3072,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.intermediate.dense.weight         loaded from language_backbone.body.model.encoder.layer.10.intermediate.dense.weight         of shape (3072, 768)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.output.LayerNorm.bias             loaded from language_backbone.body.model.encoder.layer.10.output.LayerNorm.bias             of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.output.LayerNorm.weight           loaded from language_backbone.body.model.encoder.layer.10.output.LayerNorm.weight           of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.output.dense.bias                 loaded from language_backbone.body.model.encoder.layer.10.output.dense.bias                 of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.10.output.dense.weight               loaded from language_backbone.body.model.encoder.layer.10.output.dense.weight               of shape (768, 3072)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.bias   loaded from language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.bias   of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.weight loaded from language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.weight of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.output.dense.bias       loaded from language_backbone.body.model.encoder.layer.11.attention.output.dense.bias       of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.output.dense.weight     loaded from language_backbone.body.model.encoder.layer.11.attention.output.dense.weight     of shape (768, 768)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.key.bias           loaded from language_backbone.body.model.encoder.layer.11.attention.self.key.bias           of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.key.weight         loaded from language_backbone.body.model.encoder.layer.11.attention.self.key.weight         of shape (768, 768)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.query.bias         loaded from language_backbone.body.model.encoder.layer.11.attention.self.query.bias         of shape (768,)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.query.weight       loaded from language_backbone.body.model.encoder.layer.11.attention.self.query.weight       of shape (768, 768)
2024-03-19 10:11:22,272 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.value.bias         loaded from language_backbone.body.model.encoder.layer.11.attention.self.value.bias         of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.attention.self.value.weight       loaded from language_backbone.body.model.encoder.layer.11.attention.self.value.weight       of shape (768, 768)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.intermediate.dense.bias           loaded from language_backbone.body.model.encoder.layer.11.intermediate.dense.bias           of shape (3072,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.intermediate.dense.weight         loaded from language_backbone.body.model.encoder.layer.11.intermediate.dense.weight         of shape (3072, 768)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.output.LayerNorm.bias             loaded from language_backbone.body.model.encoder.layer.11.output.LayerNorm.bias             of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.output.LayerNorm.weight           loaded from language_backbone.body.model.encoder.layer.11.output.LayerNorm.weight           of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.output.dense.bias                 loaded from language_backbone.body.model.encoder.layer.11.output.dense.bias                 of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.11.output.dense.weight               loaded from language_backbone.body.model.encoder.layer.11.output.dense.weight               of shape (768, 3072)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.2.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.2.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.2.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.2.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.2.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.2.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.2.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.2.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.2.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.2.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.2.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.2.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.2.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.2.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.2.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.3.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.3.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.3.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.3.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.3.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,273 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.3.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.3.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.3.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.3.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.3.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.3.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.3.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.3.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.3.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.3.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.4.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.4.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.4.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.4.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.4.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.4.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.4.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.4.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.4.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.4.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.4.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.4.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.4.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.4.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.4.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.5.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.5.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.5.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,274 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.5.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.5.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.5.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.5.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.5.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.5.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.5.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.5.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.5.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.5.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.5.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.5.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.6.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.6.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.6.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.6.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.6.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.6.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.6.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.6.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.6.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.6.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.6.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.6.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.6.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.6.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.6.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.7.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.7.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,275 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.7.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.7.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.7.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.7.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.7.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.7.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.7.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.7.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.7.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.7.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.7.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.7.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.7.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.8.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.8.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.8.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.8.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.8.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.8.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.8.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.8.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.8.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.8.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.8.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.8.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.8.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.8.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.8.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.bias    loaded from language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.weight  loaded from language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.output.dense.bias        loaded from language_backbone.body.model.encoder.layer.9.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,276 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.output.dense.weight      loaded from language_backbone.body.model.encoder.layer.9.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.key.bias            loaded from language_backbone.body.model.encoder.layer.9.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.key.weight          loaded from language_backbone.body.model.encoder.layer.9.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.query.bias          loaded from language_backbone.body.model.encoder.layer.9.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.query.weight        loaded from language_backbone.body.model.encoder.layer.9.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.value.bias          loaded from language_backbone.body.model.encoder.layer.9.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.attention.self.value.weight        loaded from language_backbone.body.model.encoder.layer.9.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.intermediate.dense.bias            loaded from language_backbone.body.model.encoder.layer.9.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.intermediate.dense.weight          loaded from language_backbone.body.model.encoder.layer.9.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.output.LayerNorm.bias              loaded from language_backbone.body.model.encoder.layer.9.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.output.LayerNorm.weight            loaded from language_backbone.body.model.encoder.layer.9.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.output.dense.bias                  loaded from language_backbone.body.model.encoder.layer.9.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: encoder.language_backbone.body.model.encoder.layer.9.output.dense.weight                loaded from language_backbone.body.model.encoder.layer.9.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.embeddings.LayerNorm.bias                                  loaded from language_backbone.body.model.embeddings.LayerNorm.bias                          of shape (768,)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.embeddings.LayerNorm.weight                                loaded from language_backbone.body.model.embeddings.LayerNorm.weight                        of shape (768,)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.embeddings.position_embeddings.weight                      loaded from language_backbone.body.model.embeddings.position_embeddings.weight              of shape (512, 768)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.embeddings.token_type_embeddings.weight                    loaded from language_backbone.body.model.embeddings.token_type_embeddings.weight            of shape (2, 768)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.embeddings.word_embeddings.weight                          loaded from language_backbone.body.model.embeddings.word_embeddings.weight                  of shape (30522, 768)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.0.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.0.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.0.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.0.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.0.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.0.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.0.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.0.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,277 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.0.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.0.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.0.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.0.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.0.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.0.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.0.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.0.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.1.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.1.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.1.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.1.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.1.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.1.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.1.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.1.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.1.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.1.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.1.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.1.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.1.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.1.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.1.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.1.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.bias           loaded from language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.bias   of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.weight         loaded from language_backbone.body.model.encoder.layer.10.attention.output.LayerNorm.weight of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.output.dense.bias               loaded from language_backbone.body.model.encoder.layer.10.attention.output.dense.bias       of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.output.dense.weight             loaded from language_backbone.body.model.encoder.layer.10.attention.output.dense.weight     of shape (768, 768)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.key.bias                   loaded from language_backbone.body.model.encoder.layer.10.attention.self.key.bias           of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.key.weight                 loaded from language_backbone.body.model.encoder.layer.10.attention.self.key.weight         of shape (768, 768)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.query.bias                 loaded from language_backbone.body.model.encoder.layer.10.attention.self.query.bias         of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.query.weight               loaded from language_backbone.body.model.encoder.layer.10.attention.self.query.weight       of shape (768, 768)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.value.bias                 loaded from language_backbone.body.model.encoder.layer.10.attention.self.value.bias         of shape (768,)
2024-03-19 10:11:22,278 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.attention.self.value.weight               loaded from language_backbone.body.model.encoder.layer.10.attention.self.value.weight       of shape (768, 768)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.intermediate.dense.bias                   loaded from language_backbone.body.model.encoder.layer.10.intermediate.dense.bias           of shape (3072,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.intermediate.dense.weight                 loaded from language_backbone.body.model.encoder.layer.10.intermediate.dense.weight         of shape (3072, 768)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.output.LayerNorm.bias                     loaded from language_backbone.body.model.encoder.layer.10.output.LayerNorm.bias             of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.output.LayerNorm.weight                   loaded from language_backbone.body.model.encoder.layer.10.output.LayerNorm.weight           of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.output.dense.bias                         loaded from language_backbone.body.model.encoder.layer.10.output.dense.bias                 of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.10.output.dense.weight                       loaded from language_backbone.body.model.encoder.layer.10.output.dense.weight               of shape (768, 3072)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.bias           loaded from language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.bias   of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.weight         loaded from language_backbone.body.model.encoder.layer.11.attention.output.LayerNorm.weight of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.output.dense.bias               loaded from language_backbone.body.model.encoder.layer.11.attention.output.dense.bias       of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.output.dense.weight             loaded from language_backbone.body.model.encoder.layer.11.attention.output.dense.weight     of shape (768, 768)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.key.bias                   loaded from language_backbone.body.model.encoder.layer.11.attention.self.key.bias           of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.key.weight                 loaded from language_backbone.body.model.encoder.layer.11.attention.self.key.weight         of shape (768, 768)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.query.bias                 loaded from language_backbone.body.model.encoder.layer.11.attention.self.query.bias         of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.query.weight               loaded from language_backbone.body.model.encoder.layer.11.attention.self.query.weight       of shape (768, 768)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.value.bias                 loaded from language_backbone.body.model.encoder.layer.11.attention.self.value.bias         of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.attention.self.value.weight               loaded from language_backbone.body.model.encoder.layer.11.attention.self.value.weight       of shape (768, 768)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.intermediate.dense.bias                   loaded from language_backbone.body.model.encoder.layer.11.intermediate.dense.bias           of shape (3072,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.intermediate.dense.weight                 loaded from language_backbone.body.model.encoder.layer.11.intermediate.dense.weight         of shape (3072, 768)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.output.LayerNorm.bias                     loaded from language_backbone.body.model.encoder.layer.11.output.LayerNorm.bias             of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.output.LayerNorm.weight                   loaded from language_backbone.body.model.encoder.layer.11.output.LayerNorm.weight           of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.output.dense.bias                         loaded from language_backbone.body.model.encoder.layer.11.output.dense.bias                 of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.11.output.dense.weight                       loaded from language_backbone.body.model.encoder.layer.11.output.dense.weight               of shape (768, 3072)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.2.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.2.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.2.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.2.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.2.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.2.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.2.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,279 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.2.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.2.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.2.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.2.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.2.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.2.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.2.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.2.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.2.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.3.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.3.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.3.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.3.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.3.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.3.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.3.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.3.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.3.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.3.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.3.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.3.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.3.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.3.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.3.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.3.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.4.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.4.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.4.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.4.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.4.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.4.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,280 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.4.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.4.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.4.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.4.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.4.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.4.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.4.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.4.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.4.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.4.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.5.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.5.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.5.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.5.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.5.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.5.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.5.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.5.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.5.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.5.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.5.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.5.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.5.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.5.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.5.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.5.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.6.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.6.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.6.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.6.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.6.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.6.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,281 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.6.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.6.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.6.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.6.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.6.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.6.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.6.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.6.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.6.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.6.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.7.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.7.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.7.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.7.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.7.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.7.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.7.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.7.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.7.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.7.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.7.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.7.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.7.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.7.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.7.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.7.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.8.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.8.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.8.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.8.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.8.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,282 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.8.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.8.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.8.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.8.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.8.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.8.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.8.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.8.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.8.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.8.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.8.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.bias            loaded from language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.bias    of shape (768,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.weight          loaded from language_backbone.body.model.encoder.layer.9.attention.output.LayerNorm.weight  of shape (768,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.output.dense.bias                loaded from language_backbone.body.model.encoder.layer.9.attention.output.dense.bias        of shape (768,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.output.dense.weight              loaded from language_backbone.body.model.encoder.layer.9.attention.output.dense.weight      of shape (768, 768)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.key.bias                    loaded from language_backbone.body.model.encoder.layer.9.attention.self.key.bias            of shape (768,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.key.weight                  loaded from language_backbone.body.model.encoder.layer.9.attention.self.key.weight          of shape (768, 768)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.query.bias                  loaded from language_backbone.body.model.encoder.layer.9.attention.self.query.bias          of shape (768,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.query.weight                loaded from language_backbone.body.model.encoder.layer.9.attention.self.query.weight        of shape (768, 768)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.value.bias                  loaded from language_backbone.body.model.encoder.layer.9.attention.self.value.bias          of shape (768,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.attention.self.value.weight                loaded from language_backbone.body.model.encoder.layer.9.attention.self.value.weight        of shape (768, 768)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.intermediate.dense.bias                    loaded from language_backbone.body.model.encoder.layer.9.intermediate.dense.bias            of shape (3072,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.intermediate.dense.weight                  loaded from language_backbone.body.model.encoder.layer.9.intermediate.dense.weight          of shape (3072, 768)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.output.LayerNorm.bias                      loaded from language_backbone.body.model.encoder.layer.9.output.LayerNorm.bias              of shape (768,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.output.LayerNorm.weight                    loaded from language_backbone.body.model.encoder.layer.9.output.LayerNorm.weight            of shape (768,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.output.dense.bias                          loaded from language_backbone.body.model.encoder.layer.9.output.dense.bias                  of shape (768,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: language_backbone.body.model.encoder.layer.9.output.dense.weight                        loaded from language_backbone.body.model.encoder.layer.9.output.dense.weight                of shape (768, 3072)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0                                                     loaded from rpn.anchor_generator.cell_anchors.0                                             of shape (1, 4)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1                                                     loaded from rpn.anchor_generator.cell_anchors.1                                             of shape (1, 4)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2                                                     loaded from rpn.anchor_generator.cell_anchors.2                                             of shape (1, 4)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3                                                     loaded from rpn.anchor_generator.cell_anchors.3                                             of shape (1, 4)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4                                                     loaded from rpn.anchor_generator.cell_anchors.4                                             of shape (1, 4)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                                                                 loaded from rpn.head.bbox_pred.bias                                                         of shape (4,)
2024-03-19 10:11:22,283 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                                                               loaded from rpn.head.bbox_pred.weight                                                       of shape (4, 256, 1, 1)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bias0                                                                          loaded from rpn.head.bias0                                                                  of shape (1,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bias_lang                                                                      loaded from rpn.head.bias_lang                                                              of shape (768,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.centerness.bias                                                                loaded from rpn.head.centerness.bias                                                        of shape (1,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.centerness.weight                                                              loaded from rpn.head.centerness.weight                                                      of shape (1, 256, 1, 1)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                                                                loaded from rpn.head.cls_logits.bias                                                        of shape (80,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                                                              loaded from rpn.head.cls_logits.weight                                                      of shape (80, 256, 1, 1)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dot_product_projection_text.bias                                               loaded from rpn.head.dot_product_projection_text.bias                                       of shape (256,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dot_product_projection_text.weight                                             loaded from rpn.head.dot_product_projection_text.weight                                     of shape (256, 768)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.0.AttnConv.1.bias                                         of shape (1,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.0.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.0.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.0.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.0.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.0.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.0.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.0.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.0.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.0.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.0.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.0.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.0.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.0.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.offset.bias                                                     loaded from rpn.head.dyhead_tower.0.offset.bias                                             of shape (27,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.offset.weight                                                   loaded from rpn.head.dyhead_tower.0.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.0.relu.fc.0.bias                                          of shape (64,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.0.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.0.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.0.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.0.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.1.AttnConv.1.bias                                         of shape (1,)
2024-03-19 10:11:22,284 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.1.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.1.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.1.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.1.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.1.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.1.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.1.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.1.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.1.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.1.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.1.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.1.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.1.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.offset.bias                                                     loaded from rpn.head.dyhead_tower.1.offset.bias                                             of shape (27,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.offset.weight                                                   loaded from rpn.head.dyhead_tower.1.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.1.relu.fc.0.bias                                          of shape (64,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.1.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.1.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.1.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.1.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.2.AttnConv.1.bias                                         of shape (1,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.2.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.2.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.2.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.2.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.2.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.2.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.2.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.2.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.2.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.2.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.2.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,285 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.2.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.2.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.offset.bias                                                     loaded from rpn.head.dyhead_tower.2.offset.bias                                             of shape (27,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.offset.weight                                                   loaded from rpn.head.dyhead_tower.2.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.2.relu.fc.0.bias                                          of shape (64,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.2.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.2.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.2.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.2.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.3.AttnConv.1.bias                                         of shape (1,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.3.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.3.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.3.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.3.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.3.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.3.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.3.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.3.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.3.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.3.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.3.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.3.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.3.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.offset.bias                                                     loaded from rpn.head.dyhead_tower.3.offset.bias                                             of shape (27,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.offset.weight                                                   loaded from rpn.head.dyhead_tower.3.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.3.relu.fc.0.bias                                          of shape (64,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.3.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.3.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.3.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.3.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.4.AttnConv.1.bias                                         of shape (1,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.4.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.4.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,286 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.4.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.4.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.4.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.4.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.4.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.4.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.4.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.4.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.4.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.4.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.4.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.offset.bias                                                     loaded from rpn.head.dyhead_tower.4.offset.bias                                             of shape (27,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.offset.weight                                                   loaded from rpn.head.dyhead_tower.4.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.4.relu.fc.0.bias                                          of shape (64,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.4.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.4.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.4.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.4.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.AttnConv.1.bias                                                 loaded from rpn.head.dyhead_tower.5.AttnConv.1.bias                                         of shape (1,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.AttnConv.1.weight                                               loaded from rpn.head.dyhead_tower.5.AttnConv.1.weight                                       of shape (1, 256, 1, 1)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.0.bn.bias                                                loaded from rpn.head.dyhead_tower.5.DyConv.0.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.0.bn.weight                                              loaded from rpn.head.dyhead_tower.5.DyConv.0.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.0.conv.bias                                              loaded from rpn.head.dyhead_tower.5.DyConv.0.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.0.conv.weight                                            loaded from rpn.head.dyhead_tower.5.DyConv.0.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.1.bn.bias                                                loaded from rpn.head.dyhead_tower.5.DyConv.1.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.1.bn.weight                                              loaded from rpn.head.dyhead_tower.5.DyConv.1.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.1.conv.bias                                              loaded from rpn.head.dyhead_tower.5.DyConv.1.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.1.conv.weight                                            loaded from rpn.head.dyhead_tower.5.DyConv.1.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.2.bn.bias                                                loaded from rpn.head.dyhead_tower.5.DyConv.2.bn.bias                                        of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.2.bn.weight                                              loaded from rpn.head.dyhead_tower.5.DyConv.2.bn.weight                                      of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.2.conv.bias                                              loaded from rpn.head.dyhead_tower.5.DyConv.2.conv.bias                                      of shape (256,)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.DyConv.2.conv.weight                                            loaded from rpn.head.dyhead_tower.5.DyConv.2.conv.weight                                    of shape (256, 256, 3, 3)
2024-03-19 10:11:22,287 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.offset.bias                                                     loaded from rpn.head.dyhead_tower.5.offset.bias                                             of shape (27,)
2024-03-19 10:11:22,288 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.offset.weight                                                   loaded from rpn.head.dyhead_tower.5.offset.weight                                           of shape (27, 256, 3, 3)
2024-03-19 10:11:22,288 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.relu.fc.0.bias                                                  loaded from rpn.head.dyhead_tower.5.relu.fc.0.bias                                          of shape (64,)
2024-03-19 10:11:22,288 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.relu.fc.0.weight                                                loaded from rpn.head.dyhead_tower.5.relu.fc.0.weight                                        of shape (64, 256)
2024-03-19 10:11:22,288 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.relu.fc.2.bias                                                  loaded from rpn.head.dyhead_tower.5.relu.fc.2.bias                                          of shape (1024,)
2024-03-19 10:11:22,288 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.dyhead_tower.5.relu.fc.2.weight                                                loaded from rpn.head.dyhead_tower.5.relu.fc.2.weight                                        of shape (1024, 64)
2024-03-19 10:11:22,288 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.log_scale                                                                      loaded from rpn.head.log_scale                                                              of shape (1,)
2024-03-19 10:11:22,288 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.scales.0.scale                                                                 loaded from rpn.head.scales.0.scale                                                         of shape (1,)
2024-03-19 10:11:22,288 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.scales.1.scale                                                                 loaded from rpn.head.scales.1.scale                                                         of shape (1,)
2024-03-19 10:11:22,288 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.scales.2.scale                                                                 loaded from rpn.head.scales.2.scale                                                         of shape (1,)
2024-03-19 10:11:22,288 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.scales.3.scale                                                                 loaded from rpn.head.scales.3.scale                                                         of shape (1,)
2024-03-19 10:11:22,288 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.scales.4.scale                                                                 loaded from rpn.head.scales.4.scale                                                         of shape (1,)
2024-03-19 10:11:22,292 maskrcnn_benchmark.utils.model_serialization WARNING: Some layers unloaded with pre-trained weight: 
encoder.embeddings.LayerNorm.{bias, weight}
encoder.embeddings.position_embeddings.weight
encoder.embeddings.token_type_embeddings.weight
encoder.embeddings.word_embeddings.weight
encoder.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.0.attention.output.dense.{bias, weight}
encoder.encoder.layer.0.attention.self.key.{bias, weight}
encoder.encoder.layer.0.attention.self.query.{bias, weight}
encoder.encoder.layer.0.attention.self.value.{bias, weight}
encoder.encoder.layer.0.intermediate.dense.{bias, weight}
encoder.encoder.layer.0.output.LayerNorm.{bias, weight}
encoder.encoder.layer.0.output.dense.{bias, weight}
encoder.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.1.attention.output.dense.{bias, weight}
encoder.encoder.layer.1.attention.self.key.{bias, weight}
encoder.encoder.layer.1.attention.self.query.{bias, weight}
encoder.encoder.layer.1.attention.self.value.{bias, weight}
encoder.encoder.layer.1.intermediate.dense.{bias, weight}
encoder.encoder.layer.1.output.LayerNorm.{bias, weight}
encoder.encoder.layer.1.output.dense.{bias, weight}
encoder.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.10.attention.output.dense.{bias, weight}
encoder.encoder.layer.10.attention.self.key.{bias, weight}
encoder.encoder.layer.10.attention.self.query.{bias, weight}
encoder.encoder.layer.10.attention.self.value.{bias, weight}
encoder.encoder.layer.10.intermediate.dense.{bias, weight}
encoder.encoder.layer.10.output.LayerNorm.{bias, weight}
encoder.encoder.layer.10.output.dense.{bias, weight}
encoder.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.11.attention.output.dense.{bias, weight}
encoder.encoder.layer.11.attention.self.key.{bias, weight}
encoder.encoder.layer.11.attention.self.query.{bias, weight}
encoder.encoder.layer.11.attention.self.value.{bias, weight}
encoder.encoder.layer.11.intermediate.dense.{bias, weight}
encoder.encoder.layer.11.output.LayerNorm.{bias, weight}
encoder.encoder.layer.11.output.dense.{bias, weight}
encoder.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.2.attention.output.dense.{bias, weight}
encoder.encoder.layer.2.attention.self.key.{bias, weight}
encoder.encoder.layer.2.attention.self.query.{bias, weight}
encoder.encoder.layer.2.attention.self.value.{bias, weight}
encoder.encoder.layer.2.intermediate.dense.{bias, weight}
encoder.encoder.layer.2.output.LayerNorm.{bias, weight}
encoder.encoder.layer.2.output.dense.{bias, weight}
encoder.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.3.attention.output.dense.{bias, weight}
encoder.encoder.layer.3.attention.self.key.{bias, weight}
encoder.encoder.layer.3.attention.self.query.{bias, weight}
encoder.encoder.layer.3.attention.self.value.{bias, weight}
encoder.encoder.layer.3.intermediate.dense.{bias, weight}
encoder.encoder.layer.3.output.LayerNorm.{bias, weight}
encoder.encoder.layer.3.output.dense.{bias, weight}
encoder.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.4.attention.output.dense.{bias, weight}
encoder.encoder.layer.4.attention.self.key.{bias, weight}
encoder.encoder.layer.4.attention.self.query.{bias, weight}
encoder.encoder.layer.4.attention.self.value.{bias, weight}
encoder.encoder.layer.4.intermediate.dense.{bias, weight}
encoder.encoder.layer.4.output.LayerNorm.{bias, weight}
encoder.encoder.layer.4.output.dense.{bias, weight}
encoder.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.5.attention.output.dense.{bias, weight}
encoder.encoder.layer.5.attention.self.key.{bias, weight}
encoder.encoder.layer.5.attention.self.query.{bias, weight}
encoder.encoder.layer.5.attention.self.value.{bias, weight}
encoder.encoder.layer.5.intermediate.dense.{bias, weight}
encoder.encoder.layer.5.output.LayerNorm.{bias, weight}
encoder.encoder.layer.5.output.dense.{bias, weight}
encoder.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.6.attention.output.dense.{bias, weight}
encoder.encoder.layer.6.attention.self.key.{bias, weight}
encoder.encoder.layer.6.attention.self.query.{bias, weight}
encoder.encoder.layer.6.attention.self.value.{bias, weight}
encoder.encoder.layer.6.intermediate.dense.{bias, weight}
encoder.encoder.layer.6.output.LayerNorm.{bias, weight}
encoder.encoder.layer.6.output.dense.{bias, weight}
encoder.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.7.attention.output.dense.{bias, weight}
encoder.encoder.layer.7.attention.self.key.{bias, weight}
encoder.encoder.layer.7.attention.self.query.{bias, weight}
encoder.encoder.layer.7.attention.self.value.{bias, weight}
encoder.encoder.layer.7.intermediate.dense.{bias, weight}
encoder.encoder.layer.7.output.LayerNorm.{bias, weight}
encoder.encoder.layer.7.output.dense.{bias, weight}
encoder.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.8.attention.output.dense.{bias, weight}
encoder.encoder.layer.8.attention.self.key.{bias, weight}
encoder.encoder.layer.8.attention.self.query.{bias, weight}
encoder.encoder.layer.8.attention.self.value.{bias, weight}
encoder.encoder.layer.8.intermediate.dense.{bias, weight}
encoder.encoder.layer.8.output.LayerNorm.{bias, weight}
encoder.encoder.layer.8.output.dense.{bias, weight}
encoder.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
encoder.encoder.layer.9.attention.output.dense.{bias, weight}
encoder.encoder.layer.9.attention.self.key.{bias, weight}
encoder.encoder.layer.9.attention.self.query.{bias, weight}
encoder.encoder.layer.9.attention.self.value.{bias, weight}
encoder.encoder.layer.9.intermediate.dense.{bias, weight}
encoder.encoder.layer.9.output.LayerNorm.{bias, weight}
encoder.encoder.layer.9.output.dense.{bias, weight}
encoder.fpn.fpn_inner2.{bias, weight}
encoder.fpn.fpn_inner3.{bias, weight}
encoder.fpn.fpn_inner4.{bias, weight}
encoder.fpn.fpn_layer2.{bias, weight}
encoder.fpn.fpn_layer3.{bias, weight}
encoder.fpn.fpn_layer4.{bias, weight}
encoder.fpn.top_blocks.p6.{bias, weight}
encoder.fpn.top_blocks.p7.{bias, weight}
encoder.language_backbone.body.embeddings.LayerNorm.{bias, weight}
encoder.language_backbone.body.embeddings.position_embeddings.weight
encoder.language_backbone.body.embeddings.token_type_embeddings.weight
encoder.language_backbone.body.embeddings.word_embeddings.weight
encoder.language_backbone.body.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.language_backbone.body.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.0.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.1.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.10.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.11.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.2.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.3.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.4.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.5.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.6.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.7.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.8.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.attention.output.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.attention.self.key.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.attention.self.query.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.attention.self.value.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.intermediate.dense.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.output.LayerNorm.{bias, weight}
encoder.language_backbone.body.encoder.layer.9.output.dense.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_backbone.body.model.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.language_backbone.body.model.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.embeddings.LayerNorm.{bias, weight}
encoder.language_encoder.embeddings.position_embeddings.weight
encoder.language_encoder.embeddings.token_type_embeddings.weight
encoder.language_encoder.embeddings.word_embeddings.weight
encoder.language_encoder.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.language_encoder.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.0.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.0.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.0.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.0.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.0.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.0.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.0.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.1.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.1.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.1.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.1.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.1.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.1.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.1.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.10.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.10.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.10.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.10.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.10.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.10.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.10.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.11.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.11.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.11.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.11.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.11.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.11.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.11.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.2.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.2.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.2.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.2.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.2.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.2.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.2.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.3.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.3.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.3.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.3.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.3.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.3.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.3.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.4.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.4.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.4.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.4.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.4.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.4.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.4.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.5.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.5.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.5.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.5.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.5.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.5.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.5.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.6.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.6.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.6.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.6.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.6.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.6.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.6.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.7.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.7.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.7.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.7.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.7.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.7.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.7.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.8.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.8.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.8.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.8.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.8.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.8.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.8.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.9.attention.output.dense.{bias, weight}
encoder.language_encoder.encoder.layer.9.attention.self.key.{bias, weight}
encoder.language_encoder.encoder.layer.9.attention.self.query.{bias, weight}
encoder.language_encoder.encoder.layer.9.attention.self.value.{bias, weight}
encoder.language_encoder.encoder.layer.9.intermediate.dense.{bias, weight}
encoder.language_encoder.encoder.layer.9.output.LayerNorm.{bias, weight}
encoder.language_encoder.encoder.layer.9.output.dense.{bias, weight}
encoder.language_encoder.model.embeddings.LayerNorm.{bias, weight}
encoder.language_encoder.model.embeddings.position_embeddings.weight
encoder.language_encoder.model.embeddings.token_type_embeddings.weight
encoder.language_encoder.model.embeddings.word_embeddings.weight
encoder.language_encoder.model.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.language_encoder.model.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.language_encoder.model.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.0.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.1.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.10.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.11.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.2.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.3.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.4.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.5.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.6.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.7.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.8.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.attention.output.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.attention.self.key.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.attention.self.query.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.attention.self.value.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.intermediate.dense.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.output.LayerNorm.{bias, weight}
encoder.language_encoder.model.encoder.layer.9.output.dense.{bias, weight}
encoder.layers.0.blocks.0.attn.proj.{bias, weight}
encoder.layers.0.blocks.0.attn.qkv.{bias, weight}
encoder.layers.0.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.0.blocks.0.mlp.fc1.{bias, weight}
encoder.layers.0.blocks.0.mlp.fc2.{bias, weight}
encoder.layers.0.blocks.0.norm1.{bias, weight}
encoder.layers.0.blocks.0.norm2.{bias, weight}
encoder.layers.0.blocks.1.attn.proj.{bias, weight}
encoder.layers.0.blocks.1.attn.qkv.{bias, weight}
encoder.layers.0.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.0.blocks.1.mlp.fc1.{bias, weight}
encoder.layers.0.blocks.1.mlp.fc2.{bias, weight}
encoder.layers.0.blocks.1.norm1.{bias, weight}
encoder.layers.0.blocks.1.norm2.{bias, weight}
encoder.layers.0.downsample.norm.{bias, weight}
encoder.layers.0.downsample.reduction.weight
encoder.layers.1.blocks.0.attn.proj.{bias, weight}
encoder.layers.1.blocks.0.attn.qkv.{bias, weight}
encoder.layers.1.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.1.blocks.0.mlp.fc1.{bias, weight}
encoder.layers.1.blocks.0.mlp.fc2.{bias, weight}
encoder.layers.1.blocks.0.norm1.{bias, weight}
encoder.layers.1.blocks.0.norm2.{bias, weight}
encoder.layers.1.blocks.1.attn.proj.{bias, weight}
encoder.layers.1.blocks.1.attn.qkv.{bias, weight}
encoder.layers.1.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.1.blocks.1.mlp.fc1.{bias, weight}
encoder.layers.1.blocks.1.mlp.fc2.{bias, weight}
encoder.layers.1.blocks.1.norm1.{bias, weight}
encoder.layers.1.blocks.1.norm2.{bias, weight}
encoder.layers.1.downsample.norm.{bias, weight}
encoder.layers.1.downsample.reduction.weight
encoder.layers.2.blocks.0.attn.proj.{bias, weight}
encoder.layers.2.blocks.0.attn.qkv.{bias, weight}
encoder.layers.2.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.0.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.0.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.0.norm1.{bias, weight}
encoder.layers.2.blocks.0.norm2.{bias, weight}
encoder.layers.2.blocks.1.attn.proj.{bias, weight}
encoder.layers.2.blocks.1.attn.qkv.{bias, weight}
encoder.layers.2.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.1.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.1.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.1.norm1.{bias, weight}
encoder.layers.2.blocks.1.norm2.{bias, weight}
encoder.layers.2.blocks.2.attn.proj.{bias, weight}
encoder.layers.2.blocks.2.attn.qkv.{bias, weight}
encoder.layers.2.blocks.2.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.2.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.2.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.2.norm1.{bias, weight}
encoder.layers.2.blocks.2.norm2.{bias, weight}
encoder.layers.2.blocks.3.attn.proj.{bias, weight}
encoder.layers.2.blocks.3.attn.qkv.{bias, weight}
encoder.layers.2.blocks.3.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.3.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.3.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.3.norm1.{bias, weight}
encoder.layers.2.blocks.3.norm2.{bias, weight}
encoder.layers.2.blocks.4.attn.proj.{bias, weight}
encoder.layers.2.blocks.4.attn.qkv.{bias, weight}
encoder.layers.2.blocks.4.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.4.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.4.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.4.norm1.{bias, weight}
encoder.layers.2.blocks.4.norm2.{bias, weight}
encoder.layers.2.blocks.5.attn.proj.{bias, weight}
encoder.layers.2.blocks.5.attn.qkv.{bias, weight}
encoder.layers.2.blocks.5.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.2.blocks.5.mlp.fc1.{bias, weight}
encoder.layers.2.blocks.5.mlp.fc2.{bias, weight}
encoder.layers.2.blocks.5.norm1.{bias, weight}
encoder.layers.2.blocks.5.norm2.{bias, weight}
encoder.layers.2.downsample.norm.{bias, weight}
encoder.layers.2.downsample.reduction.weight
encoder.layers.3.blocks.0.attn.proj.{bias, weight}
encoder.layers.3.blocks.0.attn.qkv.{bias, weight}
encoder.layers.3.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.3.blocks.0.mlp.fc1.{bias, weight}
encoder.layers.3.blocks.0.mlp.fc2.{bias, weight}
encoder.layers.3.blocks.0.norm1.{bias, weight}
encoder.layers.3.blocks.0.norm2.{bias, weight}
encoder.layers.3.blocks.1.attn.proj.{bias, weight}
encoder.layers.3.blocks.1.attn.qkv.{bias, weight}
encoder.layers.3.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.layers.3.blocks.1.mlp.fc1.{bias, weight}
encoder.layers.3.blocks.1.mlp.fc2.{bias, weight}
encoder.layers.3.blocks.1.norm1.{bias, weight}
encoder.layers.3.blocks.1.norm2.{bias, weight}
encoder.model.embeddings.LayerNorm.{bias, weight}
encoder.model.embeddings.position_embeddings.weight
encoder.model.embeddings.token_type_embeddings.weight
encoder.model.embeddings.word_embeddings.weight
encoder.model.encoder.interactModuleList.0.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.0.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.1.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.1.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.10.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.10.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.11.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.11.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.2.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.2.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.3.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.3.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.4.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.4.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.5.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.5.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.6.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.6.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.7.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.7.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.8.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.8.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.interactModuleList.9.textual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.9.visual_norm.{bias, weight}
encoder.model.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
encoder.model.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.0.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.0.attention.self.key.{bias, weight}
encoder.model.encoder.layer.0.attention.self.query.{bias, weight}
encoder.model.encoder.layer.0.attention.self.value.{bias, weight}
encoder.model.encoder.layer.0.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.0.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.0.output.dense.{bias, weight}
encoder.model.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.1.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.1.attention.self.key.{bias, weight}
encoder.model.encoder.layer.1.attention.self.query.{bias, weight}
encoder.model.encoder.layer.1.attention.self.value.{bias, weight}
encoder.model.encoder.layer.1.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.1.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.1.output.dense.{bias, weight}
encoder.model.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.10.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.10.attention.self.key.{bias, weight}
encoder.model.encoder.layer.10.attention.self.query.{bias, weight}
encoder.model.encoder.layer.10.attention.self.value.{bias, weight}
encoder.model.encoder.layer.10.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.10.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.10.output.dense.{bias, weight}
encoder.model.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.11.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.11.attention.self.key.{bias, weight}
encoder.model.encoder.layer.11.attention.self.query.{bias, weight}
encoder.model.encoder.layer.11.attention.self.value.{bias, weight}
encoder.model.encoder.layer.11.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.11.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.11.output.dense.{bias, weight}
encoder.model.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.2.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.2.attention.self.key.{bias, weight}
encoder.model.encoder.layer.2.attention.self.query.{bias, weight}
encoder.model.encoder.layer.2.attention.self.value.{bias, weight}
encoder.model.encoder.layer.2.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.2.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.2.output.dense.{bias, weight}
encoder.model.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.3.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.3.attention.self.key.{bias, weight}
encoder.model.encoder.layer.3.attention.self.query.{bias, weight}
encoder.model.encoder.layer.3.attention.self.value.{bias, weight}
encoder.model.encoder.layer.3.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.3.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.3.output.dense.{bias, weight}
encoder.model.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.4.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.4.attention.self.key.{bias, weight}
encoder.model.encoder.layer.4.attention.self.query.{bias, weight}
encoder.model.encoder.layer.4.attention.self.value.{bias, weight}
encoder.model.encoder.layer.4.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.4.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.4.output.dense.{bias, weight}
encoder.model.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.5.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.5.attention.self.key.{bias, weight}
encoder.model.encoder.layer.5.attention.self.query.{bias, weight}
encoder.model.encoder.layer.5.attention.self.value.{bias, weight}
encoder.model.encoder.layer.5.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.5.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.5.output.dense.{bias, weight}
encoder.model.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.6.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.6.attention.self.key.{bias, weight}
encoder.model.encoder.layer.6.attention.self.query.{bias, weight}
encoder.model.encoder.layer.6.attention.self.value.{bias, weight}
encoder.model.encoder.layer.6.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.6.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.6.output.dense.{bias, weight}
encoder.model.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.7.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.7.attention.self.key.{bias, weight}
encoder.model.encoder.layer.7.attention.self.query.{bias, weight}
encoder.model.encoder.layer.7.attention.self.value.{bias, weight}
encoder.model.encoder.layer.7.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.7.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.7.output.dense.{bias, weight}
encoder.model.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.8.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.8.attention.self.key.{bias, weight}
encoder.model.encoder.layer.8.attention.self.query.{bias, weight}
encoder.model.encoder.layer.8.attention.self.value.{bias, weight}
encoder.model.encoder.layer.8.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.8.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.8.output.dense.{bias, weight}
encoder.model.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.9.attention.output.dense.{bias, weight}
encoder.model.encoder.layer.9.attention.self.key.{bias, weight}
encoder.model.encoder.layer.9.attention.self.query.{bias, weight}
encoder.model.encoder.layer.9.attention.self.value.{bias, weight}
encoder.model.encoder.layer.9.intermediate.dense.{bias, weight}
encoder.model.encoder.layer.9.output.LayerNorm.{bias, weight}
encoder.model.encoder.layer.9.output.dense.{bias, weight}
encoder.norm1.{bias, weight}
encoder.norm2.{bias, weight}
encoder.norm3.{bias, weight}
encoder.patch_embed.norm.{bias, weight}
encoder.patch_embed.proj.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.attn.proj.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.0.blocks.0.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.norm1.{bias, weight}
encoder.visual_encoder.layers.0.blocks.0.norm2.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.attn.proj.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.0.blocks.1.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.norm1.{bias, weight}
encoder.visual_encoder.layers.0.blocks.1.norm2.{bias, weight}
encoder.visual_encoder.layers.0.downsample.norm.{bias, weight}
encoder.visual_encoder.layers.0.downsample.reduction.weight
encoder.visual_encoder.layers.1.blocks.0.attn.proj.{bias, weight}
encoder.visual_encoder.layers.1.blocks.0.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.1.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.1.blocks.0.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.1.blocks.0.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.1.blocks.0.norm1.{bias, weight}
encoder.visual_encoder.layers.1.blocks.0.norm2.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.attn.proj.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.1.blocks.1.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.norm1.{bias, weight}
encoder.visual_encoder.layers.1.blocks.1.norm2.{bias, weight}
encoder.visual_encoder.layers.1.downsample.norm.{bias, weight}
encoder.visual_encoder.layers.1.downsample.reduction.weight
encoder.visual_encoder.layers.2.blocks.0.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.0.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.0.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.0.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.0.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.0.norm2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.1.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.1.norm2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.2.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.2.norm2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.3.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.3.norm2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.4.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.4.norm2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.attn.proj.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.2.blocks.5.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.norm1.{bias, weight}
encoder.visual_encoder.layers.2.blocks.5.norm2.{bias, weight}
encoder.visual_encoder.layers.2.downsample.norm.{bias, weight}
encoder.visual_encoder.layers.2.downsample.reduction.weight
encoder.visual_encoder.layers.3.blocks.0.attn.proj.{bias, weight}
encoder.visual_encoder.layers.3.blocks.0.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.3.blocks.0.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.3.blocks.0.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.3.blocks.0.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.3.blocks.0.norm1.{bias, weight}
encoder.visual_encoder.layers.3.blocks.0.norm2.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.attn.proj.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.attn.qkv.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.attn.{relative_position_bias_table, relative_position_index}
encoder.visual_encoder.layers.3.blocks.1.mlp.fc1.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.mlp.fc2.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.norm1.{bias, weight}
encoder.visual_encoder.layers.3.blocks.1.norm2.{bias, weight}
encoder.visual_encoder.norm1.{bias, weight}
encoder.visual_encoder.norm2.{bias, weight}
encoder.visual_encoder.norm3.{bias, weight}
encoder.visual_encoder.patch_embed.norm.{bias, weight}
encoder.visual_encoder.patch_embed.proj.{bias, weight}
language_backbone.body.embeddings.LayerNorm.{bias, weight}
language_backbone.body.embeddings.position_embeddings.weight
language_backbone.body.embeddings.token_type_embeddings.weight
language_backbone.body.embeddings.word_embeddings.weight
language_backbone.body.encoder.interactModuleList.0.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.0.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.1.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.1.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.10.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.10.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.11.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.11.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.2.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.2.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.3.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.3.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.4.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.4.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.5.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.5.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.6.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.6.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.7.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.7.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.8.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.8.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.interactModuleList.9.textual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.9.visual_norm.{bias, weight}
language_backbone.body.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.encoder.layer.0.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.0.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.0.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.0.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.0.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.0.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.0.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.0.output.dense.{bias, weight}
language_backbone.body.encoder.layer.1.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.1.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.1.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.1.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.1.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.1.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.1.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.1.output.dense.{bias, weight}
language_backbone.body.encoder.layer.10.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.10.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.10.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.10.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.10.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.10.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.10.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.10.output.dense.{bias, weight}
language_backbone.body.encoder.layer.11.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.11.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.11.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.11.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.11.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.11.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.11.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.11.output.dense.{bias, weight}
language_backbone.body.encoder.layer.2.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.2.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.2.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.2.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.2.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.2.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.2.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.2.output.dense.{bias, weight}
language_backbone.body.encoder.layer.3.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.3.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.3.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.3.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.3.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.3.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.3.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.3.output.dense.{bias, weight}
language_backbone.body.encoder.layer.4.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.4.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.4.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.4.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.4.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.4.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.4.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.4.output.dense.{bias, weight}
language_backbone.body.encoder.layer.5.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.5.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.5.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.5.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.5.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.5.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.5.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.5.output.dense.{bias, weight}
language_backbone.body.encoder.layer.6.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.6.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.6.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.6.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.6.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.6.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.6.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.6.output.dense.{bias, weight}
language_backbone.body.encoder.layer.7.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.7.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.7.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.7.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.7.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.7.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.7.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.7.output.dense.{bias, weight}
language_backbone.body.encoder.layer.8.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.8.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.8.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.8.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.8.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.8.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.8.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.8.output.dense.{bias, weight}
language_backbone.body.encoder.layer.9.attention.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.9.attention.output.dense.{bias, weight}
language_backbone.body.encoder.layer.9.attention.self.key.{bias, weight}
language_backbone.body.encoder.layer.9.attention.self.query.{bias, weight}
language_backbone.body.encoder.layer.9.attention.self.value.{bias, weight}
language_backbone.body.encoder.layer.9.intermediate.dense.{bias, weight}
language_backbone.body.encoder.layer.9.output.LayerNorm.{bias, weight}
language_backbone.body.encoder.layer.9.output.dense.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.0.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.0.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.0.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.1.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.1.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.1.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.10.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.10.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.10.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.11.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.11.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.11.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.2.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.2.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.2.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.3.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.3.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.3.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.4.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.4.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.4.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.5.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.5.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.5.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.6.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.6.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.6.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.7.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.7.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.7.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.8.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.8.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.8.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
language_backbone.body.model.encoder.interactModuleList.9.textual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.9.visual_norm.{bias, weight}
language_backbone.body.model.encoder.interactModuleList.9.{dim_1_t2v, dim_1_v2t, dim_2_t2v, dim_2_v2t, dim_3_t2v, dim_3_v2t}
rpn.tunable_linear.weight
textual_prompt.0.{dim_1, dim_2, dim_3}
textual_prompt.1.{dim_1, dim_2, dim_3}
textual_prompt.10.{dim_1, dim_2, dim_3}
textual_prompt.11.{dim_1, dim_2, dim_3}
textual_prompt.2.{dim_1, dim_2, dim_3}
textual_prompt.3.{dim_1, dim_2, dim_3}
textual_prompt.4.{dim_1, dim_2, dim_3}
textual_prompt.5.{dim_1, dim_2, dim_3}
textual_prompt.6.{dim_1, dim_2, dim_3}
textual_prompt.7.{dim_1, dim_2, dim_3}
textual_prompt.8.{dim_1, dim_2, dim_3}
textual_prompt.9.{dim_1, dim_2, dim_3}
visual_prompt.0.{dim_1, dim_2, dim_3}
visual_prompt.1.{dim_1, dim_2, dim_3}
visual_prompt.10.{dim_1, dim_2, dim_3}
visual_prompt.11.{dim_1, dim_2, dim_3}
visual_prompt.2.{dim_1, dim_2, dim_3}
visual_prompt.3.{dim_1, dim_2, dim_3}
visual_prompt.4.{dim_1, dim_2, dim_3}
visual_prompt.5.{dim_1, dim_2, dim_3}
visual_prompt.6.{dim_1, dim_2, dim_3}
visual_prompt.7.{dim_1, dim_2, dim_3}
visual_prompt.8.{dim_1, dim_2, dim_3}
visual_prompt.9.{dim_1, dim_2, dim_3}
Backbone Freeze: True
FPN Freeze: True
RPN Freeze: True
Linear Probe: True
Language Freeze: True
Linear Layer (True Prmopt Tuning): True
High Level Override: language_prompt_v4
2024-03-19 10:11:24,174 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 10:11:24,174 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 10:11:24,174 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 10:11:24,174 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 10:11:24,174 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 10:11:24,174 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 10:11:24,174 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 10:11:24,174 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 10:11:24,174 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 10:11:24,174 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.0.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 10:11:24,175 maskrcnn_benchmark INFO: visual_prompt.0.dim_1 : Not Frozen, param number, 36
2024-03-19 10:11:24,175 maskrcnn_benchmark INFO: visual_prompt.0.dim_2 : Not Frozen, param number, 64
2024-03-19 10:11:24,175 maskrcnn_benchmark INFO: visual_prompt.0.dim_3 : Not Frozen, param number, 384
2024-03-19 10:11:24,176 maskrcnn_benchmark INFO: textual_prompt.0.dim_1 : Not Frozen, param number, 36
2024-03-19 10:11:24,176 maskrcnn_benchmark INFO: textual_prompt.0.dim_2 : Not Frozen, param number, 64
2024-03-19 10:11:24,176 maskrcnn_benchmark INFO: textual_prompt.0.dim_3 : Not Frozen, param number, 3072
2024-03-19 10:11:24,178 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 10:11:24,178 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.77s)
creating index...
index created!
2024-03-19 10:11:27,025 maskrcnn_benchmark INFO: Training on task 0: appliance, total training sample size: 804
refexp_train has the 804 data points RefExpDataset
Number of iterations are 251
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 10:11:27,227 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
2024-03-19 10:11:27,228 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  25
eta: 0:05:08  iter: 20  loss: 2.7296 (2.7381)  loss_reg: 0.2695 (0.2723)  loss_centerness: 0.4841 (0.4829)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7278 (1.7645)  alignment_loss: 0.2185 (0.2184)  time: 1.2159 (1.3350)  data: 0.1284 (0.2297)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:04:31  iter: 40  loss: 2.6761 (2.7341)  loss_reg: 0.2608 (0.2740)  loss_centerness: 0.4826 (0.4839)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7648 (1.7579)  alignment_loss: 0.2181 (0.2183)  time: 1.2112 (1.2850)  data: 0.1252 (0.1794)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:04:04  iter: 60  loss: 2.6094 (2.7148)  loss_reg: 0.2845 (0.2780)  loss_centerness: 0.4847 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6128 (1.7347)  alignment_loss: 0.2176 (0.2180)  time: 1.2490 (1.2786)  data: 0.1259 (0.1625)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:03:36  iter: 80  loss: 2.7990 (2.7356)  loss_reg: 0.2751 (0.2807)  loss_centerness: 0.4843 (0.4847)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7697 (1.7525)  alignment_loss: 0.2171 (0.2178)  time: 1.2065 (1.2657)  data: 0.1204 (0.1536)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:03:10  iter: 100  loss: 2.6358 (2.7156)  loss_reg: 0.2721 (0.2796)  loss_centerness: 0.4805 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6490 (1.7343)  alignment_loss: 0.2166 (0.2176)  time: 1.2560 (1.2615)  data: 0.1316 (0.1495)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:02:44  iter: 120  loss: 2.7160 (2.7224)  loss_reg: 0.2828 (0.2799)  loss_centerness: 0.4837 (0.4841)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7320 (1.7412)  alignment_loss: 0.2160 (0.2173)  time: 1.2389 (1.2588)  data: 0.1272 (0.1469)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:02:19  iter: 140  loss: 2.6721 (2.7166)  loss_reg: 0.2700 (0.2794)  loss_centerness: 0.4834 (0.4840)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6706 (1.7363)  alignment_loss: 0.2155 (0.2170)  time: 1.2105 (1.2570)  data: 0.1197 (0.1470)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:01:54  iter: 160  loss: 2.7105 (2.7184)  loss_reg: 0.2866 (0.2803)  loss_centerness: 0.4855 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7411 (1.7371)  alignment_loss: 0.2148 (0.2168)  time: 1.2197 (1.2547)  data: 0.1277 (0.1448)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:01:29  iter: 180  loss: 2.6970 (2.7177)  loss_reg: 0.2725 (0.2798)  loss_centerness: 0.4826 (0.4841)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7470 (1.7374)  alignment_loss: 0.2141 (0.2165)  time: 1.2576 (1.2571)  data: 0.1274 (0.1462)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:01:04  iter: 200  loss: 2.7034 (2.7105)  loss_reg: 0.2665 (0.2791)  loss_centerness: 0.4819 (0.4840)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6897 (1.7312)  alignment_loss: 0.2134 (0.2162)  time: 1.2153 (1.2554)  data: 0.1266 (0.1445)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:00:38  iter: 220  loss: 2.7412 (2.7120)  loss_reg: 0.2739 (0.2792)  loss_centerness: 0.4823 (0.4840)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7381 (1.7330)  alignment_loss: 0.2126 (0.2158)  time: 1.2037 (1.2545)  data: 0.1164 (0.1450)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:00:13  iter: 240  loss: 2.6172 (2.7072)  loss_reg: 0.2783 (0.2794)  loss_centerness: 0.4849 (0.4841)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6673 (1.7282)  alignment_loss: 0.2117 (0.2155)  time: 1.2423 (1.2535)  data: 0.1265 (0.1438)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:00:00  iter: 251  loss: 2.6048 (2.7066)  loss_reg: 0.2854 (0.2803)  loss_centerness: 0.4855 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6394 (1.7269)  alignment_loss: 0.2111 (0.2153)  time: 1.2472 (1.2535)  data: 0.1271 (0.1432)  lr: 0.009045  wd: 0.000500  max mem: 12611
Evaluating
2024-03-19 10:17:26,504 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 10:17:34,662 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:17:34,665 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 10:17:34,687 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.136986301369863, 0.5068493150684932, 0.5753424657534246] 

2024-03-19 10:17:34,688 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:17:34,688 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:17:34,688 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 0, res: {'refcoco': [0.136986301369863, 0.5068493150684932, 0.5753424657534246], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:17:34,733 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 10:17:35,907 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 10:17:37,657 maskrcnn_benchmark.trainer INFO: Total training time: 0:06:10.415870 (1.4758 s / it)
2024-03-19 10:17:37,667 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 10:17:37,667 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 10:17:37,667 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 10:17:37,667 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 10:17:37,667 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 10:17:37,667 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 10:17:37,668 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 10:17:37,668 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 10:17:37,668 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 10:17:37,668 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.1.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 10:17:37,669 maskrcnn_benchmark INFO: visual_prompt.1.dim_1 : Not Frozen, param number, 36
2024-03-19 10:17:37,669 maskrcnn_benchmark INFO: visual_prompt.1.dim_2 : Not Frozen, param number, 64
2024-03-19 10:17:37,669 maskrcnn_benchmark INFO: visual_prompt.1.dim_3 : Not Frozen, param number, 384
2024-03-19 10:17:37,669 maskrcnn_benchmark INFO: textual_prompt.1.dim_1 : Not Frozen, param number, 36
2024-03-19 10:17:37,669 maskrcnn_benchmark INFO: textual_prompt.1.dim_2 : Not Frozen, param number, 64
2024-03-19 10:17:37,669 maskrcnn_benchmark INFO: textual_prompt.1.dim_3 : Not Frozen, param number, 3072
2024-03-19 10:17:37,671 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 10:17:37,671 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.82s)
creating index...
index created!
2024-03-19 10:17:40,304 maskrcnn_benchmark INFO: Training on task 1: sports, total training sample size: 853
refexp_train has the 853 data points RefExpDataset
Number of iterations are 266
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 10:17:40,508 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 10:17:40,691 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
2024-03-19 10:17:40,833 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  26
eta: 0:05:10  iter: 20  loss: 3.0980 (2.7353)  loss_reg: 0.3158 (0.2826)  loss_centerness: 0.4916 (0.4846)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.9382 (1.7434)  alignment_loss: 0.2081 (0.2148)  time: 1.1427 (1.2633)  data: 0.0135 (0.1523)  task_loss: 0.1342 (0.1342)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:04:45  iter: 40  loss: 3.1069 (2.7574)  loss_reg: 0.3130 (0.2844)  loss_centerness: 0.4865 (0.4849)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.9435 (1.7556)  alignment_loss: 0.2051 (0.2141)  time: 1.1497 (1.2633)  data: 0.0140 (0.1510)  task_loss: 0.1339 (0.1340)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:04:20  iter: 60  loss: 3.0552 (2.7756)  loss_reg: 0.3035 (0.2863)  loss_centerness: 0.4851 (0.4851)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8875 (1.7651)  alignment_loss: 0.2014 (0.2133)  time: 1.1471 (1.2634)  data: 0.0135 (0.1502)  task_loss: 0.1334 (0.1338)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:03:55  iter: 80  loss: 3.0606 (2.7893)  loss_reg: 0.2960 (0.2880)  loss_centerness: 0.4871 (0.4853)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.9384 (1.7714)  alignment_loss: 0.1975 (0.2123)  time: 1.1070 (1.2667)  data: 0.0123 (0.1540)  task_loss: 0.1330 (0.1336)  lr: 0.010000  wd: 0.000500  max mem: 12611
eta: 0:03:30  iter: 100  loss: 2.9517 (2.8000)  loss_reg: 0.2929 (0.2890)  loss_centerness: 0.4899 (0.4856)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8395 (1.7761)  alignment_loss: 0.1934 (0.2112)  time: 1.1453 (1.2657)  data: 0.0133 (0.1529)  task_loss: 0.1325 (0.1334)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:03:04  iter: 120  loss: 3.0263 (2.8121)  loss_reg: 0.3105 (0.2906)  loss_centerness: 0.4882 (0.4858)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.9214 (1.7826)  alignment_loss: 0.1890 (0.2100)  time: 1.1463 (1.2663)  data: 0.0133 (0.1532)  task_loss: 0.1320 (0.1332)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:02:39  iter: 140  loss: 2.8840 (2.8148)  loss_reg: 0.2842 (0.2910)  loss_centerness: 0.4873 (0.4859)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7426 (1.7816)  alignment_loss: 0.1845 (0.2087)  time: 1.1457 (1.2657)  data: 0.0134 (0.1523)  task_loss: 0.1316 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:02:14  iter: 160  loss: 2.7259 (2.8137)  loss_reg: 0.2893 (0.2913)  loss_centerness: 0.4864 (0.4860)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6243 (1.7774)  alignment_loss: 0.1799 (0.2073)  time: 1.1140 (1.2643)  data: 0.0119 (0.1511)  task_loss: 0.1312 (0.1327)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:01:48  iter: 180  loss: 2.7810 (2.8128)  loss_reg: 0.3073 (0.2925)  loss_centerness: 0.4886 (0.4862)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6244 (1.7729)  alignment_loss: 0.1756 (0.2059)  time: 1.1464 (1.2641)  data: 0.0139 (0.1501)  task_loss: 0.1307 (0.1325)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:01:23  iter: 200  loss: 2.6410 (2.8059)  loss_reg: 0.3085 (0.2931)  loss_centerness: 0.4909 (0.4864)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5704 (1.7634)  alignment_loss: 0.1717 (0.2043)  time: 1.1449 (1.2640)  data: 0.0134 (0.1495)  task_loss: 0.1303 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:00:58  iter: 220  loss: 2.4779 (2.7942)  loss_reg: 0.3163 (0.2940)  loss_centerness: 0.4888 (0.4865)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4229 (1.7492)  alignment_loss: 0.1684 (0.2028)  time: 1.1482 (1.2649)  data: 0.0133 (0.1500)  task_loss: 0.1298 (0.1320)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:00:32  iter: 240  loss: 2.4341 (2.7814)  loss_reg: 0.3122 (0.2946)  loss_centerness: 0.4880 (0.4866)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3300 (1.7345)  alignment_loss: 0.1653 (0.2013)  time: 1.1085 (1.2634)  data: 0.0124 (0.1490)  task_loss: 0.1292 (0.1318)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:00:07  iter: 260  loss: 2.3325 (2.7644)  loss_reg: 0.2851 (0.2949)  loss_centerness: 0.4857 (0.4867)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2202 (1.7161)  alignment_loss: 0.1617 (0.1997)  time: 1.1484 (1.2627)  data: 0.0133 (0.1482)  task_loss: 0.1287 (0.1316)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:00:00  iter: 266  loss: 2.3977 (2.7601)  loss_reg: 0.3040 (0.2951)  loss_centerness: 0.4900 (0.4867)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2939 (1.7114)  alignment_loss: 0.1606 (0.1993)  time: 1.1485 (1.2627)  data: 0.0133 (0.1479)  task_loss: 0.1285 (0.1315)  lr: 0.000955  wd: 0.000500  max mem: 12612
Evaluating
2024-03-19 10:24:10,025 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 10:24:19,285 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:24:19,288 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 10:24:19,310 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.136986301369863, 0.5068493150684932, 0.5753424657534246] 

2024-03-19 10:24:19,310 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:24:19,310 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:24:19,310 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 0, res: {'refcoco': [0.136986301369863, 0.5068493150684932, 0.5753424657534246], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:24:19,327 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 10:24:23,930 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:24:23,934 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 10:24:23,944 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25925925925925924, 0.7037037037037037, 0.7777777777777778] 

2024-03-19 10:24:23,944 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:24:23,944 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:24:23,944 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.25925925925925924, 0.7037037037037037, 0.7777777777777778], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:24:23,993 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 10:24:25,026 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 10:24:26,269 maskrcnn_benchmark.trainer INFO: Total training time: 0:06:45.422802 (1.5241 s / it)
2024-03-19 10:24:26,282 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 10:24:26,282 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 10:24:26,282 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 10:24:26,282 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 10:24:26,282 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 10:24:26,282 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 10:24:26,282 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 10:24:26,282 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 10:24:26,282 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 10:24:26,283 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.2.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 10:24:26,283 maskrcnn_benchmark INFO: visual_prompt.2.dim_1 : Not Frozen, param number, 36
2024-03-19 10:24:26,284 maskrcnn_benchmark INFO: visual_prompt.2.dim_2 : Not Frozen, param number, 64
2024-03-19 10:24:26,284 maskrcnn_benchmark INFO: visual_prompt.2.dim_3 : Not Frozen, param number, 384
2024-03-19 10:24:26,284 maskrcnn_benchmark INFO: textual_prompt.2.dim_1 : Not Frozen, param number, 36
2024-03-19 10:24:26,284 maskrcnn_benchmark INFO: textual_prompt.2.dim_2 : Not Frozen, param number, 64
2024-03-19 10:24:26,284 maskrcnn_benchmark INFO: textual_prompt.2.dim_3 : Not Frozen, param number, 3072
2024-03-19 10:24:26,288 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 10:24:26,289 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.90s)
creating index...
index created!
2024-03-19 10:24:29,021 maskrcnn_benchmark INFO: Training on task 2: outdoor, total training sample size: 1063
refexp_train has the 1063 data points RefExpDataset
Number of iterations are 332
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.98s)
creating index...
index created!
2024-03-19 10:24:30,145 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 10:24:30,334 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 10:24:30,521 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
2024-03-19 10:24:30,723 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  33
eta: 0:06:35  iter: 20  loss: 2.5823 (2.7563)  loss_reg: 0.2786 (0.2948)  loss_centerness: 0.4810 (0.4866)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4873 (1.7053)  alignment_loss: 0.2114 (0.1997)  time: 1.1651 (1.2667)  data: 0.0136 (0.1514)  task_loss: 0.1295 (0.1314)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:06:09  iter: 40  loss: 2.4582 (2.7468)  loss_reg: 0.2642 (0.2941)  loss_centerness: 0.4813 (0.4864)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3557 (1.6942)  alignment_loss: 0.2079 (0.2000)  time: 1.1552 (1.2663)  data: 0.0154 (0.1506)  task_loss: 0.1295 (0.1312)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:05:44  iter: 60  loss: 2.5437 (2.7413)  loss_reg: 0.2761 (0.2938)  loss_centerness: 0.4812 (0.4863)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4653 (1.6870)  alignment_loss: 0.2041 (0.2002)  time: 1.1597 (1.2662)  data: 0.0140 (0.1501)  task_loss: 0.1295 (0.1311)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:05:18  iter: 80  loss: 2.5090 (2.7369)  loss_reg: 0.2795 (0.2934)  loss_centerness: 0.4832 (0.4862)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3760 (1.6812)  alignment_loss: 0.2006 (0.2002)  time: 1.1607 (1.2647)  data: 0.0133 (0.1492)  task_loss: 0.1295 (0.1310)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:04:53  iter: 100  loss: 2.5569 (2.7323)  loss_reg: 0.2862 (0.2931)  loss_centerness: 0.4808 (0.4861)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4458 (1.6754)  alignment_loss: 0.1971 (0.2001)  time: 1.1689 (1.2641)  data: 0.0135 (0.1486)  task_loss: 0.1294 (0.1309)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:04:28  iter: 120  loss: 2.5594 (2.7262)  loss_reg: 0.2772 (0.2927)  loss_centerness: 0.4825 (0.4860)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4909 (1.6684)  alignment_loss: 0.1937 (0.1999)  time: 1.2053 (1.2645)  data: 0.0135 (0.1480)  task_loss: 0.1294 (0.1309)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:04:02  iter: 140  loss: 2.4412 (2.7197)  loss_reg: 0.2667 (0.2922)  loss_centerness: 0.4823 (0.4859)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4226 (1.6612)  alignment_loss: 0.1902 (0.1996)  time: 1.1559 (1.2644)  data: 0.0133 (0.1476)  task_loss: 0.1294 (0.1308)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:03:37  iter: 160  loss: 2.5673 (2.7155)  loss_reg: 0.2752 (0.2920)  loss_centerness: 0.4842 (0.4858)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5003 (1.6562)  alignment_loss: 0.1867 (0.1992)  time: 1.1557 (1.2635)  data: 0.0151 (0.1471)  task_loss: 0.1294 (0.1307)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:03:11  iter: 180  loss: 2.5732 (2.7108)  loss_reg: 0.2807 (0.2917)  loss_centerness: 0.4815 (0.4857)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4569 (1.6511)  alignment_loss: 0.1831 (0.1987)  time: 1.1459 (1.2627)  data: 0.0142 (0.1464)  task_loss: 0.1294 (0.1307)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:02:46  iter: 200  loss: 2.4942 (2.7063)  loss_reg: 0.2748 (0.2915)  loss_centerness: 0.4816 (0.4856)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4559 (1.6461)  alignment_loss: 0.1794 (0.1982)  time: 1.1666 (1.2622)  data: 0.0138 (0.1460)  task_loss: 0.1293 (0.1306)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:02:21  iter: 220  loss: 2.4215 (2.7001)  loss_reg: 0.2756 (0.2911)  loss_centerness: 0.4820 (0.4855)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3440 (1.6397)  alignment_loss: 0.1756 (0.1976)  time: 1.1616 (1.2627)  data: 0.0137 (0.1463)  task_loss: 0.1293 (0.1306)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:01:56  iter: 240  loss: 2.4799 (2.6943)  loss_reg: 0.2735 (0.2908)  loss_centerness: 0.4816 (0.4855)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3985 (1.6339)  alignment_loss: 0.1716 (0.1969)  time: 1.1964 (1.2623)  data: 0.0152 (0.1460)  task_loss: 0.1293 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:01:30  iter: 260  loss: 2.4973 (2.6901)  loss_reg: 0.2681 (0.2903)  loss_centerness: 0.4815 (0.4853)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4851 (1.6300)  alignment_loss: 0.1675 (0.1961)  time: 1.2039 (1.2617)  data: 0.0139 (0.1455)  task_loss: 0.1292 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:01:05  iter: 280  loss: 2.4241 (2.6841)  loss_reg: 0.2813 (0.2903)  loss_centerness: 0.4830 (0.4853)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3759 (1.6239)  alignment_loss: 0.1632 (0.1953)  time: 1.1820 (1.2609)  data: 0.0158 (0.1450)  task_loss: 0.1292 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:00:40  iter: 300  loss: 2.5261 (2.6810)  loss_reg: 0.2727 (0.2899)  loss_centerness: 0.4817 (0.4853)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4856 (1.6211)  alignment_loss: 0.1588 (0.1944)  time: 1.1691 (1.2607)  data: 0.0153 (0.1447)  task_loss: 0.1292 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:00:15  iter: 320  loss: 2.4604 (2.6754)  loss_reg: 0.2734 (0.2898)  loss_centerness: 0.4824 (0.4852)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3836 (1.6157)  alignment_loss: 0.1542 (0.1935)  time: 1.1696 (1.2607)  data: 0.0162 (0.1449)  task_loss: 0.1291 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:00:00  iter: 332  loss: 2.4529 (2.6720)  loss_reg: 0.2660 (0.2896)  loss_centerness: 0.4807 (0.4852)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3859 (1.6126)  alignment_loss: 0.1509 (0.1929)  time: 1.1696 (1.2604)  data: 0.0162 (0.1447)  task_loss: 0.1291 (0.1303)  lr: 0.006545  wd: 0.000500  max mem: 12612
Evaluating
2024-03-19 10:32:24,991 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 10:32:34,014 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:32:34,017 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 10:32:34,043 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.5068493150684932, 0.5753424657534246] 

2024-03-19 10:32:34,043 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:32:34,043 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:32:34,044 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.5068493150684932, 0.5753424657534246], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:32:34,060 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 10:32:38,415 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:32:38,421 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 10:32:38,439 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25925925925925924, 0.7037037037037037, 0.7777777777777778] 

2024-03-19 10:32:38,439 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:32:38,439 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:32:38,439 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.25925925925925924, 0.7037037037037037, 0.7777777777777778], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:32:38,458 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 10:32:44,329 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:32:44,331 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 10:32:44,342 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25, 0.6590909090909091, 0.7272727272727273] 

2024-03-19 10:32:44,342 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:32:44,342 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:32:44,343 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8181818181818182
evaluate on task refcoco, val, 2, res: {'refcoco': [0.25, 0.6590909090909091, 0.7272727272727273], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:32:44,386 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 10:32:45,623 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 10:32:46,989 maskrcnn_benchmark.trainer INFO: Total training time: 0:08:16.251026 (1.4947 s / it)
2024-03-19 10:32:47,002 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 10:32:47,002 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 10:32:47,002 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 10:32:47,002 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 10:32:47,002 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 10:32:47,002 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 10:32:47,003 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 10:32:47,003 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 10:32:47,003 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 10:32:47,003 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.3.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 10:32:47,004 maskrcnn_benchmark INFO: visual_prompt.3.dim_1 : Not Frozen, param number, 36
2024-03-19 10:32:47,004 maskrcnn_benchmark INFO: visual_prompt.3.dim_2 : Not Frozen, param number, 64
2024-03-19 10:32:47,004 maskrcnn_benchmark INFO: visual_prompt.3.dim_3 : Not Frozen, param number, 384
2024-03-19 10:32:47,004 maskrcnn_benchmark INFO: textual_prompt.3.dim_1 : Not Frozen, param number, 36
2024-03-19 10:32:47,004 maskrcnn_benchmark INFO: textual_prompt.3.dim_2 : Not Frozen, param number, 64
2024-03-19 10:32:47,004 maskrcnn_benchmark INFO: textual_prompt.3.dim_3 : Not Frozen, param number, 3072
2024-03-19 10:32:47,007 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 10:32:47,008 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.95s)
creating index...
index created!
2024-03-19 10:32:49,816 maskrcnn_benchmark INFO: Training on task 3: electronic, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.88s)
creating index...
index created!
2024-03-19 10:32:50,826 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 10:32:51,008 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 10:32:51,192 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 10:32:51,376 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
2024-03-19 10:32:51,601 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:12:43  iter: 20  loss: 2.6436 (2.6718)  loss_reg: 0.1858 (0.2876)  loss_centerness: 0.4740 (0.4849)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6403 (1.6132)  alignment_loss: 0.2206 (0.1935)  time: 1.1542 (1.2627)  data: 0.0174 (0.1468)  task_loss: 0.1315 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:12:18  iter: 40  loss: 2.7260 (2.6719)  loss_reg: 0.1962 (0.2857)  loss_centerness: 0.4751 (0.4847)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6761 (1.6139)  alignment_loss: 0.2199 (0.1941)  time: 1.1546 (1.2625)  data: 0.0158 (0.1464)  task_loss: 0.1314 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:11:53  iter: 60  loss: 2.6539 (2.6727)  loss_reg: 0.1875 (0.2837)  loss_centerness: 0.4719 (0.4844)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6458 (1.6156)  alignment_loss: 0.2191 (0.1946)  time: 1.1504 (1.2620)  data: 0.0144 (0.1461)  task_loss: 0.1313 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:11:27  iter: 80  loss: 2.6274 (2.6717)  loss_reg: 0.2007 (0.2819)  loss_centerness: 0.4728 (0.4842)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6175 (1.6153)  alignment_loss: 0.2183 (0.1951)  time: 1.1191 (1.2613)  data: 0.0141 (0.1457)  task_loss: 0.1312 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:11:02  iter: 100  loss: 2.6659 (2.6711)  loss_reg: 0.1921 (0.2801)  loss_centerness: 0.4708 (0.4839)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6495 (1.6155)  alignment_loss: 0.2175 (0.1956)  time: 1.1713 (1.2617)  data: 0.0152 (0.1462)  task_loss: 0.1311 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:10:36  iter: 120  loss: 2.7924 (2.6728)  loss_reg: 0.2051 (0.2786)  loss_centerness: 0.4738 (0.4838)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7530 (1.6177)  alignment_loss: 0.2166 (0.1960)  time: 1.1486 (1.2612)  data: 0.0163 (0.1459)  task_loss: 0.1310 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:10:11  iter: 140  loss: 2.6242 (2.6727)  loss_reg: 0.1863 (0.2771)  loss_centerness: 0.4720 (0.4836)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6261 (1.6182)  alignment_loss: 0.2157 (0.1964)  time: 1.1705 (1.2610)  data: 0.0163 (0.1456)  task_loss: 0.1309 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:09:46  iter: 160  loss: 2.6111 (2.6718)  loss_reg: 0.2025 (0.2757)  loss_centerness: 0.4734 (0.4834)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6410 (1.6179)  alignment_loss: 0.2148 (0.1968)  time: 1.1569 (1.2610)  data: 0.0157 (0.1454)  task_loss: 0.1308 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:09:21  iter: 180  loss: 2.6694 (2.6718)  loss_reg: 0.1931 (0.2743)  loss_centerness: 0.4719 (0.4832)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6743 (1.6185)  alignment_loss: 0.2138 (0.1971)  time: 1.1618 (1.2611)  data: 0.0176 (0.1452)  task_loss: 0.1307 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:08:55  iter: 200  loss: 2.7638 (2.6729)  loss_reg: 0.1882 (0.2729)  loss_centerness: 0.4741 (0.4830)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7553 (1.6203)  alignment_loss: 0.2128 (0.1974)  time: 1.1592 (1.2612)  data: 0.0155 (0.1454)  task_loss: 0.1306 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:08:30  iter: 220  loss: 2.5660 (2.6708)  loss_reg: 0.2010 (0.2716)  loss_centerness: 0.4736 (0.4829)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5799 (1.6188)  alignment_loss: 0.2117 (0.1977)  time: 1.1644 (1.2610)  data: 0.0138 (0.1452)  task_loss: 0.1304 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:08:05  iter: 240  loss: 2.6841 (2.6701)  loss_reg: 0.1983 (0.2702)  loss_centerness: 0.4731 (0.4827)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6591 (1.6188)  alignment_loss: 0.2105 (0.1979)  time: 1.1569 (1.2607)  data: 0.0157 (0.1449)  task_loss: 0.1303 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:07:39  iter: 260  loss: 2.5719 (2.6690)  loss_reg: 0.1851 (0.2689)  loss_centerness: 0.4726 (0.4825)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5611 (1.6185)  alignment_loss: 0.2092 (0.1981)  time: 1.1568 (1.2602)  data: 0.0155 (0.1446)  task_loss: 0.1302 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:07:14  iter: 280  loss: 2.5669 (2.6678)  loss_reg: 0.2039 (0.2678)  loss_centerness: 0.4749 (0.4824)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5536 (1.6179)  alignment_loss: 0.2077 (0.1983)  time: 1.1546 (1.2596)  data: 0.0133 (0.1443)  task_loss: 0.1301 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:06:49  iter: 300  loss: 2.5534 (2.6662)  loss_reg: 0.1751 (0.2666)  loss_centerness: 0.4723 (0.4822)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5775 (1.6169)  alignment_loss: 0.2062 (0.1984)  time: 1.1521 (1.2600)  data: 0.0156 (0.1446)  task_loss: 0.1299 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:06:24  iter: 320  loss: 2.5873 (2.6649)  loss_reg: 0.1846 (0.2655)  loss_centerness: 0.4715 (0.4820)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5411 (1.6165)  alignment_loss: 0.2044 (0.1985)  time: 1.1493 (1.2595)  data: 0.0140 (0.1443)  task_loss: 0.1298 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:05:58  iter: 340  loss: 2.5386 (2.6638)  loss_reg: 0.1996 (0.2646)  loss_centerness: 0.4746 (0.4819)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5260 (1.6158)  alignment_loss: 0.2026 (0.1986)  time: 1.1548 (1.2596)  data: 0.0158 (0.1446)  task_loss: 0.1297 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:05:33  iter: 360  loss: 2.4328 (2.6607)  loss_reg: 0.1767 (0.2633)  loss_centerness: 0.4738 (0.4818)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4540 (1.6137)  alignment_loss: 0.2006 (0.1986)  time: 1.1673 (1.2599)  data: 0.0147 (0.1449)  task_loss: 0.1296 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:05:08  iter: 380  loss: 2.5206 (2.6597)  loss_reg: 0.1864 (0.2622)  loss_centerness: 0.4734 (0.4817)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5275 (1.6135)  alignment_loss: 0.1985 (0.1986)  time: 1.1598 (1.2596)  data: 0.0145 (0.1446)  task_loss: 0.1294 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:04:43  iter: 400  loss: 2.5628 (2.6578)  loss_reg: 0.1906 (0.2611)  loss_centerness: 0.4711 (0.4815)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5355 (1.6124)  alignment_loss: 0.1962 (0.1986)  time: 1.1526 (1.2601)  data: 0.0168 (0.1445)  task_loss: 0.1293 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:04:18  iter: 420  loss: 2.4635 (2.6545)  loss_reg: 0.2141 (0.2605)  loss_centerness: 0.4755 (0.4814)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4394 (1.6095)  alignment_loss: 0.1938 (0.1985)  time: 1.1541 (1.2599)  data: 0.0187 (0.1443)  task_loss: 0.1292 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:03:53  iter: 440  loss: 2.4012 (2.6512)  loss_reg: 0.1855 (0.2594)  loss_centerness: 0.4723 (0.4813)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4327 (1.6071)  alignment_loss: 0.1912 (0.1984)  time: 1.2106 (1.2599)  data: 0.0141 (0.1441)  task_loss: 0.1290 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:03:27  iter: 460  loss: 2.4452 (2.6488)  loss_reg: 0.1897 (0.2585)  loss_centerness: 0.4722 (0.4811)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4794 (1.6056)  alignment_loss: 0.1885 (0.1983)  time: 1.1664 (1.2595)  data: 0.0153 (0.1438)  task_loss: 0.1289 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:03:02  iter: 480  loss: 2.3953 (2.6449)  loss_reg: 0.1958 (0.2577)  loss_centerness: 0.4750 (0.4811)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3716 (1.6024)  alignment_loss: 0.1856 (0.1981)  time: 1.2064 (1.2594)  data: 0.0158 (0.1437)  task_loss: 0.1288 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:02:37  iter: 500  loss: 2.2459 (2.6402)  loss_reg: 0.1938 (0.2569)  loss_centerness: 0.4736 (0.4810)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2442 (1.5985)  alignment_loss: 0.1826 (0.1978)  time: 1.1501 (1.2593)  data: 0.0135 (0.1435)  task_loss: 0.1287 (0.1302)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:02:12  iter: 520  loss: 2.2530 (2.6346)  loss_reg: 0.2025 (0.2562)  loss_centerness: 0.4735 (0.4809)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2660 (1.5936)  alignment_loss: 0.1795 (0.1976)  time: 1.1593 (1.2596)  data: 0.0149 (0.1438)  task_loss: 0.1286 (0.1302)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:01:47  iter: 540  loss: 2.1028 (2.6277)  loss_reg: 0.1864 (0.2553)  loss_centerness: 0.4723 (0.4807)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1794 (1.5877)  alignment_loss: 0.1764 (0.1973)  time: 1.1681 (1.2596)  data: 0.0160 (0.1436)  task_loss: 0.1285 (0.1302)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:01:21  iter: 560  loss: 2.2062 (2.6219)  loss_reg: 0.2123 (0.2548)  loss_centerness: 0.4755 (0.4807)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1797 (1.5825)  alignment_loss: 0.1733 (0.1969)  time: 1.1614 (1.2596)  data: 0.0155 (0.1435)  task_loss: 0.1284 (0.1301)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:00:56  iter: 580  loss: 2.0118 (2.6134)  loss_reg: 0.1846 (0.2539)  loss_centerness: 0.4735 (0.4806)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0502 (1.5751)  alignment_loss: 0.1704 (0.1966)  time: 1.1556 (1.2596)  data: 0.0166 (0.1434)  task_loss: 0.1283 (0.1301)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:00:31  iter: 600  loss: 2.0354 (2.6058)  loss_reg: 0.2031 (0.2532)  loss_centerness: 0.4737 (0.4805)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0407 (1.5684)  alignment_loss: 0.1676 (0.1962)  time: 1.1781 (1.2591)  data: 0.0141 (0.1431)  task_loss: 0.1282 (0.1301)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:00:06  iter: 620  loss: 1.9446 (2.5968)  loss_reg: 0.1933 (0.2525)  loss_centerness: 0.4723 (0.4804)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9537 (1.5604)  alignment_loss: 0.1649 (0.1957)  time: 1.1558 (1.2592)  data: 0.0178 (0.1433)  task_loss: 0.1282 (0.1300)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:00:00  iter: 625  loss: 1.9732 (2.5953)  loss_reg: 0.2014 (0.2524)  loss_centerness: 0.4743 (0.4804)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9970 (1.5590)  alignment_loss: 0.1642 (0.1956)  time: 1.1558 (1.2591)  data: 0.0178 (0.1432)  task_loss: 0.1282 (0.1300)  lr: 0.000000  wd: 0.000500  max mem: 12612
Evaluating
2024-03-19 10:47:45,260 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 10:47:53,873 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:47:53,877 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 10:47:53,898 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.5068493150684932, 0.5753424657534246] 

2024-03-19 10:47:53,898 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:47:53,899 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:47:53,899 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9178082191780822
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.5068493150684932, 0.5753424657534246], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:47:53,913 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 10:47:58,524 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:47:58,527 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 10:47:58,538 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25925925925925924, 0.7037037037037037, 0.7777777777777778] 

2024-03-19 10:47:58,538 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:47:58,538 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:47:58,538 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.25925925925925924, 0.7037037037037037, 0.7777777777777778], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:47:58,554 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 10:48:04,778 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:48:04,781 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 10:48:04,795 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25, 0.6363636363636364, 0.7272727272727273] 

2024-03-19 10:48:04,795 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:48:04,795 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:48:04,795 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6818181818181818
evaluate on task refcoco, val, 2, res: {'refcoco': [0.25, 0.6363636363636364, 0.7272727272727273], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:48:04,811 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 10:48:29,257 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 10:48:29,260 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 10:48:29,351 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.29411764705882354, 0.7764705882352941, 0.8823529411764706] 

2024-03-19 10:48:29,351 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 10:48:29,351 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 10:48:29,351 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9019607843137255
evaluate on task refcoco, val, 3, res: {'refcoco': [0.29411764705882354, 0.7764705882352941, 0.8823529411764706], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 10:48:29,405 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 10:48:30,630 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 10:48:31,804 maskrcnn_benchmark.trainer INFO: Total training time: 0:15:40.189018 (1.5043 s / it)
2024-03-19 10:48:31,820 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 10:48:31,820 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 10:48:31,820 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 10:48:31,820 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 10:48:31,820 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 10:48:31,820 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 10:48:31,820 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 10:48:31,820 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 10:48:31,820 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 10:48:31,820 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.4.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 10:48:31,821 maskrcnn_benchmark INFO: visual_prompt.4.dim_1 : Not Frozen, param number, 36
2024-03-19 10:48:31,821 maskrcnn_benchmark INFO: visual_prompt.4.dim_2 : Not Frozen, param number, 64
2024-03-19 10:48:31,821 maskrcnn_benchmark INFO: visual_prompt.4.dim_3 : Not Frozen, param number, 384
2024-03-19 10:48:31,821 maskrcnn_benchmark INFO: textual_prompt.4.dim_1 : Not Frozen, param number, 36
2024-03-19 10:48:31,821 maskrcnn_benchmark INFO: textual_prompt.4.dim_2 : Not Frozen, param number, 64
2024-03-19 10:48:31,821 maskrcnn_benchmark INFO: textual_prompt.4.dim_3 : Not Frozen, param number, 3072
2024-03-19 10:48:31,824 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 10:48:31,824 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.96s)
creating index...
index created!
2024-03-19 10:48:35,330 maskrcnn_benchmark INFO: Training on task 4: accessory, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 10:48:35,535 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 10:48:35,714 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 10:48:35,897 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 10:48:36,084 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 10:48:36,280 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
2024-03-19 10:48:36,514 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:12:42  iter: 20  loss: 3.0044 (2.6010)  loss_reg: 0.2483 (0.2522)  loss_centerness: 0.4785 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.9164 (1.5643)  alignment_loss: 0.2113 (0.1958)  time: 1.2213 (1.2601)  data: 0.1235 (0.1444)  task_loss: 0.1319 (0.1301)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:12:16  iter: 40  loss: 2.9175 (2.6056)  loss_reg: 0.2419 (0.2521)  loss_centerness: 0.4787 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8666 (1.5687)  alignment_loss: 0.2047 (0.1959)  time: 1.2392 (1.2598)  data: 0.1280 (0.1442)  task_loss: 0.1319 (0.1301)  lr: 0.010000  wd: 0.000500  max mem: 12612
eta: 0:11:51  iter: 60  loss: 2.8959 (2.6096)  loss_reg: 0.2157 (0.2517)  loss_centerness: 0.4779 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8501 (1.5727)  alignment_loss: 0.1991 (0.1960)  time: 1.2127 (1.2598)  data: 0.1162 (0.1440)  task_loss: 0.1318 (0.1301)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:11:26  iter: 80  loss: 2.8861 (2.6135)  loss_reg: 0.2353 (0.2516)  loss_centerness: 0.4772 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8372 (1.5765)  alignment_loss: 0.1941 (0.1960)  time: 1.2164 (1.2594)  data: 0.1274 (0.1437)  task_loss: 0.1317 (0.1301)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:11:01  iter: 100  loss: 2.9654 (2.6177)  loss_reg: 0.2365 (0.2515)  loss_centerness: 0.4760 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8912 (1.5806)  alignment_loss: 0.1891 (0.1959)  time: 1.2625 (1.2595)  data: 0.1295 (0.1436)  task_loss: 0.1317 (0.1302)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:10:35  iter: 120  loss: 2.8803 (2.6212)  loss_reg: 0.2238 (0.2511)  loss_centerness: 0.4801 (0.4803)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8755 (1.5844)  alignment_loss: 0.1839 (0.1957)  time: 1.2155 (1.2591)  data: 0.1253 (0.1434)  task_loss: 0.1316 (0.1302)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:10:10  iter: 140  loss: 2.7037 (2.6231)  loss_reg: 0.2162 (0.2509)  loss_centerness: 0.4769 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6720 (1.5865)  alignment_loss: 0.1785 (0.1955)  time: 1.2033 (1.2587)  data: 0.1162 (0.1432)  task_loss: 0.1316 (0.1302)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:09:45  iter: 160  loss: 2.8159 (2.6263)  loss_reg: 0.2242 (0.2507)  loss_centerness: 0.4774 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8076 (1.5899)  alignment_loss: 0.1727 (0.1952)  time: 1.2600 (1.2587)  data: 0.1326 (0.1431)  task_loss: 0.1316 (0.1302)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:09:20  iter: 180  loss: 2.9089 (2.6307)  loss_reg: 0.2325 (0.2506)  loss_centerness: 0.4790 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8748 (1.5945)  alignment_loss: 0.1667 (0.1949)  time: 1.2625 (1.2591)  data: 0.1359 (0.1434)  task_loss: 0.1316 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:08:55  iter: 200  loss: 2.7813 (2.6333)  loss_reg: 0.2116 (0.2502)  loss_centerness: 0.4770 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8098 (1.5976)  alignment_loss: 0.1607 (0.1945)  time: 1.2238 (1.2597)  data: 0.1304 (0.1440)  task_loss: 0.1316 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:08:30  iter: 220  loss: 2.7424 (2.6353)  loss_reg: 0.2477 (0.2502)  loss_centerness: 0.4798 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7477 (1.5999)  alignment_loss: 0.1548 (0.1940)  time: 1.2170 (1.2594)  data: 0.1247 (0.1438)  task_loss: 0.1315 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:08:04  iter: 240  loss: 2.8350 (2.6388)  loss_reg: 0.2320 (0.2501)  loss_centerness: 0.4793 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8342 (1.6038)  alignment_loss: 0.1488 (0.1935)  time: 1.2213 (1.2592)  data: 0.1209 (0.1436)  task_loss: 0.1315 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:07:39  iter: 260  loss: 2.8725 (2.6413)  loss_reg: 0.2354 (0.2500)  loss_centerness: 0.4789 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.9041 (1.6068)  alignment_loss: 0.1433 (0.1929)  time: 1.2238 (1.2588)  data: 0.1320 (0.1434)  task_loss: 0.1315 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:07:14  iter: 280  loss: 2.9014 (2.6440)  loss_reg: 0.2343 (0.2498)  loss_centerness: 0.4783 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8953 (1.6101)  alignment_loss: 0.1381 (0.1923)  time: 1.2786 (1.2590)  data: 0.1278 (0.1437)  task_loss: 0.1316 (0.1303)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:06:49  iter: 300  loss: 2.6931 (2.6448)  loss_reg: 0.2197 (0.2496)  loss_centerness: 0.4785 (0.4802)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7272 (1.6115)  alignment_loss: 0.1334 (0.1916)  time: 1.2664 (1.2591)  data: 0.1275 (0.1435)  task_loss: 0.1316 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:06:23  iter: 320  loss: 2.8197 (2.6463)  loss_reg: 0.2424 (0.2496)  loss_centerness: 0.4767 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8259 (1.6134)  alignment_loss: 0.1291 (0.1909)  time: 1.2320 (1.2590)  data: 0.1227 (0.1434)  task_loss: 0.1316 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:05:58  iter: 340  loss: 2.7956 (2.6474)  loss_reg: 0.2287 (0.2494)  loss_centerness: 0.4782 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7773 (1.6153)  alignment_loss: 0.1252 (0.1902)  time: 1.2209 (1.2588)  data: 0.1273 (0.1433)  task_loss: 0.1317 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:05:33  iter: 360  loss: 2.6068 (2.6480)  loss_reg: 0.2340 (0.2493)  loss_centerness: 0.4782 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6614 (1.6166)  alignment_loss: 0.1218 (0.1895)  time: 1.2235 (1.2586)  data: 0.1284 (0.1431)  task_loss: 0.1317 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:05:08  iter: 380  loss: 2.6002 (2.6478)  loss_reg: 0.2186 (0.2491)  loss_centerness: 0.4759 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6592 (1.6172)  alignment_loss: 0.1188 (0.1887)  time: 1.2576 (1.2588)  data: 0.1260 (0.1430)  task_loss: 0.1318 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:04:43  iter: 400  loss: 2.6358 (2.6478)  loss_reg: 0.2437 (0.2490)  loss_centerness: 0.4775 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6406 (1.6178)  alignment_loss: 0.1163 (0.1879)  time: 1.2500 (1.2587)  data: 0.1266 (0.1428)  task_loss: 0.1319 (0.1304)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:04:17  iter: 420  loss: 2.5559 (2.6471)  loss_reg: 0.2357 (0.2489)  loss_centerness: 0.4801 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5860 (1.6177)  alignment_loss: 0.1142 (0.1871)  time: 1.2170 (1.2585)  data: 0.1166 (0.1427)  task_loss: 0.1321 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:03:52  iter: 440  loss: 2.4982 (2.6459)  loss_reg: 0.2281 (0.2488)  loss_centerness: 0.4794 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5156 (1.6173)  alignment_loss: 0.1120 (0.1864)  time: 1.2612 (1.2584)  data: 0.1290 (0.1426)  task_loss: 0.1322 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:03:27  iter: 460  loss: 2.4907 (2.6445)  loss_reg: 0.2252 (0.2486)  loss_centerness: 0.4771 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5378 (1.6166)  alignment_loss: 0.1096 (0.1856)  time: 1.2160 (1.2581)  data: 0.1175 (0.1424)  task_loss: 0.1324 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:03:02  iter: 480  loss: 2.2913 (2.6414)  loss_reg: 0.2350 (0.2485)  loss_centerness: 0.4810 (0.4801)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3248 (1.6143)  alignment_loss: 0.1069 (0.1848)  time: 1.2535 (1.2579)  data: 0.1275 (0.1423)  task_loss: 0.1325 (0.1305)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:02:37  iter: 500  loss: 2.2527 (2.6381)  loss_reg: 0.2286 (0.2484)  loss_centerness: 0.4767 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3141 (1.6118)  alignment_loss: 0.1038 (0.1839)  time: 1.2622 (1.2582)  data: 0.1278 (0.1422)  task_loss: 0.1326 (0.1306)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:02:12  iter: 520  loss: 2.2649 (2.6344)  loss_reg: 0.2244 (0.2482)  loss_centerness: 0.4786 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3370 (1.6089)  alignment_loss: 0.1004 (0.1831)  time: 1.2406 (1.2581)  data: 0.1293 (0.1421)  task_loss: 0.1327 (0.1306)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:01:46  iter: 540  loss: 2.2204 (2.6306)  loss_reg: 0.2446 (0.2482)  loss_centerness: 0.4791 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2687 (1.6058)  alignment_loss: 0.0969 (0.1822)  time: 1.2580 (1.2581)  data: 0.1339 (0.1420)  task_loss: 0.1328 (0.1306)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:01:21  iter: 560  loss: 2.1372 (2.6262)  loss_reg: 0.2252 (0.2480)  loss_centerness: 0.4773 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1942 (1.6023)  alignment_loss: 0.0931 (0.1814)  time: 1.2357 (1.2578)  data: 0.1294 (0.1419)  task_loss: 0.1328 (0.1306)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:56  iter: 580  loss: 2.1545 (2.6216)  loss_reg: 0.2306 (0.2479)  loss_centerness: 0.4782 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2164 (1.5986)  alignment_loss: 0.0900 (0.1805)  time: 1.2132 (1.2577)  data: 0.1286 (0.1418)  task_loss: 0.1328 (0.1307)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:31  iter: 600  loss: 2.0874 (2.6169)  loss_reg: 0.2459 (0.2478)  loss_centerness: 0.4790 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1428 (1.5947)  alignment_loss: 0.0871 (0.1796)  time: 1.2495 (1.2579)  data: 0.1251 (0.1417)  task_loss: 0.1328 (0.1307)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:06  iter: 620  loss: 2.1155 (2.6124)  loss_reg: 0.2365 (0.2477)  loss_centerness: 0.4762 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1925 (1.5910)  alignment_loss: 0.0844 (0.1787)  time: 1.2189 (1.2579)  data: 0.1160 (0.1418)  task_loss: 0.1328 (0.1307)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:00  iter: 625  loss: 2.0598 (2.6112)  loss_reg: 0.2360 (0.2476)  loss_centerness: 0.4776 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1401 (1.5901)  alignment_loss: 0.0836 (0.1784)  time: 1.2189 (1.2579)  data: 0.1160 (0.1418)  task_loss: 0.1328 (0.1307)  lr: 0.000000  wd: 0.000500  max mem: 12614
Evaluating
2024-03-19 11:03:29,545 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 11:03:38,038 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:03:38,042 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:03:38,069 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.5068493150684932, 0.5753424657534246] 

2024-03-19 11:03:38,069 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:03:38,069 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:03:38,070 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9178082191780822
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.5068493150684932, 0.5753424657534246], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:03:38,087 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 11:03:43,041 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:03:43,045 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 11:03:43,055 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25925925925925924, 0.7037037037037037, 0.8148148148148148] 

2024-03-19 11:03:43,055 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:03:43,055 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:03:43,055 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.25925925925925924, 0.7037037037037037, 0.8148148148148148], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:03:43,073 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 11:03:49,062 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:03:49,064 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:03:49,076 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25, 0.6590909090909091, 0.75] 

2024-03-19 11:03:49,076 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:03:49,076 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:03:49,076 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.25, 0.6590909090909091, 0.75], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:03:49,090 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 11:04:13,029 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:04:13,033 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:04:13,113 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3058823529411765, 0.7803921568627451, 0.8941176470588236] 

2024-03-19 11:04:13,114 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:04:13,114 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:04:13,114 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8784313725490196
evaluate on task refcoco, val, 3, res: {'refcoco': [0.3058823529411765, 0.7803921568627451, 0.8941176470588236], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:04:13,129 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 11:04:33,078 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:04:33,083 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:04:33,166 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2523809523809524, 0.7904761904761904, 0.8666666666666667] 

2024-03-19 11:04:33,166 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:04:33,167 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:04:33,167 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9095238095238095
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2523809523809524, 0.7904761904761904, 0.8666666666666667], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:04:33,217 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 11:04:34,492 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 11:04:35,815 maskrcnn_benchmark.trainer INFO: Total training time: 0:15:59.287032 (1.5349 s / it)
2024-03-19 11:04:35,829 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 11:04:35,829 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 11:04:35,830 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 11:04:35,830 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 11:04:35,830 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 11:04:35,830 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 11:04:35,830 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 11:04:35,830 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 11:04:35,830 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 11:04:35,830 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.5.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 11:04:35,831 maskrcnn_benchmark INFO: visual_prompt.5.dim_1 : Not Frozen, param number, 36
2024-03-19 11:04:35,831 maskrcnn_benchmark INFO: visual_prompt.5.dim_2 : Not Frozen, param number, 64
2024-03-19 11:04:35,831 maskrcnn_benchmark INFO: visual_prompt.5.dim_3 : Not Frozen, param number, 384
2024-03-19 11:04:35,831 maskrcnn_benchmark INFO: textual_prompt.5.dim_1 : Not Frozen, param number, 36
2024-03-19 11:04:35,831 maskrcnn_benchmark INFO: textual_prompt.5.dim_2 : Not Frozen, param number, 64
2024-03-19 11:04:35,831 maskrcnn_benchmark INFO: textual_prompt.5.dim_3 : Not Frozen, param number, 3072
2024-03-19 11:04:35,837 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 11:04:35,838 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=2.16s)
creating index...
index created!
2024-03-19 11:04:38,864 maskrcnn_benchmark INFO: Training on task 5: indoor, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 11:04:39,068 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.99s)
creating index...
index created!
2024-03-19 11:04:40,173 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:04:40,357 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:04:40,540 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:04:40,724 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 11:04:40,911 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
2024-03-19 11:04:41,120 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:12:41  iter: 20  loss: 2.7347 (2.6127)  loss_reg: 0.2303 (0.2476)  loss_centerness: 0.4784 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7099 (1.5911)  alignment_loss: 0.2182 (0.1788)  time: 1.1538 (1.2590)  data: 0.0137 (0.1427)  task_loss: 0.1344 (0.1307)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:12:16  iter: 40  loss: 2.7992 (2.6142)  loss_reg: 0.2364 (0.2475)  loss_centerness: 0.4778 (0.4800)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7193 (1.5922)  alignment_loss: 0.2171 (0.1792)  time: 1.1496 (1.2589)  data: 0.0131 (0.1426)  task_loss: 0.1344 (0.1308)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:11:51  iter: 60  loss: 2.6400 (2.6148)  loss_reg: 0.2203 (0.2473)  loss_centerness: 0.4783 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5588 (1.5924)  alignment_loss: 0.2159 (0.1795)  time: 1.1269 (1.2587)  data: 0.0132 (0.1425)  task_loss: 0.1343 (0.1308)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:11:26  iter: 80  loss: 2.6542 (2.6161)  loss_reg: 0.2378 (0.2473)  loss_centerness: 0.4805 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6096 (1.5933)  alignment_loss: 0.2149 (0.1798)  time: 1.1432 (1.2589)  data: 0.0134 (0.1427)  task_loss: 0.1343 (0.1309)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:11:00  iter: 100  loss: 2.5994 (2.6166)  loss_reg: 0.2124 (0.2471)  loss_centerness: 0.4757 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5787 (1.5935)  alignment_loss: 0.2139 (0.1801)  time: 1.1427 (1.2588)  data: 0.0128 (0.1426)  task_loss: 0.1343 (0.1309)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:10:35  iter: 120  loss: 2.6688 (2.6174)  loss_reg: 0.2299 (0.2470)  loss_centerness: 0.4774 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6273 (1.5940)  alignment_loss: 0.2130 (0.1804)  time: 1.1107 (1.2586)  data: 0.0122 (0.1424)  task_loss: 0.1343 (0.1309)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:10:10  iter: 140  loss: 2.6410 (2.6180)  loss_reg: 0.2431 (0.2469)  loss_centerness: 0.4797 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5245 (1.5941)  alignment_loss: 0.2122 (0.1807)  time: 1.1465 (1.2585)  data: 0.0130 (0.1423)  task_loss: 0.1342 (0.1310)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:09:45  iter: 160  loss: 2.6268 (2.6192)  loss_reg: 0.2312 (0.2469)  loss_centerness: 0.4769 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5624 (1.5950)  alignment_loss: 0.2112 (0.1810)  time: 1.1284 (1.2583)  data: 0.0133 (0.1422)  task_loss: 0.1342 (0.1310)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:09:19  iter: 180  loss: 2.6709 (2.6196)  loss_reg: 0.2335 (0.2467)  loss_centerness: 0.4782 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5510 (1.5951)  alignment_loss: 0.2102 (0.1813)  time: 1.1195 (1.2582)  data: 0.0137 (0.1421)  task_loss: 0.1342 (0.1310)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:08:54  iter: 200  loss: 2.6656 (2.6200)  loss_reg: 0.2285 (0.2466)  loss_centerness: 0.4784 (0.4799)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6232 (1.5953)  alignment_loss: 0.2092 (0.1815)  time: 1.1153 (1.2583)  data: 0.0120 (0.1420)  task_loss: 0.1341 (0.1311)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:08:29  iter: 220  loss: 2.5290 (2.6202)  loss_reg: 0.2180 (0.2465)  loss_centerness: 0.4760 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4535 (1.5952)  alignment_loss: 0.2081 (0.1817)  time: 1.1412 (1.2581)  data: 0.0129 (0.1419)  task_loss: 0.1341 (0.1311)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:08:04  iter: 240  loss: 2.6177 (2.6208)  loss_reg: 0.2379 (0.2463)  loss_centerness: 0.4774 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5702 (1.5957)  alignment_loss: 0.2068 (0.1819)  time: 1.1116 (1.2578)  data: 0.0119 (0.1417)  task_loss: 0.1340 (0.1311)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:07:39  iter: 260  loss: 2.5682 (2.6205)  loss_reg: 0.2483 (0.2464)  loss_centerness: 0.4789 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4768 (1.5950)  alignment_loss: 0.2054 (0.1821)  time: 1.1455 (1.2577)  data: 0.0136 (0.1416)  task_loss: 0.1340 (0.1311)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:07:13  iter: 280  loss: 2.6262 (2.6208)  loss_reg: 0.2373 (0.2463)  loss_centerness: 0.4787 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5427 (1.5950)  alignment_loss: 0.2039 (0.1823)  time: 1.1421 (1.2576)  data: 0.0129 (0.1415)  task_loss: 0.1339 (0.1312)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:06:48  iter: 300  loss: 2.5564 (2.6201)  loss_reg: 0.1924 (0.2460)  loss_centerness: 0.4751 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4701 (1.5944)  alignment_loss: 0.2023 (0.1825)  time: 1.1564 (1.2581)  data: 0.0134 (0.1420)  task_loss: 0.1339 (0.1312)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:06:23  iter: 320  loss: 2.5575 (2.6195)  loss_reg: 0.2411 (0.2460)  loss_centerness: 0.4785 (0.4798)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4979 (1.5935)  alignment_loss: 0.2004 (0.1826)  time: 1.1155 (1.2582)  data: 0.0117 (0.1421)  task_loss: 0.1338 (0.1312)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:05:58  iter: 340  loss: 2.5021 (2.6187)  loss_reg: 0.2049 (0.2458)  loss_centerness: 0.4753 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5086 (1.5927)  alignment_loss: 0.1983 (0.1828)  time: 1.1150 (1.2579)  data: 0.0117 (0.1420)  task_loss: 0.1338 (0.1312)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:05:33  iter: 360  loss: 2.3926 (2.6178)  loss_reg: 0.2409 (0.2458)  loss_centerness: 0.4797 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3508 (1.5915)  alignment_loss: 0.1960 (0.1829)  time: 1.1092 (1.2577)  data: 0.0131 (0.1418)  task_loss: 0.1337 (0.1313)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:05:08  iter: 380  loss: 2.3281 (2.6158)  loss_reg: 0.2258 (0.2456)  loss_centerness: 0.4779 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3128 (1.5896)  alignment_loss: 0.1933 (0.1830)  time: 1.1414 (1.2576)  data: 0.0134 (0.1417)  task_loss: 0.1337 (0.1313)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:04:42  iter: 400  loss: 2.3656 (2.6137)  loss_reg: 0.2259 (0.2455)  loss_centerness: 0.4791 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3431 (1.5874)  alignment_loss: 0.1904 (0.1830)  time: 1.1475 (1.2577)  data: 0.0134 (0.1417)  task_loss: 0.1337 (0.1313)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:04:17  iter: 420  loss: 2.3598 (2.6121)  loss_reg: 0.2424 (0.2455)  loss_centerness: 0.4771 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3419 (1.5856)  alignment_loss: 0.1871 (0.1830)  time: 1.1471 (1.2576)  data: 0.0134 (0.1416)  task_loss: 0.1337 (0.1313)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:03:52  iter: 440  loss: 2.3511 (2.6100)  loss_reg: 0.2329 (0.2455)  loss_centerness: 0.4791 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3265 (1.5835)  alignment_loss: 0.1836 (0.1831)  time: 1.1448 (1.2577)  data: 0.0132 (0.1415)  task_loss: 0.1337 (0.1313)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:03:27  iter: 460  loss: 2.2516 (2.6076)  loss_reg: 0.2181 (0.2453)  loss_centerness: 0.4759 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2562 (1.5811)  alignment_loss: 0.1798 (0.1830)  time: 1.1491 (1.2577)  data: 0.0133 (0.1414)  task_loss: 0.1336 (0.1314)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:03:02  iter: 480  loss: 2.3029 (2.6052)  loss_reg: 0.2268 (0.2453)  loss_centerness: 0.4768 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2775 (1.5787)  alignment_loss: 0.1758 (0.1830)  time: 1.1103 (1.2576)  data: 0.0121 (0.1414)  task_loss: 0.1336 (0.1314)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:02:37  iter: 500  loss: 2.1295 (2.6021)  loss_reg: 0.2165 (0.2452)  loss_centerness: 0.4788 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1354 (1.5757)  alignment_loss: 0.1715 (0.1829)  time: 1.1122 (1.2574)  data: 0.0109 (0.1412)  task_loss: 0.1336 (0.1314)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:02:12  iter: 520  loss: 2.2506 (2.5994)  loss_reg: 0.2434 (0.2452)  loss_centerness: 0.4801 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2288 (1.5729)  alignment_loss: 0.1670 (0.1828)  time: 1.1466 (1.2573)  data: 0.0124 (0.1411)  task_loss: 0.1336 (0.1314)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:01:46  iter: 540  loss: 2.2571 (2.5965)  loss_reg: 0.2239 (0.2451)  loss_centerness: 0.4754 (0.4797)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1963 (1.5702)  alignment_loss: 0.1624 (0.1826)  time: 1.1160 (1.2571)  data: 0.0125 (0.1410)  task_loss: 0.1336 (0.1314)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:01:21  iter: 560  loss: 2.1507 (2.5932)  loss_reg: 0.2292 (0.2449)  loss_centerness: 0.4775 (0.4796)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1236 (1.5672)  alignment_loss: 0.1577 (0.1824)  time: 1.1620 (1.2574)  data: 0.0135 (0.1412)  task_loss: 0.1336 (0.1315)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:56  iter: 580  loss: 2.2247 (2.5905)  loss_reg: 0.2313 (0.2449)  loss_centerness: 0.4768 (0.4796)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2272 (1.5647)  alignment_loss: 0.1528 (0.1822)  time: 1.1501 (1.2575)  data: 0.0137 (0.1411)  task_loss: 0.1336 (0.1315)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:31  iter: 600  loss: 2.1207 (2.5876)  loss_reg: 0.2391 (0.2449)  loss_centerness: 0.4792 (0.4796)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1422 (1.5619)  alignment_loss: 0.1479 (0.1819)  time: 1.1450 (1.2574)  data: 0.0134 (0.1410)  task_loss: 0.1336 (0.1315)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:06  iter: 620  loss: 2.1208 (2.5843)  loss_reg: 0.2253 (0.2447)  loss_centerness: 0.4765 (0.4796)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1349 (1.5589)  alignment_loss: 0.1429 (0.1817)  time: 1.1453 (1.2573)  data: 0.0136 (0.1410)  task_loss: 0.1336 (0.1315)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:00  iter: 625  loss: 2.1208 (2.5834)  loss_reg: 0.2253 (0.2447)  loss_centerness: 0.4774 (0.4796)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1349 (1.5581)  alignment_loss: 0.1415 (0.1816)  time: 1.1415 (1.2573)  data: 0.0133 (0.1409)  task_loss: 0.1336 (0.1315)  lr: 0.000000  wd: 0.000500  max mem: 12614
Evaluating
2024-03-19 11:19:36,025 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 11:19:44,927 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:19:44,931 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:19:44,964 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.4931506849315068, 0.5616438356164384] 

2024-03-19 11:19:44,965 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:19:44,965 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:19:44,965 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9178082191780822
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.4931506849315068, 0.5616438356164384], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:19:44,982 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 11:19:49,440 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:19:49,444 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 11:19:49,457 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25925925925925924, 0.7037037037037037, 0.8148148148148148] 

2024-03-19 11:19:49,457 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:19:49,457 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:19:49,457 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.25925925925925924, 0.7037037037037037, 0.8148148148148148], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:19:49,474 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 11:19:55,206 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:19:55,208 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:19:55,219 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25, 0.6590909090909091, 0.7727272727272727] 

2024-03-19 11:19:55,219 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:19:55,220 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:19:55,220 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.25, 0.6590909090909091, 0.7727272727272727], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:19:55,234 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 11:20:18,669 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:20:18,673 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:20:18,769 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.30980392156862746, 0.7803921568627451, 0.8941176470588236] 

2024-03-19 11:20:18,770 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:20:18,770 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:20:18,770 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8784313725490196
evaluate on task refcoco, val, 3, res: {'refcoco': [0.30980392156862746, 0.7803921568627451, 0.8941176470588236], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:20:18,787 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 11:20:38,603 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:20:38,606 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:20:38,678 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2571428571428571, 0.7857142857142857, 0.8666666666666667] 

2024-03-19 11:20:38,679 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:20:38,679 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:20:38,679 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9095238095238095
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2571428571428571, 0.7857142857142857, 0.8666666666666667], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:20:38,694 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 11:21:07,653 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:21:07,657 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:21:07,744 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.20261437908496732, 0.6895424836601307, 0.8333333333333334] 

2024-03-19 11:21:07,744 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:21:07,744 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:21:07,744 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9248366013071896
evaluate on task refcoco, val, 5, res: {'refcoco': [0.20261437908496732, 0.6895424836601307, 0.8333333333333334], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:21:07,788 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 11:21:09,073 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 11:21:10,313 maskrcnn_benchmark.trainer INFO: Total training time: 0:16:29.179492 (1.5827 s / it)
2024-03-19 11:21:10,325 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 11:21:10,326 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 11:21:10,326 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 11:21:10,326 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 11:21:10,326 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 11:21:10,326 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 11:21:10,326 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 11:21:10,326 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 11:21:10,326 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 11:21:10,326 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.6.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 11:21:10,327 maskrcnn_benchmark INFO: visual_prompt.6.dim_1 : Not Frozen, param number, 36
2024-03-19 11:21:10,327 maskrcnn_benchmark INFO: visual_prompt.6.dim_2 : Not Frozen, param number, 64
2024-03-19 11:21:10,327 maskrcnn_benchmark INFO: visual_prompt.6.dim_3 : Not Frozen, param number, 384
2024-03-19 11:21:10,327 maskrcnn_benchmark INFO: textual_prompt.6.dim_1 : Not Frozen, param number, 36
2024-03-19 11:21:10,327 maskrcnn_benchmark INFO: textual_prompt.6.dim_2 : Not Frozen, param number, 64
2024-03-19 11:21:10,327 maskrcnn_benchmark INFO: textual_prompt.6.dim_3 : Not Frozen, param number, 3072
2024-03-19 11:21:10,329 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 11:21:10,330 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=2.20s)
creating index...
index created!
2024-03-19 11:21:13,395 maskrcnn_benchmark INFO: Training on task 6: kitchen, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:21:13,596 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:21:13,777 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:21:13,958 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:21:14,140 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:21:14,320 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:21:15,604 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:21:15,790 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
2024-03-19 11:21:16,014 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:12:41  iter: 20  loss: 2.5283 (2.5827)  loss_reg: 0.1749 (0.2442)  loss_centerness: 0.4691 (0.4795)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5052 (1.5576)  alignment_loss: 0.2250 (0.1819)  time: 1.1441 (1.2580)  data: 0.0136 (0.1416)  task_loss: 0.1343 (0.1315)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:12:15  iter: 40  loss: 2.4836 (2.5824)  loss_reg: 0.1698 (0.2437)  loss_centerness: 0.4675 (0.4795)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5160 (1.5575)  alignment_loss: 0.2062 (0.1821)  time: 1.1131 (1.2578)  data: 0.0121 (0.1415)  task_loss: 0.1343 (0.1316)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:11:50  iter: 60  loss: 2.4426 (2.5819)  loss_reg: 0.1829 (0.2432)  loss_centerness: 0.4700 (0.4794)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5103 (1.5574)  alignment_loss: 0.1931 (0.1822)  time: 1.1478 (1.2577)  data: 0.0134 (0.1414)  task_loss: 0.1343 (0.1316)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:11:25  iter: 80  loss: 2.3746 (2.5812)  loss_reg: 0.1731 (0.2427)  loss_centerness: 0.4685 (0.4793)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3796 (1.5571)  alignment_loss: 0.1844 (0.1822)  time: 1.1117 (1.2576)  data: 0.0120 (0.1414)  task_loss: 0.1343 (0.1316)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:11:00  iter: 100  loss: 2.3607 (2.5801)  loss_reg: 0.1726 (0.2423)  loss_centerness: 0.4699 (0.4793)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4153 (1.5565)  alignment_loss: 0.1781 (0.1821)  time: 1.1383 (1.2575)  data: 0.0133 (0.1413)  task_loss: 0.1342 (0.1316)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:10:34  iter: 120  loss: 2.4815 (2.5791)  loss_reg: 0.1764 (0.2418)  loss_centerness: 0.4702 (0.4792)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5054 (1.5560)  alignment_loss: 0.1732 (0.1821)  time: 1.1188 (1.2573)  data: 0.0119 (0.1411)  task_loss: 0.1342 (0.1316)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:10:09  iter: 140  loss: 2.4189 (2.5776)  loss_reg: 0.1733 (0.2414)  loss_centerness: 0.4699 (0.4791)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4355 (1.5550)  alignment_loss: 0.1694 (0.1820)  time: 1.1576 (1.2572)  data: 0.0131 (0.1411)  task_loss: 0.1342 (0.1317)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:09:44  iter: 160  loss: 2.4007 (2.5764)  loss_reg: 0.1697 (0.2409)  loss_centerness: 0.4699 (0.4791)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4581 (1.5544)  alignment_loss: 0.1663 (0.1819)  time: 1.1476 (1.2572)  data: 0.0137 (0.1410)  task_loss: 0.1342 (0.1317)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:09:19  iter: 180  loss: 2.2808 (2.5751)  loss_reg: 0.1702 (0.2404)  loss_centerness: 0.4685 (0.4790)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3450 (1.5536)  alignment_loss: 0.1640 (0.1818)  time: 1.1406 (1.2571)  data: 0.0135 (0.1409)  task_loss: 0.1342 (0.1317)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:08:54  iter: 200  loss: 2.3357 (2.5737)  loss_reg: 0.1840 (0.2400)  loss_centerness: 0.4676 (0.4789)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4140 (1.5527)  alignment_loss: 0.1622 (0.1816)  time: 1.1133 (1.2571)  data: 0.0118 (0.1410)  task_loss: 0.1341 (0.1317)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:08:29  iter: 220  loss: 2.3110 (2.5722)  loss_reg: 0.1691 (0.2396)  loss_centerness: 0.4707 (0.4789)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3802 (1.5517)  alignment_loss: 0.1606 (0.1815)  time: 1.1083 (1.2569)  data: 0.0118 (0.1409)  task_loss: 0.1341 (0.1317)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:08:03  iter: 240  loss: 2.1853 (2.5699)  loss_reg: 0.1674 (0.2392)  loss_centerness: 0.4700 (0.4788)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2381 (1.5500)  alignment_loss: 0.1593 (0.1813)  time: 1.1537 (1.2569)  data: 0.0134 (0.1408)  task_loss: 0.1341 (0.1318)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:07:38  iter: 260  loss: 2.1106 (2.5675)  loss_reg: 0.1643 (0.2387)  loss_centerness: 0.4679 (0.4787)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1679 (1.5482)  alignment_loss: 0.1580 (0.1812)  time: 1.1482 (1.2569)  data: 0.0133 (0.1408)  task_loss: 0.1341 (0.1318)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:07:13  iter: 280  loss: 2.1488 (2.5648)  loss_reg: 0.1810 (0.2384)  loss_centerness: 0.4699 (0.4787)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2075 (1.5460)  alignment_loss: 0.1565 (0.1810)  time: 1.1117 (1.2567)  data: 0.0123 (0.1407)  task_loss: 0.1341 (0.1318)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:06:48  iter: 300  loss: 2.0984 (2.5620)  loss_reg: 0.1629 (0.2379)  loss_centerness: 0.4701 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1580 (1.5438)  alignment_loss: 0.1549 (0.1808)  time: 1.1123 (1.2566)  data: 0.0124 (0.1406)  task_loss: 0.1341 (0.1318)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:06:23  iter: 320  loss: 2.1783 (2.5596)  loss_reg: 0.1829 (0.2375)  loss_centerness: 0.4688 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2627 (1.5419)  alignment_loss: 0.1530 (0.1807)  time: 1.1477 (1.2568)  data: 0.0135 (0.1408)  task_loss: 0.1341 (0.1318)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:05:58  iter: 340  loss: 2.0362 (2.5565)  loss_reg: 0.1834 (0.2372)  loss_centerness: 0.4700 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0941 (1.5394)  alignment_loss: 0.1509 (0.1805)  time: 1.1144 (1.2566)  data: 0.0119 (0.1407)  task_loss: 0.1341 (0.1318)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:05:32  iter: 360  loss: 2.0473 (2.5537)  loss_reg: 0.1772 (0.2368)  loss_centerness: 0.4693 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1221 (1.5370)  alignment_loss: 0.1485 (0.1803)  time: 1.1531 (1.2566)  data: 0.0135 (0.1406)  task_loss: 0.1341 (0.1318)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:05:07  iter: 380  loss: 2.0315 (2.5505)  loss_reg: 0.1702 (0.2364)  loss_centerness: 0.4706 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1293 (1.5345)  alignment_loss: 0.1459 (0.1800)  time: 1.1167 (1.2564)  data: 0.0117 (0.1405)  task_loss: 0.1341 (0.1319)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:04:42  iter: 400  loss: 2.0809 (2.5475)  loss_reg: 0.1810 (0.2361)  loss_centerness: 0.4718 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1248 (1.5320)  alignment_loss: 0.1434 (0.1798)  time: 1.1343 (1.2563)  data: 0.0131 (0.1405)  task_loss: 0.1341 (0.1319)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:04:17  iter: 420  loss: 1.9686 (2.5439)  loss_reg: 0.1639 (0.2357)  loss_centerness: 0.4669 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0559 (1.5291)  alignment_loss: 0.1409 (0.1796)  time: 1.1518 (1.2563)  data: 0.0133 (0.1404)  task_loss: 0.1341 (0.1319)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:03:52  iter: 440  loss: 1.9702 (2.5404)  loss_reg: 0.1855 (0.2353)  loss_centerness: 0.4688 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0392 (1.5261)  alignment_loss: 0.1384 (0.1793)  time: 1.1133 (1.2564)  data: 0.0129 (0.1405)  task_loss: 0.1341 (0.1319)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:03:27  iter: 460  loss: 1.9170 (2.5368)  loss_reg: 0.1659 (0.2349)  loss_centerness: 0.4689 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0101 (1.5231)  alignment_loss: 0.1359 (0.1790)  time: 1.1124 (1.2562)  data: 0.0121 (0.1405)  task_loss: 0.1341 (0.1319)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:03:02  iter: 480  loss: 1.9082 (2.5334)  loss_reg: 0.1675 (0.2346)  loss_centerness: 0.4683 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9946 (1.5204)  alignment_loss: 0.1333 (0.1787)  time: 1.1458 (1.2561)  data: 0.0134 (0.1404)  task_loss: 0.1341 (0.1319)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:02:37  iter: 500  loss: 1.9659 (2.5298)  loss_reg: 0.1729 (0.2342)  loss_centerness: 0.4705 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0541 (1.5175)  alignment_loss: 0.1307 (0.1784)  time: 1.1521 (1.2562)  data: 0.0138 (0.1403)  task_loss: 0.1341 (0.1320)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:02:11  iter: 520  loss: 1.9452 (2.5262)  loss_reg: 0.1584 (0.2338)  loss_centerness: 0.4678 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0427 (1.5145)  alignment_loss: 0.1279 (0.1781)  time: 1.1483 (1.2562)  data: 0.0135 (0.1403)  task_loss: 0.1341 (0.1320)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:01:46  iter: 540  loss: 1.9363 (2.5228)  loss_reg: 0.1763 (0.2335)  loss_centerness: 0.4685 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0226 (1.5117)  alignment_loss: 0.1249 (0.1778)  time: 1.1204 (1.2561)  data: 0.0119 (0.1403)  task_loss: 0.1342 (0.1320)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:01:21  iter: 560  loss: 1.9435 (2.5194)  loss_reg: 0.1669 (0.2332)  loss_centerness: 0.4708 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0410 (1.5089)  alignment_loss: 0.1217 (0.1775)  time: 1.1115 (1.2562)  data: 0.0120 (0.1404)  task_loss: 0.1342 (0.1320)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:56  iter: 580  loss: 1.9018 (2.5156)  loss_reg: 0.1784 (0.2329)  loss_centerness: 0.4700 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 0.9773 (1.5057)  alignment_loss: 0.1184 (0.1771)  time: 1.1453 (1.2562)  data: 0.0124 (0.1404)  task_loss: 0.1342 (0.1320)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:31  iter: 600  loss: 1.8968 (2.5120)  loss_reg: 0.1678 (0.2325)  loss_centerness: 0.4697 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0341 (1.5029)  alignment_loss: 0.1147 (0.1767)  time: 1.1496 (1.2562)  data: 0.0124 (0.1403)  task_loss: 0.1342 (0.1320)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:06  iter: 620  loss: 1.8952 (2.5086)  loss_reg: 0.1747 (0.2322)  loss_centerness: 0.4683 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0149 (1.5001)  alignment_loss: 0.1108 (0.1763)  time: 1.1386 (1.2561)  data: 0.0121 (0.1403)  task_loss: 0.1342 (0.1320)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:00  iter: 625  loss: 1.8928 (2.5077)  loss_reg: 0.1573 (0.2321)  loss_centerness: 0.4675 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0149 (1.4994)  alignment_loss: 0.1096 (0.1762)  time: 1.1070 (1.2561)  data: 0.0109 (0.1402)  task_loss: 0.1343 (0.1320)  lr: 0.000000  wd: 0.000500  max mem: 12614
Evaluating
2024-03-19 11:36:08,532 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 11:36:16,610 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:36:16,614 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:36:16,635 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.4931506849315068, 0.589041095890411] 

2024-03-19 11:36:16,636 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:36:16,636 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:36:16,636 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9178082191780822
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.4931506849315068, 0.589041095890411], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:36:16,654 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 11:36:20,833 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:36:20,836 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 11:36:20,847 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2962962962962963, 0.7037037037037037, 0.8518518518518519] 

2024-03-19 11:36:20,847 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:36:20,847 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:36:20,847 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2962962962962963, 0.7037037037037037, 0.8518518518518519], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:36:20,865 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 11:36:27,370 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:36:27,372 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:36:27,383 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25, 0.6590909090909091, 0.7727272727272727] 

2024-03-19 11:36:27,384 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:36:27,384 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:36:27,384 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.25, 0.6590909090909091, 0.7727272727272727], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:36:27,402 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 11:36:51,665 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:36:51,668 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:36:51,748 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3137254901960784, 0.7843137254901961, 0.8941176470588236] 

2024-03-19 11:36:51,748 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:36:51,748 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:36:51,748 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8784313725490196
evaluate on task refcoco, val, 3, res: {'refcoco': [0.3137254901960784, 0.7843137254901961, 0.8941176470588236], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:36:51,763 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 11:37:11,320 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:37:11,324 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:37:11,394 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.26666666666666666, 0.7857142857142857, 0.861904761904762] 

2024-03-19 11:37:11,394 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:37:11,394 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:37:11,394 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9095238095238095
evaluate on task refcoco, val, 4, res: {'refcoco': [0.26666666666666666, 0.7857142857142857, 0.861904761904762], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:37:11,410 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 11:37:39,967 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:37:39,970 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:37:40,058 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.21895424836601307, 0.696078431372549, 0.8431372549019608] 

2024-03-19 11:37:40,058 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:37:40,058 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:37:40,058 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8954248366013072
evaluate on task refcoco, val, 5, res: {'refcoco': [0.21895424836601307, 0.696078431372549, 0.8431372549019608], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:37:40,074 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 11:38:22,377 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:38:22,383 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:38:22,540 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.35864978902953587, 0.9029535864978903, 0.9662447257383966] 

2024-03-19 11:38:22,541 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:38:22,541 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:38:22,541 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9430379746835443
evaluate on task refcoco, val, 6, res: {'refcoco': [0.35864978902953587, 0.9029535864978903, 0.9662447257383966], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:38:22,592 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 11:38:24,573 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 11:38:25,774 maskrcnn_benchmark.trainer INFO: Total training time: 0:17:09.746325 (1.6476 s / it)
2024-03-19 11:38:25,792 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 11:38:25,792 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 11:38:25,792 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 11:38:25,792 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 11:38:25,792 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 11:38:25,792 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 11:38:25,792 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 11:38:25,792 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 11:38:25,793 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 11:38:25,793 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.7.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 11:38:25,793 maskrcnn_benchmark INFO: visual_prompt.7.dim_1 : Not Frozen, param number, 36
2024-03-19 11:38:25,793 maskrcnn_benchmark INFO: visual_prompt.7.dim_2 : Not Frozen, param number, 64
2024-03-19 11:38:25,794 maskrcnn_benchmark INFO: visual_prompt.7.dim_3 : Not Frozen, param number, 384
2024-03-19 11:38:25,794 maskrcnn_benchmark INFO: textual_prompt.7.dim_1 : Not Frozen, param number, 36
2024-03-19 11:38:25,794 maskrcnn_benchmark INFO: textual_prompt.7.dim_2 : Not Frozen, param number, 64
2024-03-19 11:38:25,794 maskrcnn_benchmark INFO: textual_prompt.7.dim_3 : Not Frozen, param number, 3072
2024-03-19 11:38:25,796 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 11:38:25,796 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.47s)
creating index...
index created!
2024-03-19 11:38:28,154 maskrcnn_benchmark INFO: Training on task 7: furniture, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.01s)
creating index...
index created!
2024-03-19 11:38:29,303 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:38:29,483 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:38:29,668 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:38:29,848 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 11:38:30,031 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 11:38:30,220 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:38:30,404 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:38:30,588 maskrcnn_benchmark INFO: Testing on task 7: furniture, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
2024-03-19 11:38:30,829 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:12:40  iter: 20  loss: 2.5999 (2.5082)  loss_reg: 0.2751 (0.2324)  loss_centerness: 0.4820 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4687 (1.4994)  alignment_loss: 0.2096 (0.1764)  time: 1.2233 (1.2573)  data: 0.1310 (0.1415)  task_loss: 0.1353 (0.1321)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:12:15  iter: 40  loss: 2.6768 (2.5090)  loss_reg: 0.2703 (0.2327)  loss_centerness: 0.4844 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5397 (1.4996)  alignment_loss: 0.2082 (0.1766)  time: 1.2098 (1.2572)  data: 0.1201 (0.1414)  task_loss: 0.1353 (0.1321)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:11:50  iter: 60  loss: 2.5798 (2.5098)  loss_reg: 0.2606 (0.2329)  loss_centerness: 0.4804 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4788 (1.4999)  alignment_loss: 0.2065 (0.1768)  time: 1.2378 (1.2571)  data: 0.1284 (0.1413)  task_loss: 0.1353 (0.1321)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:11:25  iter: 80  loss: 2.5518 (2.5105)  loss_reg: 0.2854 (0.2332)  loss_centerness: 0.4822 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4813 (1.5000)  alignment_loss: 0.2045 (0.1769)  time: 1.2502 (1.2570)  data: 0.1243 (0.1413)  task_loss: 0.1353 (0.1321)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:10:59  iter: 100  loss: 2.5123 (2.5107)  loss_reg: 0.2628 (0.2333)  loss_centerness: 0.4817 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4138 (1.4998)  alignment_loss: 0.2022 (0.1771)  time: 1.2216 (1.2569)  data: 0.1235 (0.1412)  task_loss: 0.1353 (0.1321)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:10:34  iter: 120  loss: 2.6309 (2.5118)  loss_reg: 0.2821 (0.2336)  loss_centerness: 0.4831 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5433 (1.5004)  alignment_loss: 0.1999 (0.1772)  time: 1.2127 (1.2567)  data: 0.1169 (0.1411)  task_loss: 0.1353 (0.1322)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:10:09  iter: 140  loss: 2.6988 (2.5129)  loss_reg: 0.2620 (0.2338)  loss_centerness: 0.4802 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5786 (1.5011)  alignment_loss: 0.1972 (0.1773)  time: 1.2572 (1.2568)  data: 0.1260 (0.1410)  task_loss: 0.1353 (0.1322)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:09:44  iter: 160  loss: 2.5584 (2.5131)  loss_reg: 0.2638 (0.2340)  loss_centerness: 0.4839 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4482 (1.5009)  alignment_loss: 0.1943 (0.1774)  time: 1.2599 (1.2568)  data: 0.1292 (0.1410)  task_loss: 0.1353 (0.1322)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:09:19  iter: 180  loss: 2.6339 (2.5136)  loss_reg: 0.2919 (0.2343)  loss_centerness: 0.4824 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5002 (1.5009)  alignment_loss: 0.1912 (0.1775)  time: 1.2168 (1.2567)  data: 0.1283 (0.1410)  task_loss: 0.1354 (0.1322)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:08:54  iter: 200  loss: 2.4585 (2.5136)  loss_reg: 0.2677 (0.2345)  loss_centerness: 0.4806 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4135 (1.5006)  alignment_loss: 0.1880 (0.1776)  time: 1.2340 (1.2567)  data: 0.1337 (0.1409)  task_loss: 0.1354 (0.1322)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:08:28  iter: 220  loss: 2.5626 (2.5141)  loss_reg: 0.2561 (0.2347)  loss_centerness: 0.4796 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4733 (1.5008)  alignment_loss: 0.1848 (0.1776)  time: 1.2527 (1.2566)  data: 0.1271 (0.1409)  task_loss: 0.1354 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:08:03  iter: 240  loss: 2.5445 (2.5144)  loss_reg: 0.2881 (0.2350)  loss_centerness: 0.4824 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4109 (1.5007)  alignment_loss: 0.1818 (0.1776)  time: 1.2158 (1.2565)  data: 0.1205 (0.1408)  task_loss: 0.1354 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:07:38  iter: 260  loss: 2.6222 (2.5150)  loss_reg: 0.2758 (0.2352)  loss_centerness: 0.4830 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4941 (1.5009)  alignment_loss: 0.1790 (0.1776)  time: 1.2140 (1.2563)  data: 0.1223 (0.1407)  task_loss: 0.1354 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:07:13  iter: 280  loss: 2.6224 (2.5157)  loss_reg: 0.2731 (0.2355)  loss_centerness: 0.4840 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5295 (1.5013)  alignment_loss: 0.1763 (0.1776)  time: 1.2386 (1.2564)  data: 0.1297 (0.1409)  task_loss: 0.1354 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:06:48  iter: 300  loss: 2.3547 (2.5152)  loss_reg: 0.2627 (0.2357)  loss_centerness: 0.4836 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3283 (1.5005)  alignment_loss: 0.1737 (0.1776)  time: 1.2295 (1.2563)  data: 0.1265 (0.1408)  task_loss: 0.1354 (0.1323)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:06:23  iter: 320  loss: 2.4591 (2.5153)  loss_reg: 0.2725 (0.2359)  loss_centerness: 0.4841 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4037 (1.5003)  alignment_loss: 0.1715 (0.1776)  time: 1.2582 (1.2563)  data: 0.1303 (0.1408)  task_loss: 0.1354 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:05:58  iter: 340  loss: 2.4794 (2.5153)  loss_reg: 0.2616 (0.2361)  loss_centerness: 0.4813 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4420 (1.5001)  alignment_loss: 0.1694 (0.1775)  time: 1.2600 (1.2563)  data: 0.1302 (0.1407)  task_loss: 0.1354 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:05:32  iter: 360  loss: 2.5446 (2.5154)  loss_reg: 0.2869 (0.2364)  loss_centerness: 0.4826 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5025 (1.4999)  alignment_loss: 0.1675 (0.1775)  time: 1.2272 (1.2563)  data: 0.1257 (0.1407)  task_loss: 0.1354 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:05:07  iter: 380  loss: 2.5453 (2.5154)  loss_reg: 0.2547 (0.2366)  loss_centerness: 0.4810 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4632 (1.4996)  alignment_loss: 0.1658 (0.1774)  time: 1.2276 (1.2562)  data: 0.1269 (0.1406)  task_loss: 0.1354 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:04:42  iter: 400  loss: 2.5723 (2.5154)  loss_reg: 0.2892 (0.2369)  loss_centerness: 0.4858 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4487 (1.4993)  alignment_loss: 0.1643 (0.1773)  time: 1.2622 (1.2564)  data: 0.1302 (0.1408)  task_loss: 0.1354 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:04:17  iter: 420  loss: 2.4496 (2.5148)  loss_reg: 0.2675 (0.2370)  loss_centerness: 0.4798 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3708 (1.4985)  alignment_loss: 0.1630 (0.1773)  time: 1.2774 (1.2565)  data: 0.1297 (0.1407)  task_loss: 0.1354 (0.1324)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:03:52  iter: 440  loss: 2.3784 (2.5141)  loss_reg: 0.2502 (0.2371)  loss_centerness: 0.4795 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2933 (1.4978)  alignment_loss: 0.1619 (0.1772)  time: 1.2303 (1.2565)  data: 0.1283 (0.1407)  task_loss: 0.1354 (0.1325)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:03:27  iter: 460  loss: 2.4236 (2.5138)  loss_reg: 0.2720 (0.2374)  loss_centerness: 0.4814 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3776 (1.4973)  alignment_loss: 0.1609 (0.1771)  time: 1.2572 (1.2565)  data: 0.1288 (0.1407)  task_loss: 0.1354 (0.1325)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:03:02  iter: 480  loss: 2.3270 (2.5132)  loss_reg: 0.2661 (0.2376)  loss_centerness: 0.4831 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2550 (1.4964)  alignment_loss: 0.1600 (0.1770)  time: 1.2548 (1.2565)  data: 0.1286 (0.1406)  task_loss: 0.1355 (0.1325)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:02:37  iter: 500  loss: 2.4322 (2.5127)  loss_reg: 0.2765 (0.2379)  loss_centerness: 0.4833 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3564 (1.4957)  alignment_loss: 0.1591 (0.1769)  time: 1.2250 (1.2564)  data: 0.1291 (0.1405)  task_loss: 0.1355 (0.1325)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:02:11  iter: 520  loss: 2.2966 (2.5118)  loss_reg: 0.2715 (0.2380)  loss_centerness: 0.4819 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2655 (1.4947)  alignment_loss: 0.1583 (0.1768)  time: 1.2029 (1.2565)  data: 0.1166 (0.1408)  task_loss: 0.1355 (0.1325)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:01:46  iter: 540  loss: 2.3041 (2.5111)  loss_reg: 0.2604 (0.2382)  loss_centerness: 0.4799 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2762 (1.4938)  alignment_loss: 0.1576 (0.1767)  time: 1.2568 (1.2567)  data: 0.1216 (0.1409)  task_loss: 0.1355 (0.1325)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:01:21  iter: 560  loss: 2.3024 (2.5101)  loss_reg: 0.2756 (0.2384)  loss_centerness: 0.4829 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2173 (1.4925)  alignment_loss: 0.1570 (0.1766)  time: 1.2370 (1.2567)  data: 0.1293 (0.1409)  task_loss: 0.1355 (0.1326)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:56  iter: 580  loss: 2.2827 (2.5092)  loss_reg: 0.2823 (0.2386)  loss_centerness: 0.4824 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2071 (1.4914)  alignment_loss: 0.1563 (0.1765)  time: 1.2623 (1.2567)  data: 0.1287 (0.1409)  task_loss: 0.1355 (0.1326)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:31  iter: 600  loss: 2.3529 (2.5082)  loss_reg: 0.2566 (0.2387)  loss_centerness: 0.4813 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2999 (1.4904)  alignment_loss: 0.1556 (0.1764)  time: 1.2603 (1.2567)  data: 0.1275 (0.1408)  task_loss: 0.1355 (0.1326)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:06  iter: 620  loss: 2.2430 (2.5070)  loss_reg: 0.2754 (0.2389)  loss_centerness: 0.4837 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2031 (1.4890)  alignment_loss: 0.1549 (0.1763)  time: 1.2268 (1.2566)  data: 0.1288 (0.1408)  task_loss: 0.1354 (0.1326)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:00  iter: 625  loss: 2.2860 (2.5070)  loss_reg: 0.2779 (0.2390)  loss_centerness: 0.4837 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2281 (1.4890)  alignment_loss: 0.1546 (0.1763)  time: 1.2730 (1.2567)  data: 0.1342 (0.1408)  task_loss: 0.1354 (0.1326)  lr: 0.000000  wd: 0.000500  max mem: 12614
Evaluating
2024-03-19 11:53:28,811 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 11:53:36,939 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:53:36,942 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:53:36,964 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.4794520547945205, 0.589041095890411] 

2024-03-19 11:53:36,964 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:53:36,965 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:53:36,966 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8493150684931506
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.4794520547945205, 0.589041095890411], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:53:36,980 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 11:53:41,574 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:53:41,578 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 11:53:41,591 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2962962962962963, 0.7407407407407407, 0.8518518518518519] 

2024-03-19 11:53:41,591 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:53:41,591 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:53:41,591 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2962962962962963, 0.7407407407407407, 0.8518518518518519], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:53:41,609 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 11:53:48,519 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:53:48,522 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:53:48,541 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25, 0.6590909090909091, 0.7727272727272727] 

2024-03-19 11:53:48,542 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:53:48,542 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:53:48,542 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.25, 0.6590909090909091, 0.7727272727272727], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:53:48,564 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 11:54:12,102 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:54:12,106 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:54:12,198 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3137254901960784, 0.7764705882352941, 0.8862745098039215] 

2024-03-19 11:54:12,199 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:54:12,199 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:54:12,199 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8549019607843137
evaluate on task refcoco, val, 3, res: {'refcoco': [0.3137254901960784, 0.7764705882352941, 0.8862745098039215], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:54:12,217 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 11:54:33,138 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:54:33,142 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:54:33,224 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2714285714285714, 0.780952380952381, 0.8571428571428571] 

2024-03-19 11:54:33,224 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:54:33,224 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:54:33,224 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8809523809523809
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2714285714285714, 0.780952380952381, 0.8571428571428571], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:54:33,242 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 11:55:01,928 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:55:01,935 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:55:02,045 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.22549019607843138, 0.6928104575163399, 0.8366013071895425] 

2024-03-19 11:55:02,045 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:55:02,045 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:55:02,046 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8954248366013072
evaluate on task refcoco, val, 5, res: {'refcoco': [0.22549019607843138, 0.6928104575163399, 0.8366013071895425], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:55:02,065 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 11:55:45,412 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:55:45,416 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:55:45,544 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3649789029535865, 0.9071729957805907, 0.9641350210970464] 

2024-03-19 11:55:45,545 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:55:45,545 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:55:45,545 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9261603375527426
evaluate on task refcoco, val, 6, res: {'refcoco': [0.3649789029535865, 0.9071729957805907, 0.9641350210970464], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:55:45,561 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 7
2024-03-19 11:56:30,180 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 11:56:30,183 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 11:56:30,360 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.306, 0.784, 0.838] 

2024-03-19 11:56:30,361 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 11:56:30,361 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 11:56:30,361 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.616
evaluate on task refcoco, val, 7, res: {'refcoco': [0.306, 0.784, 0.838], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 11:56:30,405 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 11:56:31,505 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 11:56:32,869 maskrcnn_benchmark.trainer INFO: Total training time: 0:18:02.025344 (1.7312 s / it)
2024-03-19 11:56:32,884 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 11:56:32,884 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 11:56:32,884 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 11:56:32,884 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 11:56:32,884 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 11:56:32,884 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 11:56:32,884 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 11:56:32,884 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 11:56:32,885 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 11:56:32,885 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.8.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 11:56:32,886 maskrcnn_benchmark INFO: visual_prompt.8.dim_1 : Not Frozen, param number, 36
2024-03-19 11:56:32,886 maskrcnn_benchmark INFO: visual_prompt.8.dim_2 : Not Frozen, param number, 64
2024-03-19 11:56:32,886 maskrcnn_benchmark INFO: visual_prompt.8.dim_3 : Not Frozen, param number, 384
2024-03-19 11:56:32,886 maskrcnn_benchmark INFO: textual_prompt.8.dim_1 : Not Frozen, param number, 36
2024-03-19 11:56:32,886 maskrcnn_benchmark INFO: textual_prompt.8.dim_2 : Not Frozen, param number, 64
2024-03-19 11:56:32,886 maskrcnn_benchmark INFO: textual_prompt.8.dim_3 : Not Frozen, param number, 3072
2024-03-19 11:56:32,889 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 11:56:32,889 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.61s)
creating index...
index created!
2024-03-19 11:56:35,367 maskrcnn_benchmark INFO: Training on task 8: vehicle, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.05s)
creating index...
index created!
2024-03-19 11:56:36,559 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:56:36,742 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:56:36,924 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:56:37,107 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:56:37,290 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:56:37,476 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:56:37,659 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 11:56:37,843 maskrcnn_benchmark INFO: Testing on task 7: furniture, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.37s)
creating index...
index created!
2024-03-19 11:56:39,332 maskrcnn_benchmark INFO: Testing on task 8: vehicle, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
2024-03-19 11:56:39,596 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:12:40  iter: 20  loss: 2.5485 (2.5075)  loss_reg: 0.2307 (0.2390)  loss_centerness: 0.4771 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4767 (1.4892)  alignment_loss: 0.2191 (0.1765)  time: 1.2397 (1.2571)  data: 0.1318 (0.1412)  task_loss: 0.1351 (0.1326)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:12:15  iter: 40  loss: 2.5969 (2.5078)  loss_reg: 0.2447 (0.2391)  loss_centerness: 0.4790 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5281 (1.4892)  alignment_loss: 0.2156 (0.1767)  time: 1.2559 (1.2571)  data: 0.1305 (0.1412)  task_loss: 0.1351 (0.1326)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:11:50  iter: 60  loss: 2.6088 (2.5086)  loss_reg: 0.2589 (0.2392)  loss_centerness: 0.4807 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5201 (1.4896)  alignment_loss: 0.2122 (0.1769)  time: 1.2336 (1.2570)  data: 0.1170 (0.1411)  task_loss: 0.1351 (0.1326)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:11:24  iter: 80  loss: 2.5324 (2.5089)  loss_reg: 0.2571 (0.2392)  loss_centerness: 0.4780 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4449 (1.4897)  alignment_loss: 0.2092 (0.1770)  time: 1.2040 (1.2568)  data: 0.1157 (0.1410)  task_loss: 0.1351 (0.1327)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:10:59  iter: 100  loss: 2.5775 (2.5092)  loss_reg: 0.2552 (0.2393)  loss_centerness: 0.4790 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5173 (1.4897)  alignment_loss: 0.2063 (0.1772)  time: 1.2611 (1.2567)  data: 0.1302 (0.1409)  task_loss: 0.1351 (0.1327)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:10:34  iter: 120  loss: 2.5298 (2.5094)  loss_reg: 0.2431 (0.2393)  loss_centerness: 0.4786 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4576 (1.4897)  alignment_loss: 0.2034 (0.1773)  time: 1.2587 (1.2568)  data: 0.1266 (0.1409)  task_loss: 0.1351 (0.1327)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:10:09  iter: 140  loss: 2.5848 (2.5099)  loss_reg: 0.2524 (0.2394)  loss_centerness: 0.4795 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5127 (1.4899)  alignment_loss: 0.2005 (0.1774)  time: 1.2352 (1.2567)  data: 0.1335 (0.1409)  task_loss: 0.1351 (0.1327)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:09:44  iter: 160  loss: 2.4980 (2.5099)  loss_reg: 0.2289 (0.2394)  loss_centerness: 0.4773 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4574 (1.4898)  alignment_loss: 0.1975 (0.1775)  time: 1.2576 (1.2567)  data: 0.1291 (0.1408)  task_loss: 0.1351 (0.1327)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:09:19  iter: 180  loss: 2.5044 (2.5100)  loss_reg: 0.2619 (0.2395)  loss_centerness: 0.4785 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4462 (1.4897)  alignment_loss: 0.1945 (0.1776)  time: 1.2125 (1.2566)  data: 0.1209 (0.1408)  task_loss: 0.1351 (0.1327)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:08:54  iter: 200  loss: 2.5918 (2.5105)  loss_reg: 0.2561 (0.2396)  loss_centerness: 0.4801 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5406 (1.4900)  alignment_loss: 0.1915 (0.1777)  time: 1.2481 (1.2566)  data: 0.1304 (0.1407)  task_loss: 0.1351 (0.1327)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:08:28  iter: 220  loss: 2.4202 (2.5102)  loss_reg: 0.2373 (0.2396)  loss_centerness: 0.4771 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3720 (1.4896)  alignment_loss: 0.1886 (0.1777)  time: 1.2237 (1.2565)  data: 0.1232 (0.1407)  task_loss: 0.1352 (0.1327)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:08:03  iter: 240  loss: 2.4885 (2.5104)  loss_reg: 0.2429 (0.2396)  loss_centerness: 0.4772 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4578 (1.4897)  alignment_loss: 0.1858 (0.1777)  time: 1.2501 (1.2567)  data: 0.1310 (0.1408)  task_loss: 0.1352 (0.1328)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:07:38  iter: 260  loss: 2.4541 (2.5103)  loss_reg: 0.2563 (0.2397)  loss_centerness: 0.4822 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4608 (1.4894)  alignment_loss: 0.1833 (0.1778)  time: 1.2697 (1.2566)  data: 0.1339 (0.1408)  task_loss: 0.1352 (0.1328)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:07:13  iter: 280  loss: 2.4127 (2.5100)  loss_reg: 0.2517 (0.2397)  loss_centerness: 0.4782 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3709 (1.4890)  alignment_loss: 0.1809 (0.1778)  time: 1.2317 (1.2566)  data: 0.1240 (0.1408)  task_loss: 0.1352 (0.1328)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:06:48  iter: 300  loss: 2.4421 (2.5098)  loss_reg: 0.2431 (0.2398)  loss_centerness: 0.4773 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3996 (1.4887)  alignment_loss: 0.1789 (0.1778)  time: 1.2613 (1.2566)  data: 0.1273 (0.1407)  task_loss: 0.1352 (0.1328)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:06:23  iter: 320  loss: 2.3384 (2.5093)  loss_reg: 0.2528 (0.2398)  loss_centerness: 0.4803 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3268 (1.4881)  alignment_loss: 0.1771 (0.1778)  time: 1.2635 (1.2566)  data: 0.1334 (0.1407)  task_loss: 0.1352 (0.1328)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:05:58  iter: 340  loss: 2.3798 (2.5087)  loss_reg: 0.2368 (0.2398)  loss_centerness: 0.4772 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3670 (1.4874)  alignment_loss: 0.1756 (0.1778)  time: 1.2586 (1.2566)  data: 0.1277 (0.1407)  task_loss: 0.1352 (0.1328)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:05:33  iter: 360  loss: 2.4510 (2.5084)  loss_reg: 0.2572 (0.2399)  loss_centerness: 0.4785 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3444 (1.4870)  alignment_loss: 0.1742 (0.1778)  time: 1.2236 (1.2566)  data: 0.1227 (0.1408)  task_loss: 0.1352 (0.1328)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:05:07  iter: 380  loss: 2.3902 (2.5080)  loss_reg: 0.2458 (0.2400)  loss_centerness: 0.4811 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3578 (1.4865)  alignment_loss: 0.1728 (0.1777)  time: 1.2256 (1.2566)  data: 0.1280 (0.1407)  task_loss: 0.1352 (0.1328)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:04:42  iter: 400  loss: 2.2997 (2.5072)  loss_reg: 0.2473 (0.2400)  loss_centerness: 0.4792 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2906 (1.4857)  alignment_loss: 0.1716 (0.1777)  time: 1.2195 (1.2565)  data: 0.1269 (0.1407)  task_loss: 0.1352 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:04:17  iter: 420  loss: 2.3506 (2.5065)  loss_reg: 0.2419 (0.2401)  loss_centerness: 0.4787 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3347 (1.4849)  alignment_loss: 0.1704 (0.1777)  time: 1.2279 (1.2564)  data: 0.1285 (0.1406)  task_loss: 0.1352 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:03:52  iter: 440  loss: 2.3163 (2.5058)  loss_reg: 0.2480 (0.2402)  loss_centerness: 0.4793 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2359 (1.4841)  alignment_loss: 0.1691 (0.1776)  time: 1.2199 (1.2564)  data: 0.1289 (0.1406)  task_loss: 0.1352 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:03:27  iter: 460  loss: 2.2707 (2.5048)  loss_reg: 0.2390 (0.2402)  loss_centerness: 0.4766 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2435 (1.4831)  alignment_loss: 0.1679 (0.1776)  time: 1.2393 (1.2563)  data: 0.1275 (0.1405)  task_loss: 0.1352 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:03:02  iter: 480  loss: 2.2329 (2.5039)  loss_reg: 0.2420 (0.2402)  loss_centerness: 0.4795 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1881 (1.4821)  alignment_loss: 0.1667 (0.1775)  time: 1.2410 (1.2563)  data: 0.1302 (0.1405)  task_loss: 0.1353 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:02:37  iter: 500  loss: 2.2166 (2.5029)  loss_reg: 0.2496 (0.2402)  loss_centerness: 0.4794 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2169 (1.4811)  alignment_loss: 0.1655 (0.1775)  time: 1.2175 (1.2564)  data: 0.1246 (0.1406)  task_loss: 0.1353 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:02:11  iter: 520  loss: 2.2171 (2.5019)  loss_reg: 0.2480 (0.2403)  loss_centerness: 0.4782 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1831 (1.4800)  alignment_loss: 0.1642 (0.1774)  time: 1.2121 (1.2563)  data: 0.1217 (0.1406)  task_loss: 0.1353 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:01:46  iter: 540  loss: 2.2361 (2.5006)  loss_reg: 0.2451 (0.2403)  loss_centerness: 0.4791 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1905 (1.4788)  alignment_loss: 0.1630 (0.1774)  time: 1.2261 (1.2562)  data: 0.1317 (0.1405)  task_loss: 0.1353 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:01:21  iter: 560  loss: 2.1735 (2.4993)  loss_reg: 0.2331 (0.2403)  loss_centerness: 0.4772 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1636 (1.4775)  alignment_loss: 0.1618 (0.1773)  time: 1.2471 (1.2562)  data: 0.1218 (0.1405)  task_loss: 0.1353 (0.1329)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:56  iter: 580  loss: 2.2670 (2.4983)  loss_reg: 0.2554 (0.2404)  loss_centerness: 0.4785 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2499 (1.4765)  alignment_loss: 0.1606 (0.1772)  time: 1.2410 (1.2561)  data: 0.1241 (0.1404)  task_loss: 0.1353 (0.1330)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:31  iter: 600  loss: 2.1502 (2.4967)  loss_reg: 0.2450 (0.2404)  loss_centerness: 0.4788 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1153 (1.4748)  alignment_loss: 0.1593 (0.1772)  time: 1.2180 (1.2560)  data: 0.1222 (0.1404)  task_loss: 0.1353 (0.1330)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:06  iter: 620  loss: 2.1806 (2.4951)  loss_reg: 0.2385 (0.2405)  loss_centerness: 0.4777 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0957 (1.4733)  alignment_loss: 0.1579 (0.1771)  time: 1.2160 (1.2561)  data: 0.1192 (0.1405)  task_loss: 0.1353 (0.1330)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:00:00  iter: 625  loss: 2.1959 (2.4948)  loss_reg: 0.2385 (0.2405)  loss_centerness: 0.4777 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1447 (1.4729)  alignment_loss: 0.1575 (0.1770)  time: 1.2547 (1.2561)  data: 0.1242 (0.1405)  task_loss: 0.1353 (0.1330)  lr: 0.000000  wd: 0.000500  max mem: 12614
Evaluating
2024-03-19 12:11:30,280 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 12:11:38,911 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:11:38,915 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:11:38,944 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.4794520547945205, 0.589041095890411] 

2024-03-19 12:11:38,945 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:11:38,945 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:11:38,945 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8493150684931506
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.4794520547945205, 0.589041095890411], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:11:38,962 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 12:11:43,410 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:11:43,413 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 12:11:43,424 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2962962962962963, 0.7407407407407407, 0.8518518518518519] 

2024-03-19 12:11:43,424 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:11:43,424 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:11:43,424 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2962962962962963, 0.7407407407407407, 0.8518518518518519], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:11:43,439 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 12:11:49,954 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:11:49,956 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:11:49,968 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25, 0.6590909090909091, 0.7727272727272727] 

2024-03-19 12:11:49,968 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:11:49,968 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:11:49,968 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.25, 0.6590909090909091, 0.7727272727272727], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:11:49,987 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 12:12:14,794 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:12:14,799 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:12:14,895 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3137254901960784, 0.7764705882352941, 0.8862745098039215] 

2024-03-19 12:12:14,896 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:12:14,896 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:12:14,896 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8549019607843137
evaluate on task refcoco, val, 3, res: {'refcoco': [0.3137254901960784, 0.7764705882352941, 0.8862745098039215], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:12:14,914 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 12:12:35,725 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:12:35,728 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:12:35,810 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2714285714285714, 0.7857142857142857, 0.8571428571428571] 

2024-03-19 12:12:35,810 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:12:35,811 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:12:35,811 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8809523809523809
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2714285714285714, 0.7857142857142857, 0.8571428571428571], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:12:35,831 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 12:13:04,907 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:13:04,911 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:13:04,998 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.22549019607843138, 0.7026143790849673, 0.8366013071895425] 

2024-03-19 12:13:04,998 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:13:04,998 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:13:04,999 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8954248366013072
evaluate on task refcoco, val, 5, res: {'refcoco': [0.22549019607843138, 0.7026143790849673, 0.8366013071895425], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:13:05,014 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 12:13:47,307 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:13:47,311 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:13:47,440 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.36075949367088606, 0.9008438818565401, 0.9641350210970464] 

2024-03-19 12:13:47,441 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:13:47,441 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:13:47,441 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9261603375527426
evaluate on task refcoco, val, 6, res: {'refcoco': [0.36075949367088606, 0.9008438818565401, 0.9641350210970464], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:13:47,458 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 7
2024-03-19 12:14:33,062 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:14:33,066 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:14:33,277 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.308, 0.784, 0.842] 

2024-03-19 12:14:33,277 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:14:33,277 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:14:33,278 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.616
evaluate on task refcoco, val, 7, res: {'refcoco': [0.308, 0.784, 0.842], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:14:33,296 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 8
2024-03-19 12:15:17,984 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:15:17,988 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:15:18,177 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.342, 0.854, 0.916] 

2024-03-19 12:15:18,178 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:15:18,178 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:15:18,178 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.91
evaluate on task refcoco, val, 8, res: {'refcoco': [0.342, 0.854, 0.916], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:15:18,231 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 12:15:19,463 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 12:15:20,902 maskrcnn_benchmark.trainer INFO: Total training time: 0:18:41.287952 (1.7941 s / it)
2024-03-19 12:15:20,917 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 12:15:20,918 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 12:15:20,918 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 12:15:20,918 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 12:15:20,918 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 12:15:20,918 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 12:15:20,918 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 12:15:20,918 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 12:15:20,918 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 12:15:20,918 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.9.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 12:15:20,919 maskrcnn_benchmark INFO: visual_prompt.9.dim_1 : Not Frozen, param number, 36
2024-03-19 12:15:20,919 maskrcnn_benchmark INFO: visual_prompt.9.dim_2 : Not Frozen, param number, 64
2024-03-19 12:15:20,919 maskrcnn_benchmark INFO: visual_prompt.9.dim_3 : Not Frozen, param number, 384
2024-03-19 12:15:20,919 maskrcnn_benchmark INFO: textual_prompt.9.dim_1 : Not Frozen, param number, 36
2024-03-19 12:15:20,919 maskrcnn_benchmark INFO: textual_prompt.9.dim_2 : Not Frozen, param number, 64
2024-03-19 12:15:20,919 maskrcnn_benchmark INFO: textual_prompt.9.dim_3 : Not Frozen, param number, 3072
2024-03-19 12:15:20,922 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 12:15:20,922 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.71s)
creating index...
index created!
2024-03-19 12:15:24,329 maskrcnn_benchmark INFO: Training on task 9: food, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 12:15:24,539 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:15:24,721 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:15:24,905 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:15:25,090 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 12:15:25,276 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:15:25,468 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 12:15:25,661 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.48s)
creating index...
index created!
2024-03-19 12:15:27,262 maskrcnn_benchmark INFO: Testing on task 7: furniture, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 12:15:27,449 maskrcnn_benchmark INFO: Testing on task 8: vehicle, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:15:27,638 maskrcnn_benchmark INFO: Testing on task 9: food, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
2024-03-19 12:15:27,962 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:12:40  iter: 20  loss: 2.9823 (2.4970)  loss_reg: 0.2285 (0.2404)  loss_centerness: 0.4738 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.9106 (1.4749)  alignment_loss: 0.2452 (0.1773)  time: 1.2273 (1.2565)  data: 0.1298 (0.1408)  task_loss: 0.1379 (0.1330)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:12:14  iter: 40  loss: 3.2417 (2.4997)  loss_reg: 0.2396 (0.2404)  loss_centerness: 0.4749 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 2.1766 (1.4774)  alignment_loss: 0.2312 (0.1776)  time: 1.2316 (1.2564)  data: 0.1293 (0.1408)  task_loss: 0.1379 (0.1330)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:11:49  iter: 60  loss: 3.0014 (2.5020)  loss_reg: 0.2349 (0.2404)  loss_centerness: 0.4759 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.9005 (1.4795)  alignment_loss: 0.2214 (0.1778)  time: 1.2592 (1.2564)  data: 0.1296 (0.1407)  task_loss: 0.1379 (0.1330)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:11:24  iter: 80  loss: 2.9228 (2.5040)  loss_reg: 0.2355 (0.2403)  loss_centerness: 0.4742 (0.4786)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.9054 (1.4813)  alignment_loss: 0.2148 (0.1779)  time: 1.2203 (1.2563)  data: 0.1253 (0.1407)  task_loss: 0.1379 (0.1331)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:10:59  iter: 100  loss: 3.0546 (2.5065)  loss_reg: 0.2311 (0.2403)  loss_centerness: 0.4740 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.9917 (1.4836)  alignment_loss: 0.2099 (0.1781)  time: 1.2704 (1.2563)  data: 0.1356 (0.1407)  task_loss: 0.1379 (0.1331)  lr: 0.010000  wd: 0.000500  max mem: 12614
eta: 0:10:34  iter: 120  loss: 3.0437 (2.5087)  loss_reg: 0.2367 (0.2403)  loss_centerness: 0.4756 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.9644 (1.4857)  alignment_loss: 0.2057 (0.1782)  time: 1.2292 (1.2563)  data: 0.1316 (0.1406)  task_loss: 0.1379 (0.1331)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:10:09  iter: 140  loss: 2.9100 (2.5108)  loss_reg: 0.2309 (0.2403)  loss_centerness: 0.4754 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8873 (1.4877)  alignment_loss: 0.2020 (0.1783)  time: 1.2568 (1.2563)  data: 0.1310 (0.1406)  task_loss: 0.1378 (0.1331)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:09:44  iter: 160  loss: 2.8443 (2.5126)  loss_reg: 0.2135 (0.2402)  loss_centerness: 0.4747 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8087 (1.4894)  alignment_loss: 0.1985 (0.1784)  time: 1.2337 (1.2562)  data: 0.1268 (0.1405)  task_loss: 0.1378 (0.1332)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:09:19  iter: 180  loss: 2.9747 (2.5148)  loss_reg: 0.2395 (0.2402)  loss_centerness: 0.4750 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.9524 (1.4915)  alignment_loss: 0.1952 (0.1784)  time: 1.2630 (1.2562)  data: 0.1327 (0.1405)  task_loss: 0.1378 (0.1332)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:08:53  iter: 200  loss: 2.9557 (2.5165)  loss_reg: 0.2108 (0.2401)  loss_centerness: 0.4746 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.9056 (1.4932)  alignment_loss: 0.1920 (0.1785)  time: 1.2336 (1.2563)  data: 0.1305 (0.1407)  task_loss: 0.1378 (0.1332)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:08:28  iter: 220  loss: 2.7182 (2.5177)  loss_reg: 0.2334 (0.2401)  loss_centerness: 0.4747 (0.4785)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6706 (1.4944)  alignment_loss: 0.1889 (0.1785)  time: 1.2342 (1.2563)  data: 0.1319 (0.1406)  task_loss: 0.1378 (0.1332)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:08:03  iter: 240  loss: 2.8670 (2.5194)  loss_reg: 0.2293 (0.2401)  loss_centerness: 0.4757 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8085 (1.4960)  alignment_loss: 0.1857 (0.1786)  time: 1.2319 (1.2563)  data: 0.1295 (0.1406)  task_loss: 0.1377 (0.1332)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:07:38  iter: 260  loss: 2.8405 (2.5209)  loss_reg: 0.2177 (0.2400)  loss_centerness: 0.4752 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.8077 (1.4975)  alignment_loss: 0.1826 (0.1786)  time: 1.2734 (1.2563)  data: 0.1388 (0.1406)  task_loss: 0.1377 (0.1333)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:07:13  iter: 280  loss: 2.7808 (2.5220)  loss_reg: 0.2322 (0.2400)  loss_centerness: 0.4734 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7241 (1.4986)  alignment_loss: 0.1794 (0.1786)  time: 1.2596 (1.2563)  data: 0.1357 (0.1406)  task_loss: 0.1377 (0.1333)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:06:48  iter: 300  loss: 2.7453 (2.5228)  loss_reg: 0.2203 (0.2399)  loss_centerness: 0.4754 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6728 (1.4994)  alignment_loss: 0.1764 (0.1786)  time: 1.2191 (1.2562)  data: 0.1273 (0.1405)  task_loss: 0.1376 (0.1333)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:06:23  iter: 320  loss: 2.6449 (2.5235)  loss_reg: 0.2304 (0.2399)  loss_centerness: 0.4752 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6464 (1.5001)  alignment_loss: 0.1733 (0.1785)  time: 1.2584 (1.2562)  data: 0.1297 (0.1405)  task_loss: 0.1376 (0.1333)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:05:58  iter: 340  loss: 2.7306 (2.5241)  loss_reg: 0.2293 (0.2399)  loss_centerness: 0.4770 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6814 (1.5008)  alignment_loss: 0.1704 (0.1785)  time: 1.2626 (1.2564)  data: 0.1318 (0.1405)  task_loss: 0.1375 (0.1333)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:05:32  iter: 360  loss: 2.4994 (2.5243)  loss_reg: 0.2258 (0.2398)  loss_centerness: 0.4717 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4989 (1.5010)  alignment_loss: 0.1673 (0.1785)  time: 1.2728 (1.2564)  data: 0.1342 (0.1404)  task_loss: 0.1375 (0.1333)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:05:07  iter: 380  loss: 2.3572 (2.5239)  loss_reg: 0.2421 (0.2398)  loss_centerness: 0.4762 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3562 (1.5007)  alignment_loss: 0.1643 (0.1784)  time: 1.2549 (1.2564)  data: 0.1317 (0.1404)  task_loss: 0.1374 (0.1334)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:04:42  iter: 400  loss: 2.3396 (2.5235)  loss_reg: 0.2262 (0.2398)  loss_centerness: 0.4736 (0.4784)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3549 (1.5003)  alignment_loss: 0.1608 (0.1783)  time: 1.2653 (1.2564)  data: 0.1311 (0.1404)  task_loss: 0.1374 (0.1334)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:04:17  iter: 420  loss: 2.2277 (2.5224)  loss_reg: 0.2291 (0.2398)  loss_centerness: 0.4738 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2260 (1.4993)  alignment_loss: 0.1567 (0.1783)  time: 1.2760 (1.2564)  data: 0.1370 (0.1404)  task_loss: 0.1374 (0.1334)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:03:52  iter: 440  loss: 2.2515 (2.5215)  loss_reg: 0.2136 (0.2397)  loss_centerness: 0.4745 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2262 (1.4986)  alignment_loss: 0.1522 (0.1782)  time: 1.2500 (1.2564)  data: 0.1303 (0.1403)  task_loss: 0.1373 (0.1334)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:03:27  iter: 460  loss: 2.1584 (2.5202)  loss_reg: 0.2192 (0.2397)  loss_centerness: 0.4760 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1280 (1.4974)  alignment_loss: 0.1476 (0.1780)  time: 1.2545 (1.2564)  data: 0.1306 (0.1403)  task_loss: 0.1373 (0.1334)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:03:02  iter: 480  loss: 2.2200 (2.5190)  loss_reg: 0.2273 (0.2396)  loss_centerness: 0.4747 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2375 (1.4963)  alignment_loss: 0.1432 (0.1779)  time: 1.2244 (1.2565)  data: 0.1252 (0.1404)  task_loss: 0.1373 (0.1334)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:02:37  iter: 500  loss: 2.0436 (2.5175)  loss_reg: 0.2280 (0.2396)  loss_centerness: 0.4761 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0864 (1.4950)  alignment_loss: 0.1391 (0.1777)  time: 1.2195 (1.2564)  data: 0.1238 (0.1403)  task_loss: 0.1373 (0.1335)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:02:11  iter: 520  loss: 2.2018 (2.5160)  loss_reg: 0.2192 (0.2396)  loss_centerness: 0.4745 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2054 (1.4937)  alignment_loss: 0.1353 (0.1776)  time: 1.2602 (1.2563)  data: 0.1301 (0.1403)  task_loss: 0.1372 (0.1335)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:01:46  iter: 540  loss: 2.0241 (2.5143)  loss_reg: 0.2205 (0.2395)  loss_centerness: 0.4756 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0844 (1.4921)  alignment_loss: 0.1317 (0.1774)  time: 1.2362 (1.2563)  data: 0.1272 (0.1403)  task_loss: 0.1372 (0.1335)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:01:21  iter: 560  loss: 2.0931 (2.5130)  loss_reg: 0.2370 (0.2395)  loss_centerness: 0.4776 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1025 (1.4910)  alignment_loss: 0.1283 (0.1772)  time: 1.2414 (1.2563)  data: 0.1305 (0.1402)  task_loss: 0.1372 (0.1335)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:00:56  iter: 580  loss: 2.1012 (2.5115)  loss_reg: 0.2331 (0.2395)  loss_centerness: 0.4748 (0.4783)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1131 (1.4897)  alignment_loss: 0.1250 (0.1770)  time: 1.2192 (1.2562)  data: 0.1261 (0.1402)  task_loss: 0.1372 (0.1335)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:00:31  iter: 600  loss: 2.0702 (2.5100)  loss_reg: 0.2299 (0.2395)  loss_centerness: 0.4747 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.1452 (1.4884)  alignment_loss: 0.1219 (0.1768)  time: 1.2713 (1.2562)  data: 0.1394 (0.1402)  task_loss: 0.1371 (0.1335)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:00:06  iter: 620  loss: 2.0059 (2.5081)  loss_reg: 0.2265 (0.2394)  loss_centerness: 0.4736 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0416 (1.4867)  alignment_loss: 0.1186 (0.1766)  time: 1.2548 (1.2563)  data: 0.1266 (0.1401)  task_loss: 0.1371 (0.1335)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:00:00  iter: 625  loss: 1.9561 (2.5076)  loss_reg: 0.2265 (0.2394)  loss_centerness: 0.4736 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.0314 (1.4863)  alignment_loss: 0.1177 (0.1765)  time: 1.2548 (1.2563)  data: 0.1298 (0.1401)  task_loss: 0.1371 (0.1336)  lr: 0.000000  wd: 0.000500  max mem: 12616
Evaluating
2024-03-19 12:30:18,932 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 12:30:27,115 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:30:27,119 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:30:27,140 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.4794520547945205, 0.589041095890411] 

2024-03-19 12:30:27,141 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:30:27,141 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:30:27,141 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8493150684931506
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.4794520547945205, 0.589041095890411], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:30:27,158 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 12:30:31,700 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:30:31,703 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 12:30:31,714 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2962962962962963, 0.7777777777777778, 0.8518518518518519] 

2024-03-19 12:30:31,714 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:30:31,714 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:30:31,714 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2962962962962963, 0.7777777777777778, 0.8518518518518519], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:30:31,729 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 12:30:38,625 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:30:38,628 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:30:38,641 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25, 0.6590909090909091, 0.7727272727272727] 

2024-03-19 12:30:38,642 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:30:38,642 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:30:38,642 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.25, 0.6590909090909091, 0.7727272727272727], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:30:38,661 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 12:31:03,130 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:31:03,134 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:31:03,224 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3215686274509804, 0.7725490196078432, 0.8784313725490196] 

2024-03-19 12:31:03,224 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:31:03,224 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:31:03,224 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8549019607843137
evaluate on task refcoco, val, 3, res: {'refcoco': [0.3215686274509804, 0.7725490196078432, 0.8784313725490196], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:31:03,242 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 12:31:23,697 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:31:23,701 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:31:23,788 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2714285714285714, 0.7904761904761904, 0.8571428571428571] 

2024-03-19 12:31:23,789 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:31:23,789 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:31:23,789 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8809523809523809
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2714285714285714, 0.7904761904761904, 0.8571428571428571], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:31:23,811 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 12:31:52,752 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:31:52,756 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:31:52,861 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.22875816993464052, 0.6993464052287581, 0.8398692810457516] 

2024-03-19 12:31:52,861 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:31:52,861 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:31:52,862 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8790849673202614
evaluate on task refcoco, val, 5, res: {'refcoco': [0.22875816993464052, 0.6993464052287581, 0.8398692810457516], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:31:52,879 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 12:32:35,802 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:32:35,805 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:32:35,965 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.33755274261603374, 0.8776371308016878, 0.9493670886075949] 

2024-03-19 12:32:35,966 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:32:35,966 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:32:35,966 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8354430379746836
evaluate on task refcoco, val, 6, res: {'refcoco': [0.33755274261603374, 0.8776371308016878, 0.9493670886075949], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:32:35,985 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 7
2024-03-19 12:33:21,605 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:33:21,608 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:33:21,784 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.306, 0.782, 0.842] 

2024-03-19 12:33:21,785 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:33:21,785 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:33:21,785 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.594
evaluate on task refcoco, val, 7, res: {'refcoco': [0.306, 0.782, 0.842], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:33:21,802 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 8
2024-03-19 12:34:08,824 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:34:08,829 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 12:34:08,992 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.358, 0.852, 0.916] 

2024-03-19 12:34:08,993 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:34:08,993 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:34:08,993 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.91
evaluate on task refcoco, val, 8, res: {'refcoco': [0.358, 0.852, 0.916], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:34:09,014 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 9
2024-03-19 12:34:53,621 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:34:53,625 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.4000000059604645), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.4000000059604645), ('AR@1000', 0.4000000059604645), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.4000000059604645)]))])
2024-03-19 12:34:53,824 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.248, 0.626, 0.78] 

2024-03-19 12:34:53,824 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:34:53,824 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:34:53,825 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.734
evaluate on task refcoco, val, 9, res: {'refcoco': [0.248, 0.626, 0.78], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:34:53,878 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 12:34:55,197 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 12:34:56,515 maskrcnn_benchmark.trainer INFO: Total training time: 0:19:28.537756 (1.8697 s / it)
2024-03-19 12:34:56,527 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 12:34:56,528 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 12:34:56,528 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 12:34:56,528 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 12:34:56,528 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 12:34:56,528 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 12:34:56,528 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 12:34:56,528 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 12:34:56,528 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 12:34:56,528 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.10.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 12:34:56,529 maskrcnn_benchmark INFO: visual_prompt.10.dim_1 : Not Frozen, param number, 36
2024-03-19 12:34:56,529 maskrcnn_benchmark INFO: visual_prompt.10.dim_2 : Not Frozen, param number, 64
2024-03-19 12:34:56,529 maskrcnn_benchmark INFO: visual_prompt.10.dim_3 : Not Frozen, param number, 384
2024-03-19 12:34:56,529 maskrcnn_benchmark INFO: textual_prompt.10.dim_1 : Not Frozen, param number, 36
2024-03-19 12:34:56,529 maskrcnn_benchmark INFO: textual_prompt.10.dim_2 : Not Frozen, param number, 64
2024-03-19 12:34:56,529 maskrcnn_benchmark INFO: textual_prompt.10.dim_3 : Not Frozen, param number, 3072
2024-03-19 12:34:56,531 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 12:34:56,532 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.58s)
creating index...
index created!
2024-03-19 12:34:59,885 maskrcnn_benchmark INFO: Training on task 10: animal, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:35:00,085 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:35:00,267 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 12:35:00,455 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:35:00,639 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:35:00,820 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:35:01,002 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:35:01,185 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:35:01,373 maskrcnn_benchmark INFO: Testing on task 7: furniture, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.33s)
creating index...
index created!
2024-03-19 12:35:02,823 maskrcnn_benchmark INFO: Testing on task 8: vehicle, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 12:35:03,007 maskrcnn_benchmark INFO: Testing on task 9: food, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 12:35:03,193 maskrcnn_benchmark INFO: Testing on task 10: animal, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
2024-03-19 12:35:03,499 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:12:40  iter: 20  loss: 2.7730 (2.5088)  loss_reg: 0.1995 (0.2393)  loss_centerness: 0.4746 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7413 (1.4874)  alignment_loss: 0.2356 (0.1767)  time: 1.1234 (1.2566)  data: 0.0128 (0.1405)  task_loss: 0.1381 (0.1336)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:12:15  iter: 40  loss: 2.7521 (2.5098)  loss_reg: 0.1822 (0.2391)  loss_centerness: 0.4756 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.7520 (1.4883)  alignment_loss: 0.2298 (0.1769)  time: 1.1451 (1.2566)  data: 0.0129 (0.1404)  task_loss: 0.1381 (0.1336)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:11:49  iter: 60  loss: 2.6848 (2.5106)  loss_reg: 0.1819 (0.2389)  loss_centerness: 0.4752 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6499 (1.4891)  alignment_loss: 0.2256 (0.1771)  time: 1.1397 (1.2565)  data: 0.0133 (0.1404)  task_loss: 0.1381 (0.1336)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:11:24  iter: 80  loss: 2.6579 (2.5115)  loss_reg: 0.1917 (0.2388)  loss_centerness: 0.4741 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6141 (1.4900)  alignment_loss: 0.2226 (0.1773)  time: 1.1402 (1.2565)  data: 0.0131 (0.1403)  task_loss: 0.1381 (0.1336)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:10:59  iter: 100  loss: 2.7312 (2.5123)  loss_reg: 0.1887 (0.2386)  loss_centerness: 0.4738 (0.4782)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6522 (1.4907)  alignment_loss: 0.2203 (0.1775)  time: 1.1458 (1.2564)  data: 0.0123 (0.1403)  task_loss: 0.1381 (0.1336)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:10:34  iter: 120  loss: 2.7231 (2.5133)  loss_reg: 0.1821 (0.2384)  loss_centerness: 0.4731 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6832 (1.4917)  alignment_loss: 0.2185 (0.1776)  time: 1.1429 (1.2564)  data: 0.0128 (0.1402)  task_loss: 0.1381 (0.1337)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:10:09  iter: 140  loss: 2.6951 (2.5140)  loss_reg: 0.1863 (0.2383)  loss_centerness: 0.4736 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6877 (1.4925)  alignment_loss: 0.2170 (0.1778)  time: 1.1495 (1.2564)  data: 0.0133 (0.1402)  task_loss: 0.1381 (0.1337)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:09:44  iter: 160  loss: 2.7083 (2.5148)  loss_reg: 0.1975 (0.2381)  loss_centerness: 0.4744 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6829 (1.4932)  alignment_loss: 0.2156 (0.1779)  time: 1.1455 (1.2563)  data: 0.0131 (0.1402)  task_loss: 0.1381 (0.1337)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:09:19  iter: 180  loss: 2.7680 (2.5158)  loss_reg: 0.1991 (0.2380)  loss_centerness: 0.4728 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6946 (1.4942)  alignment_loss: 0.2144 (0.1780)  time: 1.1545 (1.2563)  data: 0.0138 (0.1401)  task_loss: 0.1381 (0.1337)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:08:53  iter: 200  loss: 2.5833 (2.5165)  loss_reg: 0.1899 (0.2378)  loss_centerness: 0.4736 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5992 (1.4949)  alignment_loss: 0.2131 (0.1782)  time: 1.1458 (1.2565)  data: 0.0133 (0.1403)  task_loss: 0.1381 (0.1337)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:08:28  iter: 220  loss: 2.6957 (2.5172)  loss_reg: 0.1988 (0.2377)  loss_centerness: 0.4747 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6886 (1.4955)  alignment_loss: 0.2120 (0.1783)  time: 1.1129 (1.2564)  data: 0.0123 (0.1402)  task_loss: 0.1381 (0.1337)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:08:03  iter: 240  loss: 2.6294 (2.5178)  loss_reg: 0.1981 (0.2375)  loss_centerness: 0.4757 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6068 (1.4962)  alignment_loss: 0.2109 (0.1784)  time: 1.1135 (1.2563)  data: 0.0129 (0.1402)  task_loss: 0.1381 (0.1338)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:07:38  iter: 260  loss: 2.6159 (2.5182)  loss_reg: 0.1909 (0.2374)  loss_centerness: 0.4725 (0.4781)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5662 (1.4966)  alignment_loss: 0.2097 (0.1785)  time: 1.1444 (1.2563)  data: 0.0129 (0.1401)  task_loss: 0.1381 (0.1338)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:07:13  iter: 280  loss: 2.7332 (2.5187)  loss_reg: 0.1858 (0.2372)  loss_centerness: 0.4727 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6993 (1.4972)  alignment_loss: 0.2086 (0.1786)  time: 1.1443 (1.2562)  data: 0.0123 (0.1401)  task_loss: 0.1382 (0.1338)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:06:48  iter: 300  loss: 2.6998 (2.5197)  loss_reg: 0.1886 (0.2371)  loss_centerness: 0.4748 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6716 (1.4981)  alignment_loss: 0.2074 (0.1787)  time: 1.1449 (1.2562)  data: 0.0131 (0.1401)  task_loss: 0.1382 (0.1338)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:06:23  iter: 320  loss: 2.5799 (2.5201)  loss_reg: 0.1971 (0.2369)  loss_centerness: 0.4731 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5323 (1.4985)  alignment_loss: 0.2063 (0.1788)  time: 1.1534 (1.2563)  data: 0.0137 (0.1401)  task_loss: 0.1382 (0.1338)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:05:58  iter: 340  loss: 2.5839 (2.5207)  loss_reg: 0.1886 (0.2368)  loss_centerness: 0.4721 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5718 (1.4992)  alignment_loss: 0.2051 (0.1789)  time: 1.1494 (1.2564)  data: 0.0134 (0.1402)  task_loss: 0.1382 (0.1338)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:05:32  iter: 360  loss: 2.6143 (2.5211)  loss_reg: 0.1930 (0.2367)  loss_centerness: 0.4766 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5728 (1.4996)  alignment_loss: 0.2038 (0.1790)  time: 1.1456 (1.2564)  data: 0.0134 (0.1402)  task_loss: 0.1382 (0.1339)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:05:07  iter: 380  loss: 2.6396 (2.5219)  loss_reg: 0.1875 (0.2365)  loss_centerness: 0.4735 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.6371 (1.5004)  alignment_loss: 0.2025 (0.1791)  time: 1.1077 (1.2563)  data: 0.0120 (0.1401)  task_loss: 0.1382 (0.1339)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:04:42  iter: 400  loss: 2.5972 (2.5220)  loss_reg: 0.1794 (0.2363)  loss_centerness: 0.4716 (0.4780)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5701 (1.5007)  alignment_loss: 0.2010 (0.1792)  time: 1.1509 (1.2564)  data: 0.0134 (0.1401)  task_loss: 0.1382 (0.1339)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:04:17  iter: 420  loss: 2.5640 (2.5221)  loss_reg: 0.1996 (0.2362)  loss_centerness: 0.4727 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5523 (1.5008)  alignment_loss: 0.1995 (0.1793)  time: 1.1477 (1.2563)  data: 0.0134 (0.1401)  task_loss: 0.1382 (0.1339)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:03:52  iter: 440  loss: 2.5506 (2.5225)  loss_reg: 0.2044 (0.2361)  loss_centerness: 0.4743 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5415 (1.5011)  alignment_loss: 0.1979 (0.1793)  time: 1.1228 (1.2563)  data: 0.0133 (0.1401)  task_loss: 0.1382 (0.1339)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:03:27  iter: 460  loss: 2.5215 (2.5225)  loss_reg: 0.1812 (0.2359)  loss_centerness: 0.4719 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5662 (1.5013)  alignment_loss: 0.1962 (0.1794)  time: 1.1124 (1.2563)  data: 0.0123 (0.1400)  task_loss: 0.1382 (0.1339)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:03:02  iter: 480  loss: 2.4611 (2.5224)  loss_reg: 0.1909 (0.2358)  loss_centerness: 0.4748 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4749 (1.5012)  alignment_loss: 0.1944 (0.1794)  time: 1.1365 (1.2562)  data: 0.0134 (0.1400)  task_loss: 0.1382 (0.1340)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:02:37  iter: 500  loss: 2.4524 (2.5225)  loss_reg: 0.2032 (0.2357)  loss_centerness: 0.4776 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4879 (1.5013)  alignment_loss: 0.1924 (0.1795)  time: 1.1436 (1.2564)  data: 0.0131 (0.1401)  task_loss: 0.1382 (0.1340)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:02:11  iter: 520  loss: 2.4326 (2.5221)  loss_reg: 0.1812 (0.2355)  loss_centerness: 0.4720 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4460 (1.5010)  alignment_loss: 0.1903 (0.1795)  time: 1.1493 (1.2563)  data: 0.0135 (0.1401)  task_loss: 0.1381 (0.1340)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:01:46  iter: 540  loss: 2.3968 (2.5217)  loss_reg: 0.2055 (0.2354)  loss_centerness: 0.4736 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4099 (1.5007)  alignment_loss: 0.1882 (0.1795)  time: 1.1084 (1.2563)  data: 0.0117 (0.1400)  task_loss: 0.1381 (0.1340)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:01:21  iter: 560  loss: 2.4295 (2.5215)  loss_reg: 0.2063 (0.2353)  loss_centerness: 0.4743 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4521 (1.5006)  alignment_loss: 0.1860 (0.1796)  time: 1.1273 (1.2562)  data: 0.0136 (0.1400)  task_loss: 0.1381 (0.1340)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:00:56  iter: 580  loss: 2.2749 (2.5207)  loss_reg: 0.2048 (0.2352)  loss_centerness: 0.4756 (0.4779)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2796 (1.4999)  alignment_loss: 0.1839 (0.1796)  time: 1.1590 (1.2562)  data: 0.0133 (0.1399)  task_loss: 0.1381 (0.1340)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:00:31  iter: 600  loss: 2.2846 (2.5199)  loss_reg: 0.2060 (0.2351)  loss_centerness: 0.4748 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2727 (1.4991)  alignment_loss: 0.1818 (0.1796)  time: 1.1519 (1.2563)  data: 0.0137 (0.1399)  task_loss: 0.1381 (0.1340)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:00:06  iter: 620  loss: 2.2071 (2.5188)  loss_reg: 0.1881 (0.2349)  loss_centerness: 0.4725 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2292 (1.4981)  alignment_loss: 0.1797 (0.1796)  time: 1.1495 (1.2563)  data: 0.0135 (0.1399)  task_loss: 0.1381 (0.1341)  lr: 0.010000  wd: 0.000500  max mem: 12616
eta: 0:00:00  iter: 625  loss: 2.2071 (2.5185)  loss_reg: 0.1881 (0.2349)  loss_centerness: 0.4726 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.2166 (1.4979)  alignment_loss: 0.1790 (0.1796)  time: 1.1495 (1.2563)  data: 0.0135 (0.1399)  task_loss: 0.1381 (0.1341)  lr: 0.000000  wd: 0.000500  max mem: 12616
Evaluating
2024-03-19 12:50:00,652 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 12:50:09,275 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:50:09,278 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:50:09,301 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.4794520547945205, 0.589041095890411] 

2024-03-19 12:50:09,302 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:50:09,302 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:50:09,302 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8493150684931506
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.4794520547945205, 0.589041095890411], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:50:09,317 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 12:50:13,727 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:50:13,731 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 12:50:13,743 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2962962962962963, 0.7777777777777778, 0.8518518518518519] 

2024-03-19 12:50:13,744 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:50:13,744 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:50:13,744 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 1.0
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2962962962962963, 0.7777777777777778, 0.8518518518518519], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:50:13,761 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 12:50:19,861 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:50:19,863 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:50:19,874 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25, 0.6590909090909091, 0.7727272727272727] 

2024-03-19 12:50:19,875 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:50:19,875 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:50:19,875 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.25, 0.6590909090909091, 0.7727272727272727], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:50:19,891 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 12:50:43,405 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:50:43,408 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:50:43,488 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3215686274509804, 0.7725490196078432, 0.8784313725490196] 

2024-03-19 12:50:43,489 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:50:43,489 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:50:43,489 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8549019607843137
evaluate on task refcoco, val, 3, res: {'refcoco': [0.3215686274509804, 0.7725490196078432, 0.8784313725490196], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:50:43,504 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 12:51:03,988 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:51:03,991 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:51:04,071 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.28095238095238095, 0.8, 0.861904761904762] 

2024-03-19 12:51:04,072 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:51:04,072 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:51:04,072 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8523809523809524
evaluate on task refcoco, val, 4, res: {'refcoco': [0.28095238095238095, 0.8, 0.861904761904762], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:51:04,091 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 12:51:33,620 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:51:33,624 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:51:33,712 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.22549019607843138, 0.696078431372549, 0.8398692810457516] 

2024-03-19 12:51:33,713 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:51:33,713 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:51:33,713 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8790849673202614
evaluate on task refcoco, val, 5, res: {'refcoco': [0.22549019607843138, 0.696078431372549, 0.8398692810457516], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:51:33,731 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 12:52:16,799 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:52:16,802 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:52:16,936 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.33544303797468356, 0.879746835443038, 0.9535864978902954] 

2024-03-19 12:52:16,936 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:52:16,936 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:52:16,936 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8354430379746836
evaluate on task refcoco, val, 6, res: {'refcoco': [0.33544303797468356, 0.879746835443038, 0.9535864978902954], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:52:16,953 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 7
2024-03-19 12:53:01,944 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:53:01,948 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:53:02,158 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.312, 0.782, 0.844] 

2024-03-19 12:53:02,159 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:53:02,159 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:53:02,159 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.544
evaluate on task refcoco, val, 7, res: {'refcoco': [0.312, 0.782, 0.844], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:53:02,178 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 8
2024-03-19 12:53:47,109 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:53:47,112 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 12:53:47,265 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.364, 0.856, 0.916] 

2024-03-19 12:53:47,265 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:53:47,265 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:53:47,265 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.9
evaluate on task refcoco, val, 8, res: {'refcoco': [0.364, 0.856, 0.916], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:53:47,282 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 9
2024-03-19 12:54:32,844 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:54:32,848 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.4000000059604645), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.4000000059604645), ('AR@1000', 0.4000000059604645), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.4000000059604645)]))])
2024-03-19 12:54:32,988 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.254, 0.636, 0.784] 

2024-03-19 12:54:32,988 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:54:32,989 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:54:32,989 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.734
evaluate on task refcoco, val, 9, res: {'refcoco': [0.254, 0.636, 0.784], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:54:33,009 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 10
2024-03-19 12:55:19,256 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 12:55:19,258 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 12:55:19,404 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.368, 0.898, 0.934] 

2024-03-19 12:55:19,405 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 12:55:19,405 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 12:55:19,405 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.872
evaluate on task refcoco, val, 10, res: {'refcoco': [0.368, 0.898, 0.934], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 12:55:19,459 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 12:55:20,743 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 12:55:21,922 maskrcnn_benchmark.trainer INFO: Total training time: 0:20:18.404206 (1.9494 s / it)
2024-03-19 12:55:21,935 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_1_v2t : Not Frozen, param number, 48
2024-03-19 12:55:21,935 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_2_v2t : Not Frozen, param number, 388
2024-03-19 12:55:21,935 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_3_v2t : Not Frozen, param number, 3072
2024-03-19 12:55:21,935 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_1_t2v : Not Frozen, param number, 48
2024-03-19 12:55:21,935 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_2_t2v : Not Frozen, param number, 3076
2024-03-19 12:55:21,935 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.dim_3_t2v : Not Frozen, param number, 384
2024-03-19 12:55:21,935 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.visual_norm.weight : Not Frozen, param number, 96
2024-03-19 12:55:21,935 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.visual_norm.bias : Not Frozen, param number, 96
2024-03-19 12:55:21,935 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.textual_norm.weight : Not Frozen, param number, 768
2024-03-19 12:55:21,935 maskrcnn_benchmark INFO: language_backbone.body.model.encoder.interactModuleList.11.textual_norm.bias : Not Frozen, param number, 768
2024-03-19 12:55:21,936 maskrcnn_benchmark INFO: visual_prompt.11.dim_1 : Not Frozen, param number, 36
2024-03-19 12:55:21,936 maskrcnn_benchmark INFO: visual_prompt.11.dim_2 : Not Frozen, param number, 64
2024-03-19 12:55:21,936 maskrcnn_benchmark INFO: visual_prompt.11.dim_3 : Not Frozen, param number, 384
2024-03-19 12:55:21,936 maskrcnn_benchmark INFO: textual_prompt.11.dim_1 : Not Frozen, param number, 36
2024-03-19 12:55:21,936 maskrcnn_benchmark INFO: textual_prompt.11.dim_2 : Not Frozen, param number, 64
2024-03-19 12:55:21,936 maskrcnn_benchmark INFO: textual_prompt.11.dim_3 : Not Frozen, param number, 3072
2024-03-19 12:55:21,939 maskrcnn_benchmark INFO: trainable param size 12400, total size 152347326
2024-03-19 12:55:21,939 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
The combined datasets are: ('refexp_train',).
loading annotations into memory...
Done (t=1.75s)
creating index...
index created!
2024-03-19 12:55:24,584 maskrcnn_benchmark INFO: Training on task 11: person, total training sample size: 2000
refexp_train has the 2000 data points RefExpDataset
Number of iterations are 625
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 12:55:24,796 maskrcnn_benchmark INFO: Testing on task 0: appliance, total testing sample size: 73
refexp_val has the 73 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 12:55:24,983 maskrcnn_benchmark INFO: Testing on task 1: sports, total testing sample size: 27
refexp_val has the 27 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=1.40s)
creating index...
index created!
2024-03-19 12:55:26,507 maskrcnn_benchmark INFO: Testing on task 2: outdoor, total testing sample size: 44
refexp_val has the 44 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:55:26,704 maskrcnn_benchmark INFO: Testing on task 3: electronic, total testing sample size: 255
refexp_val has the 255 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:55:26,893 maskrcnn_benchmark INFO: Testing on task 4: accessory, total testing sample size: 210
refexp_val has the 210 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:55:27,080 maskrcnn_benchmark INFO: Testing on task 5: indoor, total testing sample size: 306
refexp_val has the 306 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 12:55:27,275 maskrcnn_benchmark INFO: Testing on task 6: kitchen, total testing sample size: 474
refexp_val has the 474 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:55:27,472 maskrcnn_benchmark INFO: Testing on task 7: furniture, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:55:27,657 maskrcnn_benchmark INFO: Testing on task 8: vehicle, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:55:27,839 maskrcnn_benchmark INFO: Testing on task 9: food, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.07s)
creating index...
index created!
2024-03-19 12:55:28,021 maskrcnn_benchmark INFO: Testing on task 10: animal, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
The combined datasets are: ('refexp_val',).
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
2024-03-19 12:55:28,204 maskrcnn_benchmark INFO: Testing on task 11: person, total testing sample size: 500
refexp_val has the 500 data points RefExpDataset
2024-03-19 12:55:28,544 maskrcnn_benchmark.trainer INFO: Start training
Iter per epoch  62
eta: 0:12:40  iter: 20  loss: 2.4456 (2.5186)  loss_reg: 0.1955 (0.2347)  loss_centerness: 0.4747 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4383 (1.4980)  alignment_loss: 0.2179 (0.1797)  time: 1.1797 (1.2569)  data: 0.0156 (0.1405)  task_loss: 0.1393 (0.1341)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:12:15  iter: 40  loss: 2.4725 (2.5185)  loss_reg: 0.1861 (0.2345)  loss_centerness: 0.4743 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4826 (1.4980)  alignment_loss: 0.1872 (0.1797)  time: 1.1575 (1.2569)  data: 0.0163 (0.1405)  task_loss: 0.1393 (0.1341)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:11:50  iter: 60  loss: 2.3900 (2.5182)  loss_reg: 0.1825 (0.2344)  loss_centerness: 0.4755 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4116 (1.4979)  alignment_loss: 0.1749 (0.1797)  time: 1.1619 (1.2568)  data: 0.0186 (0.1404)  task_loss: 0.1393 (0.1341)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:11:24  iter: 80  loss: 2.4839 (2.5180)  loss_reg: 0.1686 (0.2342)  loss_centerness: 0.4734 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5126 (1.4979)  alignment_loss: 0.1685 (0.1797)  time: 1.2014 (1.2568)  data: 0.0168 (0.1404)  task_loss: 0.1393 (0.1341)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:10:59  iter: 100  loss: 2.4632 (2.5181)  loss_reg: 0.1970 (0.2340)  loss_centerness: 0.4749 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5038 (1.4981)  alignment_loss: 0.1633 (0.1796)  time: 1.1564 (1.2568)  data: 0.0150 (0.1404)  task_loss: 0.1393 (0.1342)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:10:34  iter: 120  loss: 2.3969 (2.5177)  loss_reg: 0.1908 (0.2339)  loss_centerness: 0.4743 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4175 (1.4979)  alignment_loss: 0.1584 (0.1796)  time: 1.2052 (1.2568)  data: 0.0158 (0.1403)  task_loss: 0.1393 (0.1342)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:10:09  iter: 140  loss: 2.3987 (2.5175)  loss_reg: 0.1784 (0.2338)  loss_centerness: 0.4730 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4502 (1.4979)  alignment_loss: 0.1537 (0.1795)  time: 1.1624 (1.2568)  data: 0.0136 (0.1403)  task_loss: 0.1393 (0.1342)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:09:44  iter: 160  loss: 2.4621 (2.5173)  loss_reg: 0.1837 (0.2336)  loss_centerness: 0.4776 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5254 (1.4980)  alignment_loss: 0.1490 (0.1794)  time: 1.1569 (1.2569)  data: 0.0138 (0.1404)  task_loss: 0.1393 (0.1342)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:09:19  iter: 180  loss: 2.3788 (2.5170)  loss_reg: 0.1843 (0.2335)  loss_centerness: 0.4766 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4450 (1.4979)  alignment_loss: 0.1443 (0.1793)  time: 1.1593 (1.2568)  data: 0.0149 (0.1404)  task_loss: 0.1393 (0.1342)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:08:54  iter: 200  loss: 2.3850 (2.5166)  loss_reg: 0.1775 (0.2333)  loss_centerness: 0.4740 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4533 (1.4978)  alignment_loss: 0.1397 (0.1791)  time: 1.1662 (1.2568)  data: 0.0170 (0.1403)  task_loss: 0.1393 (0.1342)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:08:28  iter: 220  loss: 2.3183 (2.5162)  loss_reg: 0.1897 (0.2332)  loss_centerness: 0.4775 (0.4778)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3757 (1.4975)  alignment_loss: 0.1351 (0.1790)  time: 1.1866 (1.2568)  data: 0.0153 (0.1403)  task_loss: 0.1393 (0.1343)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:08:03  iter: 240  loss: 2.5035 (2.5162)  loss_reg: 0.1844 (0.2330)  loss_centerness: 0.4733 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5759 (1.4979)  alignment_loss: 0.1304 (0.1788)  time: 1.1633 (1.2567)  data: 0.0165 (0.1403)  task_loss: 0.1393 (0.1343)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:07:38  iter: 260  loss: 2.3818 (2.5159)  loss_reg: 0.1940 (0.2329)  loss_centerness: 0.4759 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4484 (1.4979)  alignment_loss: 0.1258 (0.1787)  time: 1.2080 (1.2567)  data: 0.0140 (0.1402)  task_loss: 0.1393 (0.1343)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:07:13  iter: 280  loss: 2.3516 (2.5155)  loss_reg: 0.1800 (0.2327)  loss_centerness: 0.4758 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4323 (1.4978)  alignment_loss: 0.1213 (0.1785)  time: 1.1734 (1.2567)  data: 0.0136 (0.1402)  task_loss: 0.1394 (0.1343)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:06:48  iter: 300  loss: 2.3760 (2.5151)  loss_reg: 0.1828 (0.2326)  loss_centerness: 0.4733 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4536 (1.4977)  alignment_loss: 0.1169 (0.1783)  time: 1.1619 (1.2567)  data: 0.0186 (0.1402)  task_loss: 0.1394 (0.1343)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:06:23  iter: 320  loss: 2.2900 (2.5145)  loss_reg: 0.1797 (0.2324)  loss_centerness: 0.4757 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3923 (1.4975)  alignment_loss: 0.1128 (0.1781)  time: 1.1784 (1.2568)  data: 0.0141 (0.1403)  task_loss: 0.1394 (0.1344)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:05:58  iter: 340  loss: 2.4019 (2.5142)  loss_reg: 0.1968 (0.2323)  loss_centerness: 0.4742 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4949 (1.4975)  alignment_loss: 0.1090 (0.1778)  time: 1.1428 (1.2567)  data: 0.0145 (0.1402)  task_loss: 0.1394 (0.1344)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:05:33  iter: 360  loss: 2.3001 (2.5136)  loss_reg: 0.1793 (0.2321)  loss_centerness: 0.4759 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4008 (1.4972)  alignment_loss: 0.1055 (0.1776)  time: 1.2025 (1.2568)  data: 0.0139 (0.1402)  task_loss: 0.1394 (0.1344)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:05:07  iter: 380  loss: 2.4209 (2.5134)  loss_reg: 0.1841 (0.2320)  loss_centerness: 0.4744 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5260 (1.4974)  alignment_loss: 0.1024 (0.1774)  time: 1.1997 (1.2568)  data: 0.0140 (0.1402)  task_loss: 0.1394 (0.1344)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:04:42  iter: 400  loss: 2.4272 (2.5130)  loss_reg: 0.1762 (0.2318)  loss_centerness: 0.4742 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.5463 (1.4974)  alignment_loss: 0.0996 (0.1771)  time: 1.1572 (1.2568)  data: 0.0154 (0.1402)  task_loss: 0.1394 (0.1344)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:04:17  iter: 420  loss: 2.2944 (2.5124)  loss_reg: 0.1854 (0.2317)  loss_centerness: 0.4746 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3886 (1.4972)  alignment_loss: 0.0971 (0.1768)  time: 1.1741 (1.2568)  data: 0.0188 (0.1402)  task_loss: 0.1394 (0.1344)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:03:52  iter: 440  loss: 2.3182 (2.5118)  loss_reg: 0.1873 (0.2316)  loss_centerness: 0.4769 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3998 (1.4969)  alignment_loss: 0.0949 (0.1766)  time: 1.1640 (1.2568)  data: 0.0160 (0.1401)  task_loss: 0.1394 (0.1345)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:03:27  iter: 460  loss: 2.2573 (2.5112)  loss_reg: 0.1860 (0.2314)  loss_centerness: 0.4752 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3404 (1.4967)  alignment_loss: 0.0930 (0.1763)  time: 1.1689 (1.2570)  data: 0.0152 (0.1402)  task_loss: 0.1394 (0.1345)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:03:02  iter: 480  loss: 2.2905 (2.5107)  loss_reg: 0.1779 (0.2313)  loss_centerness: 0.4744 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3893 (1.4966)  alignment_loss: 0.0911 (0.1761)  time: 1.1555 (1.2569)  data: 0.0168 (0.1402)  task_loss: 0.1394 (0.1345)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:02:37  iter: 500  loss: 2.2917 (2.5102)  loss_reg: 0.1784 (0.2312)  loss_centerness: 0.4747 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4294 (1.4964)  alignment_loss: 0.0893 (0.1758)  time: 1.1590 (1.2569)  data: 0.0167 (0.1402)  task_loss: 0.1394 (0.1345)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:02:11  iter: 520  loss: 2.3925 (2.5099)  loss_reg: 0.1975 (0.2310)  loss_centerness: 0.4755 (0.4777)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.4678 (1.4965)  alignment_loss: 0.0876 (0.1755)  time: 1.2093 (1.2569)  data: 0.0209 (0.1401)  task_loss: 0.1394 (0.1345)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:01:46  iter: 540  loss: 2.2736 (2.5093)  loss_reg: 0.1893 (0.2309)  loss_centerness: 0.4762 (0.4776)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3935 (1.4962)  alignment_loss: 0.0859 (0.1752)  time: 1.1572 (1.2569)  data: 0.0152 (0.1401)  task_loss: 0.1394 (0.1345)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:01:21  iter: 560  loss: 2.2551 (2.5086)  loss_reg: 0.1820 (0.2308)  loss_centerness: 0.4754 (0.4776)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3448 (1.4959)  alignment_loss: 0.0842 (0.1749)  time: 1.1664 (1.2569)  data: 0.0172 (0.1401)  task_loss: 0.1394 (0.1345)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:00:56  iter: 580  loss: 2.2553 (2.5078)  loss_reg: 0.1775 (0.2306)  loss_centerness: 0.4740 (0.4776)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3849 (1.4956)  alignment_loss: 0.0825 (0.1747)  time: 1.1756 (1.2569)  data: 0.0164 (0.1401)  task_loss: 0.1394 (0.1346)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:00:31  iter: 600  loss: 2.2586 (2.5071)  loss_reg: 0.1922 (0.2305)  loss_centerness: 0.4751 (0.4776)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3392 (1.4953)  alignment_loss: 0.0806 (0.1744)  time: 1.1606 (1.2568)  data: 0.0142 (0.1400)  task_loss: 0.1394 (0.1346)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:00:06  iter: 620  loss: 2.2243 (2.5065)  loss_reg: 0.1904 (0.2304)  loss_centerness: 0.4738 (0.4776)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3799 (1.4951)  alignment_loss: 0.0788 (0.1741)  time: 1.1628 (1.2570)  data: 0.0151 (0.1403)  task_loss: 0.1394 (0.1346)  lr: 0.010000  wd: 0.000500  max mem: 12643
eta: 0:00:00  iter: 625  loss: 2.2243 (2.5064)  loss_reg: 0.1947 (0.2303)  loss_centerness: 0.4740 (0.4776)  loss_cls: 0.0000 (0.0000)  loss_dot_product_token: 1.3708 (1.4951)  alignment_loss: 0.0782 (0.1740)  time: 1.1628 (1.2570)  data: 0.0151 (0.1403)  task_loss: 0.1395 (0.1346)  lr: 0.000000  wd: 0.000500  max mem: 12643
Evaluating
2024-03-19 13:10:27,249 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 0
2024-03-19 13:10:35,656 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 13:10:35,660 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 13:10:35,681 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.1232876712328767, 0.4931506849315068, 0.589041095890411] 

2024-03-19 13:10:35,682 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 13:10:35,682 maskrcnn_benchmark INFO: Task[[tensor([0], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 13:10:35,682 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8493150684931506
evaluate on task refcoco, val, 0, res: {'refcoco': [0.1232876712328767, 0.4931506849315068, 0.589041095890411], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 13:10:35,697 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 1
2024-03-19 13:10:40,189 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 13:10:40,193 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 13:10:40,205 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2962962962962963, 0.7777777777777778, 0.8518518518518519] 

2024-03-19 13:10:40,205 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 13:10:40,206 maskrcnn_benchmark INFO: Task[[tensor([1], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 13:10:40,206 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8148148148148148
evaluate on task refcoco, val, 1, res: {'refcoco': [0.2962962962962963, 0.7777777777777778, 0.8518518518518519], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 13:10:40,224 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 2
2024-03-19 13:10:46,291 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 13:10:46,293 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 13:10:46,304 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.25, 0.6590909090909091, 0.7727272727272727] 

2024-03-19 13:10:46,305 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 13:10:46,305 maskrcnn_benchmark INFO: Task[[tensor([2], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 13:10:46,305 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.6363636363636364
evaluate on task refcoco, val, 2, res: {'refcoco': [0.25, 0.6590909090909091, 0.7727272727272727], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 13:10:46,321 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 3
2024-03-19 13:11:10,222 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 13:11:10,226 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 13:11:10,317 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3215686274509804, 0.7725490196078432, 0.8745098039215686] 

2024-03-19 13:11:10,318 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 13:11:10,318 maskrcnn_benchmark INFO: Task[[tensor([3], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 13:11:10,318 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8352941176470589
evaluate on task refcoco, val, 3, res: {'refcoco': [0.3215686274509804, 0.7725490196078432, 0.8745098039215686], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 13:11:10,337 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 4
2024-03-19 13:11:31,362 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 13:11:31,367 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 13:11:31,460 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.2857142857142857, 0.8, 0.861904761904762] 

2024-03-19 13:11:31,460 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 13:11:31,460 maskrcnn_benchmark INFO: Task[[tensor([4], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 13:11:31,461 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8523809523809524
evaluate on task refcoco, val, 4, res: {'refcoco': [0.2857142857142857, 0.8, 0.861904761904762], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 13:11:31,479 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 5
2024-03-19 13:12:00,471 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 13:12:00,475 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 13:12:00,579 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.23202614379084968, 0.6895424836601307, 0.8366013071895425] 

2024-03-19 13:12:00,580 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 13:12:00,580 maskrcnn_benchmark INFO: Task[[tensor([5], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 13:12:00,580 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8790849673202614
evaluate on task refcoco, val, 5, res: {'refcoco': [0.23202614379084968, 0.6895424836601307, 0.8366013071895425], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 13:12:00,599 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 6
2024-03-19 13:12:42,998 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 13:12:43,002 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 13:12:43,136 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.3333333333333333, 0.8776371308016878, 0.9578059071729957] 

2024-03-19 13:12:43,136 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 13:12:43,136 maskrcnn_benchmark INFO: Task[[tensor([6], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 13:12:43,136 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.8227848101265823
evaluate on task refcoco, val, 6, res: {'refcoco': [0.3333333333333333, 0.8776371308016878, 0.9578059071729957], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 13:12:43,153 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 7
2024-03-19 13:13:28,174 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 13:13:28,178 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 13:13:28,365 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.318, 0.78, 0.85] 

2024-03-19 13:13:28,365 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 13:13:28,365 maskrcnn_benchmark INFO: Task[[tensor([7], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 13:13:28,365 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.458
evaluate on task refcoco, val, 7, res: {'refcoco': [0.318, 0.78, 0.85], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 13:13:28,387 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 8
2024-03-19 13:14:13,351 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 13:14:13,354 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.10000000149011612), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.10000000149011612), ('AR@1000', 0.10000000149011612), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.10000000149011612)]))])
2024-03-19 13:14:13,539 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.362, 0.858, 0.914] 

2024-03-19 13:14:13,540 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 13:14:13,540 maskrcnn_benchmark INFO: Task[[tensor([8], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 13:14:13,540 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.888
evaluate on task refcoco, val, 8, res: {'refcoco': [0.362, 0.858, 0.914], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 13:14:13,559 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 9
2024-03-19 13:14:58,280 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 13:14:58,285 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.4000000059604645), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.4000000059604645), ('AR@1000', 0.4000000059604645), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.4000000059604645)]))])
2024-03-19 13:14:58,428 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.254, 0.642, 0.788] 

2024-03-19 13:14:58,429 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 13:14:58,429 maskrcnn_benchmark INFO: Task[[tensor([9], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 13:14:58,429 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.722
evaluate on task refcoco, val, 9, res: {'refcoco': [0.254, 0.642, 0.788], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 13:14:58,446 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 10
2024-03-19 13:15:42,890 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 13:15:42,892 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 13:15:43,033 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.368, 0.902, 0.94] 

2024-03-19 13:15:43,033 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 13:15:43,033 maskrcnn_benchmark INFO: Task[[tensor([10], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 13:15:43,033 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.86
evaluate on task refcoco, val, 10, res: {'refcoco': [0.368, 0.902, 0.94], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 13:15:43,052 maskrcnn_benchmark.trainer INFO: evaluating on refcoco, task type: val, task_id: 11
2024-03-19 13:16:27,916 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2024-03-19 13:16:27,919 maskrcnn_benchmark.inference INFO: OrderedDict([('box_proposal', OrderedDict([('AR@100', 0.0), ('ARs@100', 0.0), ('ARm@100', 0.0), ('ARl@100', 0.0), ('AR@1000', 0.0), ('ARs@1000', 0.0), ('ARm@1000', 0.0), ('ARl@1000', 0.0)]))])
2024-03-19 13:16:28,120 maskrcnn_benchmark INFO: Task[[tensor([11], device='cuda:0')]]: Dataset: refcoco - Precision @ 1, 5, 10: [0.29, 0.792, 0.898] 

2024-03-19 13:16:28,120 maskrcnn_benchmark INFO: Task[[tensor([11], device='cuda:0')]]: Dataset: refcoco+ - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

2024-03-19 13:16:28,121 maskrcnn_benchmark INFO: Task[[tensor([11], device='cuda:0')]]: Dataset: refcocog - Precision @ 1, 5, 10: [0.0, 0.0, 0.0] 

Default process group is not initialized
2024-03-19 13:16:28,121 maskrcnn_benchmark.inference INFO: task id prediction accuracy: 0.602
evaluate on task refcoco, val, 11, res: {'refcoco': [0.29, 0.792, 0.898], 'refcoco+': [0.0, 0.0, 0.0], 'refcocog': [0.0, 0.0, 0.0]}
2024-03-19 13:16:28,175 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_best.pth
Previous Best 0.0 Patience Counter 0 Eval Result 0.0
2024-03-19 13:16:29,330 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to OUTPUT/ft_task_1/model_final.pth
2024-03-19 13:16:30,607 maskrcnn_benchmark.trainer INFO: Total training time: 0:21:02.048069 (2.0193 s / it)
{0: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.136986301369863, 0.5068493150684932, 0.5753424657534246]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 1: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.136986301369863, 0.5068493150684932, 0.5753424657534246], 1: [0.25925925925925924, 0.7037037037037037, 0.7777777777777778]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 2: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.5068493150684932, 0.5753424657534246], 1: [0.25925925925925924, 0.7037037037037037, 0.7777777777777778], 2: [0.25, 0.6590909090909091, 0.7272727272727273]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 3: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.5068493150684932, 0.5753424657534246], 1: [0.25925925925925924, 0.7037037037037037, 0.7777777777777778], 2: [0.25, 0.6363636363636364, 0.7272727272727273], 3: [0.29411764705882354, 0.7764705882352941, 0.8823529411764706]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 4: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.5068493150684932, 0.5753424657534246], 1: [0.25925925925925924, 0.7037037037037037, 0.8148148148148148], 2: [0.25, 0.6590909090909091, 0.75], 3: [0.3058823529411765, 0.7803921568627451, 0.8941176470588236], 4: [0.2523809523809524, 0.7904761904761904, 0.8666666666666667]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 5: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.4931506849315068, 0.5616438356164384], 1: [0.25925925925925924, 0.7037037037037037, 0.8148148148148148], 2: [0.25, 0.6590909090909091, 0.7727272727272727], 3: [0.30980392156862746, 0.7803921568627451, 0.8941176470588236], 4: [0.2571428571428571, 0.7857142857142857, 0.8666666666666667], 5: [0.20261437908496732, 0.6895424836601307, 0.8333333333333334]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 6: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.4931506849315068, 0.589041095890411], 1: [0.2962962962962963, 0.7037037037037037, 0.8518518518518519], 2: [0.25, 0.6590909090909091, 0.7727272727272727], 3: [0.3137254901960784, 0.7843137254901961, 0.8941176470588236], 4: [0.26666666666666666, 0.7857142857142857, 0.861904761904762], 5: [0.21895424836601307, 0.696078431372549, 0.8431372549019608], 6: [0.35864978902953587, 0.9029535864978903, 0.9662447257383966]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 7: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.4794520547945205, 0.589041095890411], 1: [0.2962962962962963, 0.7407407407407407, 0.8518518518518519], 2: [0.25, 0.6590909090909091, 0.7727272727272727], 3: [0.3137254901960784, 0.7764705882352941, 0.8862745098039215], 4: [0.2714285714285714, 0.780952380952381, 0.8571428571428571], 5: [0.22549019607843138, 0.6928104575163399, 0.8366013071895425], 6: [0.3649789029535865, 0.9071729957805907, 0.9641350210970464], 7: [0.306, 0.784, 0.838]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 8: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.4794520547945205, 0.589041095890411], 1: [0.2962962962962963, 0.7407407407407407, 0.8518518518518519], 2: [0.25, 0.6590909090909091, 0.7727272727272727], 3: [0.3137254901960784, 0.7764705882352941, 0.8862745098039215], 4: [0.2714285714285714, 0.7857142857142857, 0.8571428571428571], 5: [0.22549019607843138, 0.7026143790849673, 0.8366013071895425], 6: [0.36075949367088606, 0.9008438818565401, 0.9641350210970464], 7: [0.308, 0.784, 0.842], 8: [0.342, 0.854, 0.916]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 9: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.4794520547945205, 0.589041095890411], 1: [0.2962962962962963, 0.7777777777777778, 0.8518518518518519], 2: [0.25, 0.6590909090909091, 0.7727272727272727], 3: [0.3215686274509804, 0.7725490196078432, 0.8784313725490196], 4: [0.2714285714285714, 0.7904761904761904, 0.8571428571428571], 5: [0.22875816993464052, 0.6993464052287581, 0.8398692810457516], 6: [0.33755274261603374, 0.8776371308016878, 0.9493670886075949], 7: [0.306, 0.782, 0.842], 8: [0.358, 0.852, 0.916], 9: [0.248, 0.626, 0.78]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 10: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.4794520547945205, 0.589041095890411], 1: [0.2962962962962963, 0.7777777777777778, 0.8518518518518519], 2: [0.25, 0.6590909090909091, 0.7727272727272727], 3: [0.3215686274509804, 0.7725490196078432, 0.8784313725490196], 4: [0.28095238095238095, 0.8, 0.861904761904762], 5: [0.22549019607843138, 0.696078431372549, 0.8398692810457516], 6: [0.33544303797468356, 0.879746835443038, 0.9535864978902954], 7: [0.312, 0.782, 0.844], 8: [0.364, 0.856, 0.916], 9: [0.254, 0.636, 0.784], 10: [0.368, 0.898, 0.934]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}, 11: {'refcoco': {'testA': {}, 'testB': {}, 'val': {0: [0.1232876712328767, 0.4931506849315068, 0.589041095890411], 1: [0.2962962962962963, 0.7777777777777778, 0.8518518518518519], 2: [0.25, 0.6590909090909091, 0.7727272727272727], 3: [0.3215686274509804, 0.7725490196078432, 0.8745098039215686], 4: [0.2857142857142857, 0.8, 0.861904761904762], 5: [0.23202614379084968, 0.6895424836601307, 0.8366013071895425], 6: [0.3333333333333333, 0.8776371308016878, 0.9578059071729957], 7: [0.318, 0.78, 0.85], 8: [0.362, 0.858, 0.914], 9: [0.254, 0.642, 0.788], 10: [0.368, 0.902, 0.94], 11: [0.29, 0.792, 0.898]}}, 'refcoco+': {'testA': {}, 'testB': {}, 'val': {}}, 'refcocog': {'test': {}, 'val': {}}}}
